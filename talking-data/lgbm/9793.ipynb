{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train on days 8 & 9\n",
    "--\n",
    "subm 023\n",
    "predictors ['nextClick', 'nextClick_shift', 'app', 'device', 'os', 'channel', 'hour', 'ip_tcount', 'ip_tchan_count', \n",
    "'ip_app_count', 'ip_app_os_count', 'ip_app_os_var', 'ip_app_channel_var_day', 'ip_app_channel_mean_hour', \n",
    "'X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'iadoc_mean_nc', 'ic_mean_nc']\n",
    "train size:  104365809\n",
    "valid size:  11596202\n",
    "test size :  18790469\n",
    "\n",
    "Training until validation scores don't improve for 30 rounds.\n",
    "[10]\ttrain's auc: 0.976291\tval's auc: 0.975958\n",
    "[20]\ttrain's auc: 0.97987\tval's auc: 0.979523\n",
    "[30]\ttrain's auc: 0.982051\tval's auc: 0.981608\n",
    "[40]\ttrain's auc: 0.983125\tval's auc: 0.982581\n",
    "[50]\ttrain's auc: 0.983691\tval's auc: 0.983042\n",
    "[60]\ttrain's auc: 0.984024\tval's auc: 0.983258\n",
    "[70]\ttrain's auc: 0.984403\tval's auc: 0.983474\n",
    "[80]\ttrain's auc: 0.984647\tval's auc: 0.983642\n",
    "[90]\ttrain's auc: 0.984878\tval's auc: 0.983743\n",
    "[100]\ttrain's auc: 0.985067\tval's auc: 0.983787\n",
    "[110]\ttrain's auc: 0.985254\tval's auc: 0.983922\n",
    "[120]\ttrain's auc: 0.985415\tval's auc: 0.984008\n",
    "[130]\ttrain's auc: 0.985534\tval's auc: 0.984037\n",
    "[140]\ttrain's auc: 0.985662\tval's auc: 0.984096\n",
    "[150]\ttrain's auc: 0.985788\tval's auc: 0.984134\n",
    "[160]\ttrain's auc: 0.985895\tval's auc: 0.984157\n",
    "[170]\ttrain's auc: 0.985993\tval's auc: 0.984149\n",
    "[180]\ttrain's auc: 0.986095\tval's auc: 0.984178\n",
    "[190]\ttrain's auc: 0.986173\tval's auc: 0.984187\n",
    "[200]\ttrain's auc: 0.986252\tval's auc: 0.984202\n",
    "[210]\ttrain's auc: 0.986323\tval's auc: 0.984217\n",
    "[220]\ttrain's auc: 0.986392\tval's auc: 0.984249\n",
    "[230]\ttrain's auc: 0.986466\tval's auc: 0.984234\n",
    "[240]\ttrain's auc: 0.986546\tval's auc: 0.984255\n",
    "[250]\ttrain's auc: 0.986608\tval's auc: 0.984257\n",
    "[260]\ttrain's auc: 0.986667\tval's auc: 0.984251\n",
    "[270]\ttrain's auc: 0.98673\tval's auc: 0.984253\n",
    "[280]\ttrain's auc: 0.986789\tval's auc: 0.984256\n",
    "Early stopping, best iteration is:\n",
    "[253]\ttrain's auc: 0.986624\tval's auc: 0.984261\n",
    "\n",
    "Model Report\n",
    "bst1.best_iteration:  253\n",
    "[5459.385001420975]: model training time\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import feather\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "inpath = '../input/'\n",
    "suffix = ''\n",
    "outpath = ''\n",
    "savepath = ''\n",
    "debug=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows=      184903891-1\n",
    "#train_size=  75000000\n",
    "#val_size=     2500000\n",
    "#offset=      75000000\n",
    "#frm=nrows-offset\n",
    "#to=frm+train_size\n",
    "\n",
    "#day 8 starting from=68941878\n",
    "#day 9 starts 131886953\n",
    "#day 9 ends 184903889\n",
    "\n",
    "#day 9 hour 4 starts; 144708152\n",
    "#day 9 hour 4 ends; 148740842\n",
    "\n",
    "train_size=  62945075\n",
    "val_size=    53016936\n",
    "offset=      68941878\n",
    "frm=offset\n",
    "to=frm+train_size+val_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68941878, 184903889)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frm, to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def do_count( df, group_cols, agg_name, agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    if show_agg:\n",
    "        print( \"Aggregating by \", group_cols , '...' )\n",
    "    gp = df[group_cols][group_cols].groupby(group_cols).size().rename(agg_name).to_frame().reset_index()\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return df \n",
    "\n",
    "def do_countuniq( df, group_cols, counted, agg_name, agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    if show_agg:\n",
    "        print( \"Counting unqiue \", counted, \" by \", group_cols , '...' )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].nunique().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return df \n",
    "    \n",
    "def do_cumcount( df, group_cols, counted, agg_name, agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    if show_agg:\n",
    "        print( \"Cumulative count by \", group_cols , '...' )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].cumcount()\n",
    "    df[agg_name]=gp.values\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return df \n",
    "\n",
    "def do_mean( df, group_cols, counted, agg_name, agg_type='float32', show_max=False, show_agg=True ):\n",
    "    if show_agg:\n",
    "        print( \"Calculating mean of \", counted, \" by \", group_cols , '...' )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].mean().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return df \n",
    "\n",
    "def do_var( df, group_cols, counted, agg_name, agg_type='float32', show_max=False, show_agg=True ):\n",
    "    if show_agg:\n",
    "        print( \"Calculating variance of \", counted, \" by \", group_cols , '...' )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].var().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return df \n",
    "\n",
    "\n",
    "def DO(frm, to):\n",
    "    dtypes = {\n",
    "            'ip'            : 'uint32',\n",
    "            'app'           : 'uint16',\n",
    "            'device'        : 'uint16',\n",
    "            'os'            : 'uint16',\n",
    "            'channel'       : 'uint16',\n",
    "            'is_attributed' : 'uint8',\n",
    "            'click_id'      : 'uint32',\n",
    "            }\n",
    "    \n",
    "    print('loading train data...')\n",
    "    train_df = feather.read_dataframe('/kaggle1/td-cache/train_base.feather')\n",
    "    train_df = train_df.iloc[frm:to]\n",
    "        \n",
    "    gc.collect()\n",
    "    \n",
    "    print('loading test data...')\n",
    "    test_df = feather.read_dataframe('/kaggle1/td-cache/test_base.feather')\n",
    "    train_df=train_df.append(test_df)\n",
    "    \n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Extracting new features...')\n",
    "    \n",
    "    gc.collect()\n",
    "    train_df = do_countuniq( train_df, ['ip'], 'channel', 'X0', 'uint8', show_max=True ); gc.collect()\n",
    "    train_df = do_cumcount( train_df, ['ip', 'device', 'os'], 'app', 'X1', show_max=True ); gc.collect()\n",
    "    train_df = do_countuniq( train_df, ['ip', 'day'], 'hour', 'X2', 'uint8', show_max=True ); gc.collect()\n",
    "    train_df = do_countuniq( train_df, ['ip'], 'app', 'X3', 'uint8', show_max=True ); gc.collect()\n",
    "    train_df = do_countuniq( train_df, ['ip', 'app'], 'os', 'X4', 'uint8', show_max=True ); gc.collect()\n",
    "    train_df = do_countuniq( train_df, ['ip'], 'device', 'X5', 'uint16', show_max=True ); gc.collect()\n",
    "    train_df = do_countuniq( train_df, ['app'], 'channel', 'X6', show_max=True ); gc.collect()\n",
    "    train_df = do_cumcount( train_df, ['ip'], 'os', 'X7', show_max=True ); gc.collect()\n",
    "    train_df = do_countuniq( train_df, ['ip', 'device', 'os'], 'app', 'X8', show_max=True ); gc.collect()\n",
    "    train_df = do_count( train_df, ['ip', 'day', 'hour'], 'ip_tcount', show_max=True ); gc.collect()\n",
    "    train_df = do_count( train_df, ['ip', 'app'], 'ip_app_count', show_max=True ); gc.collect()\n",
    "    train_df = do_count( train_df, ['ip', 'app', 'os'], 'ip_app_os_count', 'uint16', show_max=True ); gc.collect()    \n",
    "    train_df = do_var( train_df, ['ip', 'day', 'channel'], 'hour', 'ip_tchan_count', show_max=True ); gc.collect()\n",
    "    train_df = do_var( train_df, ['ip', 'app', 'os'], 'hour', 'ip_app_os_var', show_max=True ); gc.collect()\n",
    "    train_df = do_var( train_df, ['ip', 'app', 'channel'], 'day', 'ip_app_channel_var_day', show_max=True ); gc.collect()\n",
    "    train_df = do_mean( train_df, ['ip', 'app', 'channel'], 'hour', 'ip_app_channel_mean_hour', show_max=True ); gc.collect()\n",
    "\n",
    "    print('doing nextClick')\n",
    "    #predictors=[]\n",
    "    \n",
    "    new_feature = 'nextClick'\n",
    "    filename='nextClick_%d_%d.csv'%(frm,to)\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        print('loading from save file')\n",
    "        QQ=pd.read_csv(filename, header=None)[0].values\n",
    "    else:\n",
    "        D=2**26\n",
    "        train_df['category'] = (train_df['ip'].astype(str) + \"_\" + train_df['app'].astype(str) + \"_\" + train_df['device'].astype(str) \\\n",
    "            + \"_\" + train_df['os'].astype(str)).apply(hash) % D\n",
    "        click_buffer= np.full(D, 3000000000, dtype=np.uint32)\n",
    "\n",
    "        train_df['epochtime']= train_df['click_time'].astype(np.int64) // 10 ** 9\n",
    "        next_clicks= []\n",
    "        for category, t in zip(reversed(train_df['category'].values), reversed(train_df['epochtime'].values)):\n",
    "            next_clicks.append(click_buffer[category]-t)\n",
    "            click_buffer[category]= t\n",
    "        del(click_buffer)\n",
    "        QQ= list(reversed(next_clicks))\n",
    "\n",
    "        if not debug:\n",
    "            print('saving')\n",
    "            pd.DataFrame(QQ).to_csv(filename,index=False)\n",
    "            \n",
    "    to_drop = [x for x in train_df.columns if x in ['epochtime','category','click_time']]\n",
    "    train_df.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "    train_df[new_feature] = pd.Series(QQ).astype('float32')\n",
    "    #predictors.append(new_feature)\n",
    "\n",
    "    train_df[new_feature+'_shift'] = train_df[new_feature].shift(+1).values\n",
    "    #predictors.append(new_feature+'_shift')\n",
    "    \n",
    "    del QQ\n",
    "    gc.collect()\n",
    "\n",
    "    train_df['ip_tcount'] = train_df['ip_tcount'].astype('uint16')\n",
    "    train_df['ip_app_count'] = train_df['ip_app_count'].astype('uint16')\n",
    "    train_df['ip_app_os_count'] = train_df['ip_app_os_count'].astype('uint16')\n",
    "\n",
    "    print(\"vars and data type: \")\n",
    "    train_df.info()\n",
    "    \n",
    "    train_df.reset_index(drop=True, inplace=True)\n",
    "    feather.write_dataframe(train_df, '9671_train_from{}_to{}.feather'.format(frm, to))\n",
    "\n",
    "    return train_df\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-20 16:16:57.752146\n",
      "2018-04-20 16:18:28.357997\n"
     ]
    }
   ],
   "source": [
    "import feather\n",
    "import datetime\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "fname = '9671_train_from{}_to{}.feather'.format(frm, to)\n",
    "if not os.path.exists(fname):\n",
    "    print('generating')\n",
    "    DO(frm, to)\n",
    "train_df = feather.read_dataframe(fname)    \n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import feather\n",
    "#df = feather.read_dataframe('/kaggle1/td-cache/train_base.feather')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.nextClick.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 134752480 entries, 0 to 134752479\n",
      "Data columns (total 26 columns):\n",
      "app                         uint16\n",
      "channel                     uint16\n",
      "day                         uint8\n",
      "device                      uint16\n",
      "hour                        uint8\n",
      "ip                          uint32\n",
      "is_attributed               uint8\n",
      "os                          uint16\n",
      "X0                          uint8\n",
      "X1                          uint32\n",
      "X2                          uint8\n",
      "X3                          uint8\n",
      "X4                          uint8\n",
      "X5                          uint16\n",
      "X6                          uint32\n",
      "X7                          uint32\n",
      "X8                          uint32\n",
      "ip_tcount                   uint16\n",
      "ip_app_count                uint16\n",
      "ip_app_os_count             uint16\n",
      "ip_tchan_count              float32\n",
      "ip_app_os_var               float32\n",
      "ip_app_channel_var_day      float32\n",
      "ip_app_channel_mean_hour    float32\n",
      "nextClick                   float32\n",
      "nextClick_shift             float32\n",
      "dtypes: float32(6), uint16(8), uint32(5), uint8(7)\n",
      "memory usage: 8.4 GB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_modelfit_nocv(params, train_df, val_dfs, predictors, target='target', objective='binary', metrics='auc',\n",
    "                 feval=None, early_stopping_rounds=20, num_boost_round=3000, verbose_eval=10, categorical_features=None):\n",
    "    \n",
    "    lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': objective,\n",
    "        'metric':metrics,\n",
    "        'nthread': 8,\n",
    "        'verbose': 0,\n",
    "        'metric':metrics\n",
    "    }\n",
    "\n",
    "    lgb_params.update(params)\n",
    "\n",
    "    print(\"preparing validation datasets\")\n",
    "\n",
    "    dtrain = lgb.Dataset(train_df[predictors].values, label=train_df[target].values,\n",
    "                         feature_name=predictors,\n",
    "                         categorical_feature=categorical_features)\n",
    "    valid_names = ['train']\n",
    "    valid_sets = [dtrain]\n",
    "    for val_name, val_df in val_dfs.items():\n",
    "        valid_names.append(val_name)\n",
    "        dvalid = lgb.Dataset(val_df[predictors].values, \n",
    "                             label=val_df[target].values,\n",
    "                             feature_name=predictors,\n",
    "                             categorical_feature=categorical_features)\n",
    "        valid_sets.append(dvalid)\n",
    "\n",
    "    evals_results = {}\n",
    "\n",
    "    bst1 = lgb.train(lgb_params, \n",
    "                     dtrain, \n",
    "                     valid_sets=valid_sets,\n",
    "                     valid_names=valid_names, \n",
    "                     evals_result=evals_results, \n",
    "                     num_boost_round=num_boost_round,\n",
    "                     early_stopping_rounds=early_stopping_rounds,\n",
    "                     verbose_eval=10, \n",
    "                     feval=feval)\n",
    "\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"bst1.best_iteration: \", bst1.best_iteration)\n",
    "    #print(metrics+\":\", evals_results['valid'][metrics][bst1.best_iteration-1])\n",
    "\n",
    "    return bst1, bst1.best_iteration, evals_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical: ['app', 'device', 'os', 'channel', 'hour']\n"
     ]
    }
   ],
   "source": [
    "categorical = ['app', 'device', 'os', 'channel', 'hour']\n",
    "\n",
    "predictors = []\n",
    "predictors.extend(['nextClick', 'nextClick_shift'])\n",
    "predictors.extend([\n",
    "    'app','device','os', 'channel', 'hour', #'day', \n",
    "    'ip_tcount', 'ip_tchan_count', 'ip_app_count',\n",
    "    'ip_app_os_count', \n",
    "    'ip_app_os_var',\n",
    "    'ip_app_channel_var_day','ip_app_channel_mean_hour',\n",
    "    'X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8'])\n",
    "\n",
    "print('categorical:', categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_mean_nc(df, group_cols, name):\n",
    "    gp = df[group_cols + ['nextClick']].groupby(by=group_cols).nextClick.mean().rename(columns={'nextClick': name}).to_frame().reset_index()\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "train_df = _add_mean_nc(train_df, ['ip', 'app', 'device', 'os', 'channel'], 'iadoc_mean_nc')\n",
    "train_df = _add_mean_nc(train_df, ['ip', 'channel'], 'ic_mean_nc')\n",
    "predictors.extend(['iadoc_mean_nc', 'ic_mean_nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = do_count( train_df, ['ip', 'app', 'channel'], 'ip_app_channel_count', 'uint16', show_max=True ); gc.collect()\n",
    "#train_df = do_count( train_df, ['ip', 'app', 'os', 'hour'], 'ip_app_os_hour_count', 'uint16', show_max=True ); gc.collect()\n",
    "#predictors.extend(['ip_app_channel_count', 'ip_app_os_hour_count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 134752480 entries, 0 to 134752479\n",
      "Data columns (total 28 columns):\n",
      "app                         uint16\n",
      "channel                     uint16\n",
      "day                         uint8\n",
      "device                      uint16\n",
      "hour                        uint8\n",
      "ip                          uint32\n",
      "is_attributed               uint8\n",
      "os                          uint16\n",
      "X0                          uint8\n",
      "X1                          uint32\n",
      "X2                          uint8\n",
      "X3                          uint8\n",
      "X4                          uint8\n",
      "X5                          uint16\n",
      "X6                          uint32\n",
      "X7                          uint32\n",
      "X8                          uint32\n",
      "ip_tcount                   uint16\n",
      "ip_app_count                uint16\n",
      "ip_app_os_count             uint16\n",
      "ip_tchan_count              float32\n",
      "ip_app_os_var               float32\n",
      "ip_app_channel_var_day      float32\n",
      "ip_app_channel_mean_hour    float32\n",
      "nextClick                   float32\n",
      "nextClick_shift             float32\n",
      "iadoc_mean_nc               float32\n",
      "ic_mean_nc                  float32\n",
      "dtypes: float32(8), uint16(8), uint32(5), uint8(7)\n",
      "memory usage: 10.4 GB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df['iadoc_mean_nc'] = train_df['0_x']\n",
    "#train_df['ic_mean_nc'] = train_df['0_y']\n",
    "del train_df['0_x']\n",
    "del train_df['0_y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 134752480 entries, 0 to 134752479\n",
      "Data columns (total 30 columns):\n",
      "app                         uint16\n",
      "channel                     uint16\n",
      "day                         uint8\n",
      "device                      uint16\n",
      "hour                        uint8\n",
      "ip                          uint32\n",
      "is_attributed               uint8\n",
      "os                          uint16\n",
      "X0                          uint8\n",
      "X1                          uint32\n",
      "X2                          uint8\n",
      "X3                          uint8\n",
      "X4                          uint8\n",
      "X5                          uint16\n",
      "X6                          uint32\n",
      "X7                          uint32\n",
      "X8                          uint32\n",
      "ip_tcount                   uint16\n",
      "ip_app_count                uint16\n",
      "ip_app_os_count             uint16\n",
      "ip_tchan_count              float32\n",
      "ip_app_os_var               float32\n",
      "ip_app_channel_var_day      float32\n",
      "ip_app_channel_mean_hour    float32\n",
      "nextClick                   float32\n",
      "nextClick_shift             float32\n",
      "0_x                         float32\n",
      "0_y                         float32\n",
      "0_x                         float32\n",
      "0_y                         float32\n",
      "dtypes: float32(10), uint16(8), uint32(5), uint8(7)\n",
      "memory usage: 11.4 GB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def DO2(train_df, predictors, categorical):\n",
    "\n",
    "    target = 'is_attributed'\n",
    "    print('predictors', predictors)\n",
    "\n",
    "    frm, to = (68941878, 184903889)\n",
    "    \n",
    "    len_train = to - frm\n",
    "    \n",
    "    test_df = train_df[len_train:]\n",
    "    \n",
    "    train_df, val_df = train_test_split(train_df[:len_train], test_size=.1)\n",
    "\n",
    "    print(\"train size: \", len(train_df))\n",
    "    print(\"valid size: \", len(val_df))\n",
    "    print(\"test size : \", len(test_df))\n",
    "    \n",
    "    val_dfs = {\n",
    "        'val':  val_df,\n",
    "    }    \n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "    print(\"Training...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': 0.2,\n",
    "        #'is_unbalance': 'true', # replaced with scale_pos_weight argument\n",
    "        'num_leaves': 15,  # 2^max_depth - 1\n",
    "        'max_depth': 4,  # -1 means no limit\n",
    "        'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "        'max_bin': 255,  # Number of bucketed bin for feature values\n",
    "        'subsample': 0.7,  # Subsample ratio of the training instance.\n",
    "        'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n",
    "        'colsample_bytree': 0.9,  # Subsample ratio of columns when constructing each tree.\n",
    "        'min_child_weight': 0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "        'scale_pos_weight':200, # because training data is extremely unbalanced \n",
    "        'subsample_for_bin': 200000,  # Number of samples for constructing bin\n",
    "        'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "        'reg_alpha': 0,  # L1 regularization term on weights\n",
    "        'reg_lambda': 0,  # L2 regularization term on weights\n",
    "        \n",
    "    }\n",
    "    bst, best_iteration, evals_results = lgb_modelfit_nocv(params, \n",
    "                            train_df, \n",
    "                            val_dfs, \n",
    "                            predictors, \n",
    "                            target, \n",
    "                            objective='binary', \n",
    "                            metrics='auc',\n",
    "                            early_stopping_rounds=30, \n",
    "                            verbose_eval=True, \n",
    "                            num_boost_round=1000, \n",
    "                            categorical_features=categorical)\n",
    "\n",
    "    print('[{}]: model training time'.format(time.time() - start_time))\n",
    "    del train_df\n",
    "    del val_df\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "    #print('Plot feature importances...')\n",
    "    #ax = lgb.plot_importance(bst, max_num_features=100)\n",
    "    #plt.show()\n",
    "    \n",
    "\n",
    "    return bst, evals_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictors ['nextClick', 'nextClick_shift', 'app', 'device', 'os', 'channel', 'hour', 'ip_tcount', 'ip_tchan_count', 'ip_app_count', 'ip_app_os_count', 'ip_app_os_var', 'ip_app_channel_var_day', 'ip_app_channel_mean_hour', 'X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'iadoc_mean_nc', 'ic_mean_nc']\n",
      "train size:  104365809\n",
      "valid size:  11596202\n",
      "test size :  18790469\n",
      "Training...\n",
      "preparing validation datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda2/envs/talkingdata/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/miniconda2/envs/talkingdata/lib/python3.6/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds.\n",
      "[10]\ttrain's auc: 0.976291\tval's auc: 0.975958\n",
      "[20]\ttrain's auc: 0.97987\tval's auc: 0.979523\n",
      "[30]\ttrain's auc: 0.982051\tval's auc: 0.981608\n",
      "[40]\ttrain's auc: 0.983125\tval's auc: 0.982581\n",
      "[50]\ttrain's auc: 0.983691\tval's auc: 0.983042\n",
      "[60]\ttrain's auc: 0.984024\tval's auc: 0.983258\n",
      "[70]\ttrain's auc: 0.984403\tval's auc: 0.983474\n",
      "[80]\ttrain's auc: 0.984647\tval's auc: 0.983642\n",
      "[90]\ttrain's auc: 0.984878\tval's auc: 0.983743\n",
      "[100]\ttrain's auc: 0.985067\tval's auc: 0.983787\n",
      "[110]\ttrain's auc: 0.985254\tval's auc: 0.983922\n",
      "[120]\ttrain's auc: 0.985415\tval's auc: 0.984008\n",
      "[130]\ttrain's auc: 0.985534\tval's auc: 0.984037\n",
      "[140]\ttrain's auc: 0.985662\tval's auc: 0.984096\n",
      "[150]\ttrain's auc: 0.985788\tval's auc: 0.984134\n",
      "[160]\ttrain's auc: 0.985895\tval's auc: 0.984157\n",
      "[170]\ttrain's auc: 0.985993\tval's auc: 0.984149\n",
      "[180]\ttrain's auc: 0.986095\tval's auc: 0.984178\n",
      "[190]\ttrain's auc: 0.986173\tval's auc: 0.984187\n",
      "[200]\ttrain's auc: 0.986252\tval's auc: 0.984202\n",
      "[210]\ttrain's auc: 0.986323\tval's auc: 0.984217\n",
      "[220]\ttrain's auc: 0.986392\tval's auc: 0.984249\n",
      "[230]\ttrain's auc: 0.986466\tval's auc: 0.984234\n",
      "[240]\ttrain's auc: 0.986546\tval's auc: 0.984255\n",
      "[250]\ttrain's auc: 0.986608\tval's auc: 0.984257\n",
      "[260]\ttrain's auc: 0.986667\tval's auc: 0.984251\n",
      "[270]\ttrain's auc: 0.98673\tval's auc: 0.984253\n",
      "[280]\ttrain's auc: 0.986789\tval's auc: 0.984256\n",
      "Early stopping, best iteration is:\n",
      "[253]\ttrain's auc: 0.986624\tval's auc: 0.984261\n",
      "\n",
      "Model Report\n",
      "bst1.best_iteration:  253\n",
      "[5459.385001420975]: model training time\n"
     ]
    }
   ],
   "source": [
    "#day 9 starts 131886953\n",
    "#day 9 ends 184903889\n",
    "bst, evals_results = DO2(train_df, predictors, categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train_df, frm, to, predictors, bst, best_iteration=-1):\n",
    "    len_train = to - frm    \n",
    "    test_df = train_df[len_train:]\n",
    "    \n",
    "    print(\"Predicting...\")\n",
    "    click_ids = pd.read_csv('../input/test.csv', usecols=['click_id'])['click_id'].values\n",
    "    \n",
    "    sub = pd.DataFrame()    \n",
    "    sub['click_id'] = click_ids\n",
    "        \n",
    "    gc.collect()\n",
    "        \n",
    "    sub['is_attributed'] = bst.predict(test_df[predictors],num_iteration=best_iteration)\n",
    "                            \n",
    "    print(\"writing...\")\n",
    "    sub.to_csv('subm_000_{}.csv'.format(best_iteration), index=False, float_format='%.9f')\n",
    "    print(\"done...\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "writing...\n",
      "done...\n"
     ]
    }
   ],
   "source": [
    "predict(train_df, frm, to, predictors, bst, 150) #subm22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "writing...\n",
      "done...\n"
     ]
    }
   ],
   "source": [
    "predict(train_df, frm, to, predictors, bst, 250) #subm23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
