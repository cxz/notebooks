{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform train & test.csv into numpy arrays.\n",
    "\n",
    "Before starting train.csv is split into parts so we can read in parallel.\n",
    "\n",
    "- `split -l 10000000 train.csv train_part`\n",
    "- `for i in $(ls -1 train_part*); do sed -i '1s;^;ip,app,device,os,channel,click_time,attributed_time,is_attributed\\n;' $i`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import hashlib\n",
    "import traceback \n",
    "import math\n",
    "import pickle\n",
    "from csv import DictReader\n",
    "import multiprocessing as mp\n",
    "from functools import lru_cache\n",
    "from collections import Counter\n",
    "from pyhashxx import hashxx\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "D = 2 ** 23\n",
    "\n",
    "\n",
    "FEATURES = [\n",
    "    \n",
    "    # single features\n",
    "    ('ip',), \n",
    "    ('app',), \n",
    "    ('device',),\n",
    "    ('os',), \n",
    "    ('channel',),\n",
    "    \n",
    "    ('click_hour',),\n",
    "    \n",
    "    # pair interactions\n",
    "    ('device', 'app'), \n",
    "    ('channel', 'app'), \n",
    "    ('channel', 'device'), \n",
    "    ('channel', 'os'),\n",
    "    ('ip', 'channel'),\n",
    "    ('ip', 'device'),\n",
    "    ('ip', 'app'),\n",
    "    ('ip', 'click_hour'),\n",
    "    \n",
    "    # triple\n",
    "    ('ip', 'device', 'os')\n",
    "]\n",
    "\n",
    "COUNT_FEATURES = [\n",
    "    ('device', 'app'), \n",
    "    ('channel', 'app'), \n",
    "    ('channel', 'device'), \n",
    "    ('channel', 'os'),\n",
    "    ('ip', 'channel'),\n",
    "    ('ip', 'device'),\n",
    "    ('ip', 'app'),\n",
    "    ('ip', 'click_hour'),\n",
    "    ('ip', 'device', 'os')        \n",
    "]\n",
    "\n",
    "# maxsize=None means the cache is unbounded.\n",
    "# set to something reasonable if memory is limited.\n",
    "@lru_cache(maxsize=None)\n",
    "def hashed(value, D):\n",
    "    # hash is not stable after python 3.3 unless PYTHONHASHSEED is set.\n",
    "    # we need something with less collisions and stable to be able to pickle the model.\n",
    "    #return int(hashlib.md5(value.encode('utf8')).hexdigest(), 16) % D\n",
    "    return hashxx(value.encode('utf8')) % D\n",
    "\n",
    "        \n",
    "def get_x(csv_row):        \n",
    "    try:\n",
    "        x = {}\n",
    "        csv_row['click_hour'] = int(csv_row['click_time'][-8:-6]) # hour\n",
    "        for k in FEATURES:\n",
    "            x[k] = hashed(' '.join([str(csv_row[c]) for c in k]), D)\n",
    "        return x\n",
    "    except Exception as e:\n",
    "        #print(csv_row)        \n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "def load_part(fname, max_size=10000000):\n",
    "    train_x = np.zeros((max_size, len(FEATURES)), dtype=np.uint32) \n",
    "    train_y = np.zeros((max_size), dtype=np.uint8)\n",
    "    assert(D < 2**32)\n",
    "    \n",
    "    partial_counters = {}\n",
    "    for k in COUNT_FEATURES:    \n",
    "        partial_counters[k] = Counter()\n",
    "        \n",
    "    with open(fname) as f:\n",
    "        rows = 0\n",
    "        for idx, row in tqdm(enumerate(DictReader(f)), total=max_size, mininterval=30):\n",
    "            h = get_x(row)\n",
    "            x = [h[k] for k in FEATURES]\n",
    "            \n",
    "            train_x[idx, :] = x\n",
    "            train_y[idx] = 1. if row['is_attributed'] == '1' else 0\n",
    "            \n",
    "            if int(row['click_time'][-1:]) != 9:            \n",
    "                # 2017-11-09 is validation set\n",
    "                is_validation=True\n",
    "                \n",
    "                \n",
    "            # update partial counters, \n",
    "            for k in COUNT_FEATURES:                \n",
    "                partial_counters[k][h[k]] += 1\n",
    "                \n",
    "            rows += 1\n",
    "            \n",
    "        return train_x[:rows], train_y[:rows], partial_counters\n",
    "\n",
    "def prepare_train(glob_path):\n",
    "    fnames = list(glob.glob(glob_path))\n",
    "\n",
    "    p = mp.Pool(8)\n",
    "    parts = p.map(load_part, fnames)\n",
    "    \n",
    "    X = np.concatenate([p[0] for p in parts])\n",
    "    y = np.concatenate([p[1] for p in parts])\n",
    "    counters = {}\n",
    "    for k in COUNT_FEATURES:                \n",
    "        counters[k] = sum([p[2][k] for p in parts], Counter())\n",
    "    \n",
    "    print(X.shape, y.shape, type(counters))\n",
    "    p.close()\n",
    "    \n",
    "    d = int(math.log(D, 2))\n",
    "    np.savez_compressed('tmp/train-hashxx-D{}.npz'.format(d), x=X, y=y)\n",
    "    with open('tmp/aux-hashxx-D{}.pkl'.format(d), 'wb') as f:\n",
    "        pickle.dump([counters, FEATURES, COUNT_FEATURES], f)    \n",
    "    return X, y, counters\n",
    "\n",
    "def prepare_test():\n",
    "    size = 18790470\n",
    "    X = np.zeros((size, len(FEATURES)), dtype=np.uint32)\n",
    "    click_id = np.zeros((size), dtype=np.uint32)\n",
    "    with open('input/test.csv') as f:\n",
    "        for idx, row in tqdm(enumerate(DictReader(f)), total=size, mininterval=30):\n",
    "            h = get_x(row)\n",
    "            x = [h[k] for k in FEATURES]\n",
    "            X[idx, :] = x\n",
    "            click_id[idx] = row['click_id']\n",
    "    d = int(math.log(D, 2))\n",
    "    np.savez_compressed('tmp/test-hashxx-D{}.npz'.format(d), x=X, click_id=click_id)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "#X, y, counters = prepare_train('input/train_parta*')\n",
    "#print('finished train.')\n",
    "\n",
    "#X = prepare_test()\n",
    "#print('finished test.')\n",
    "\n",
    "print('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import gc\n",
    "#del X\n",
    "#del y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainz = np.load('tmp/train-hashxx-D23.npz')\n",
    "with open('tmp/aux-hashxx-D23.pkl', 'rb') as f: \n",
    "    aux = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['x', 'y'], 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainz.keys(), len(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features = [(k, features.index(k)) for k in count_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('device', 'app'), 6),\n",
       " (('channel', 'app'), 7),\n",
       " (('channel', 'device'), 8),\n",
       " (('channel', 'os'), 9),\n",
       " (('ip', 'channel'), 10),\n",
       " (('ip', 'device'), 11),\n",
       " (('ip', 'app'), 12),\n",
       " (('ip', 'click_hour'), 13),\n",
       " (('ip', 'device', 'os'), 14)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((184903890, 15),\n",
       " (184903890,),\n",
       " dict_keys([('device', 'app'), ('channel', 'app'), ('channel', 'device'), ('channel', 'os'), ('ip', 'channel'), ('ip', 'device'), ('ip', 'app'), ('ip', 'click_hour'), ('ip', 'device', 'os')]),\n",
       " list,\n",
       " 15,\n",
       " list,\n",
       " 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, counters.keys(), type(features), len(features), type(count_features), len(count_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "if False:\n",
    "    # temporary hack to parallize\n",
    "    def augment_single(feature_no):\n",
    "        X, y, counters, features, count_features = trainz['x'], trainz['y'], aux[0], aux[1], aux[2]    \n",
    "        pos_features = [\n",
    "            (('device', 'app'), 6),\n",
    "            (('channel', 'app'), 7),\n",
    "            (('channel', 'device'), 8),\n",
    "            (('channel', 'os'), 9),\n",
    "            (('ip', 'channel'), 10),\n",
    "            (('ip', 'device'), 11),\n",
    "            (('ip', 'app'), 12),\n",
    "            (('ip', 'click_hour'), 13),\n",
    "            (('ip', 'device', 'os'), 14)\n",
    "        ]\n",
    "\n",
    "        pos_feature = pos_features[feature_no]\n",
    "        feature_name, feature_pos = pos_feature\n",
    "        counter = counters[feature_name]\n",
    "        X_part = X[:, feature_pos].copy()\n",
    "\n",
    "        del X\n",
    "        del y\n",
    "        gc.collect()\n",
    "\n",
    "        extra_part = np.zeros((X_part.shape[0],), dtype=np.uint32) \n",
    "        extra_part = [counter[x] for x in tqdm(X_part)]\n",
    "        np.savez_compressed('tmp/extra-{}.npz'.format(feature_no), extra=extra_part)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def augment(X, counters, features, count_features):    \n",
    "    pos_features = [(k, features.index(k)) for k in count_features]\n",
    "    extra = np.zeros((X.shape[0], len(pos_features)), dtype=np.uint32) \n",
    "    for idx, (feature_name, feature_pos) in enumerate(pos_features):        \n",
    "        counter = counters[feature_name]\n",
    "        extra[:, idx] = [counter[x] for x in tqdm(X[:, feature_pos], mininterval=30)]\n",
    "    return extra\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_extra = augment(X, counters, features, count_features)\n",
    "\n",
    "trainz = np.load('tmp/train-hashxx-D23.npz')\n",
    "\n",
    "with open('tmp/aux-hashxx-D23.pkl', 'rb') as f: \n",
    "    aux = pickle.load(f)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, counters, features, count_features = trainz['x'], trainz['y'], aux[0], aux[1], aux[2]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = np.zeros((X.shape[0], 8), dtype=np.uint32) \n",
    "for feature_no in range(8):\n",
    "    extra[:, feature_no] = np.load('tmp/extra-{}.npz'.format(feature_no))['extra']\n",
    "                                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184903890, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184903890, 15)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.hstack([X, extra])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184903890, 23)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('tmp/train-hashxx-D23-extra.npz', x=X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X\n",
    "del extra\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('tmp/test-hashxx-D{}.npz'.format(d), x=X, click_id=click_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    train = np.load('tmp/train.npz')\n",
    "    X_train, y_trqain = train['x'], train['y']\n",
    "    print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    test = np.load('tmp/test.npz')\n",
    "    X_test = test['x']\n",
    "    print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=Counter()\n",
    "b=Counter()\n",
    "a['a'] += 1\n",
    "b['b'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 1, 'b': 1})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([a, b], Counter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
