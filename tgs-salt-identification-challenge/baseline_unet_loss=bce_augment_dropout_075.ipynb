{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#filters from 8 to 16\n",
    "#-->  .727 --> 77\n",
    "#0.9444444444444444 0.7085820895522389, --> 0.8888888888888888 0.7364427860696516  --> 75\n",
    "#0.9444444444444444 0.698150431565968 --> .727 --> 78\n",
    "#0.9444444444444444 0.6929113924050634  --> .72\n",
    "#0.7222222222222222 0.6810191082802548 --> .73\n",
    "\n",
    "#more dropout\n",
    "#heavier augmentations\n",
    "#changed loss back to bce\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import SpatialDropout2D, Activation\n",
    "from keras.layers import MaxPooling2D, UpSampling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "        \n",
    "PATH = 'input'\n",
    "\n",
    "sample_df = pd.read_csv('input/sample_submission.csv')\n",
    "test_ids = sample_df.id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "FOLDS_CSV = os.path.join(PATH, 'folds.csv')\n",
    "def generate_folds():\n",
    "    n_fold = 5\n",
    "    depths = pd.read_csv(os.path.join(PATH, 'depths.csv'))\n",
    "    depths.sort_values('z', inplace=True)\n",
    "    depths.drop('z', axis=1, inplace=True)\n",
    "    depths['fold'] = (list(range(n_fold))*depths.shape[0])[:depths.shape[0]]\n",
    "    print(depths.head())\n",
    "    depths.to_csv(FOLDS_CSV, index=False)\n",
    "\n",
    "if not os.path.exists(FOLDS_CSV):\n",
    "    generate_folds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = 128\n",
    "im_height = 128\n",
    "im_chan = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('input/X_train_128.npy')\n",
    "y_train = np.load('input/y_train_128.npy')\n",
    "X_test = np.load('input/X_test_128.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def double_conv_layer(x, size, dropout=0.0, batch_norm=True):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 3\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    if dropout > 0:\n",
    "        conv = SpatialDropout2D(dropout)(conv)\n",
    "    return conv\n",
    "\n",
    "def build_unet2(dropout_val=0.2, weights=None):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        inputs = Input((im_height, im_width, im_chan), name='inputs1')\n",
    "        axis = 1\n",
    "    else:\n",
    "        inputs = Input((im_height, im_width, im_chan), name='inputs1')\n",
    "        axis = 3\n",
    "\n",
    "    filters = 16\n",
    "    conv_224 = double_conv_layer(inputs, filters)\n",
    "    pool_112 = MaxPooling2D(pool_size=(2, 2))(conv_224)\n",
    "\n",
    "    conv_112 = double_conv_layer(pool_112, 2*filters)\n",
    "    pool_56 = MaxPooling2D(pool_size=(2, 2))(conv_112)\n",
    "\n",
    "    conv_56 = double_conv_layer(pool_56, 4*filters)\n",
    "    pool_28 = MaxPooling2D(pool_size=(2, 2))(conv_56)\n",
    "\n",
    "    conv_28 = double_conv_layer(pool_28, 8*filters)\n",
    "    pool_14 = MaxPooling2D(pool_size=(2, 2))(conv_28)\n",
    "\n",
    "    conv_14 = double_conv_layer(pool_14, 16*filters)\n",
    "    pool_7 = MaxPooling2D(pool_size=(2, 2))(conv_14)\n",
    "\n",
    "    conv_7 = double_conv_layer(pool_7, 32*filters)\n",
    "\n",
    "    up_14 = concatenate([UpSampling2D(size=(2, 2))(conv_7), conv_14], axis=axis)\n",
    "    up_conv_14 = double_conv_layer(up_14, 16*filters)\n",
    "\n",
    "    up_28 = concatenate([UpSampling2D(size=(2, 2))(up_conv_14), conv_28], axis=axis)\n",
    "    up_conv_28 = double_conv_layer(up_28, 8*filters)\n",
    "\n",
    "    up_56 = concatenate([UpSampling2D(size=(2, 2))(up_conv_28), conv_56], axis=axis)\n",
    "    up_conv_56 = double_conv_layer(up_56, 4*filters)\n",
    "\n",
    "    up_112 = concatenate([UpSampling2D(size=(2, 2))(up_conv_56), conv_112], axis=axis)\n",
    "    up_conv_112 = double_conv_layer(up_112, 2*filters, dropout_val)\n",
    "\n",
    "    up_224 = concatenate([UpSampling2D(size=(2, 2))(up_conv_112), conv_224], axis=axis)\n",
    "    up_conv_224 = double_conv_layer(up_224, filters, dropout_val)\n",
    "\n",
    "    output_mask_channels = 1\n",
    "    conv_final = Conv2D(output_mask_channels, (1, 1))(up_conv_224)\n",
    "    conv_final = Activation('sigmoid')(conv_final)    \n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv_final])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fold(X_train, y_train, fold):\n",
    "    train_df = pd.read_csv(os.path.join(PATH, 'train.csv'))\n",
    "    train_ids = train_df.id.values\n",
    "    \n",
    "    folds = pd.read_csv(FOLDS_CSV)\n",
    "    fold_dict = folds.set_index('id').to_dict()['fold']\n",
    "    \n",
    "    fold_train = [fold_dict[x]!=fold for x in train_ids]\n",
    "    fold_val = [fold_dict[x]==fold for x in train_ids]\n",
    "    \n",
    "    X_fold, y_fold = X_train[fold_train], y_train[fold_train]    \n",
    "    X_val, y_val = X_train[fold_val], y_train[fold_val]    \n",
    "    return X_fold, y_fold, X_val, y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fold(X_fold, y_fold, X_val, y_val, weights_file):\n",
    "    model = build_unet2()\n",
    "        \n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=5, verbose=1),\n",
    "        ReduceLROnPlateau(patience=3, verbose=1),\n",
    "        ModelCheckpoint(weights_file, verbose=1, save_best_only=True)\n",
    "    ]\n",
    "        \n",
    "    data_gen_args = dict(\n",
    "        width_shift_range=0.25,\n",
    "        height_shift_range=0.25,\n",
    "        fill_mode='reflect',\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.1\n",
    "    )\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    \n",
    "    seed = 1\n",
    "    image_datagen.fit(X_fold, augment=True, seed=seed)\n",
    "    mask_datagen.fit(y_fold, augment=True, seed=seed)\n",
    "\n",
    "    image_generator = image_datagen.flow(X_fold, batch_size=32, seed=seed)\n",
    "    mask_generator = mask_datagen.flow(y_fold, batch_size=32, seed=seed)    \n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "    results = model.fit_generator(\n",
    "        train_generator, \n",
    "        epochs=100, \n",
    "        steps_per_epoch=len(X_fold)//32,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=(X_val, y_val))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running fold  0\n",
      "Epoch 1/100\n",
      "99/99 [==============================] - 14s 145ms/step - loss: 0.4709 - val_loss: 0.5322\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.53224, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 9s 89ms/step - loss: 0.3581 - val_loss: 0.6880\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.3263 - val_loss: 0.3258\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.53224 to 0.32583, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.3088 - val_loss: 0.3212\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.32583 to 0.32116, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.2940 - val_loss: 0.3338\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.2823 - val_loss: 0.2925\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.32116 to 0.29251, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.2555 - val_loss: 0.3812\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.2718 - val_loss: 0.3191\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 9s 88ms/step - loss: 0.2707 - val_loss: 0.4181\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.2449 - val_loss: 0.2570\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.29251 to 0.25703, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 9s 90ms/step - loss: 0.2382 - val_loss: 0.2397\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.25703 to 0.23975, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 9s 89ms/step - loss: 0.2358 - val_loss: 0.5922\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.2302 - val_loss: 0.2202\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.23975 to 0.22018, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 9s 89ms/step - loss: 0.2279 - val_loss: 0.1932\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.22018 to 0.19321, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.2151 - val_loss: 0.1870\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.19321 to 0.18701, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 9s 91ms/step - loss: 0.2134 - val_loss: 0.2466\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.2063 - val_loss: 0.2235\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.2194 - val_loss: 0.2055\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 9s 88ms/step - loss: 0.2070 - val_loss: 0.1707\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.18701 to 0.17071, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 9s 89ms/step - loss: 0.2214 - val_loss: 0.2019\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.2128 - val_loss: 0.1998\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 9s 88ms/step - loss: 0.1956 - val_loss: 0.2139\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 9s 88ms/step - loss: 0.1975 - val_loss: 0.1830\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 9s 88ms/step - loss: 0.1878 - val_loss: 0.1419\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.17071 to 0.14195, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 9s 89ms/step - loss: 0.1674 - val_loss: 0.1408\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.14195 to 0.14079, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 9s 88ms/step - loss: 0.1690 - val_loss: 0.1398\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.14079 to 0.13975, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 9s 89ms/step - loss: 0.1726 - val_loss: 0.1398\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.1680 - val_loss: 0.1379\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.13975 to 0.13787, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 9s 90ms/step - loss: 0.1645 - val_loss: 0.1367\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.13787 to 0.13672, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 9s 89ms/step - loss: 0.1677 - val_loss: 0.1364\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.13672 to 0.13636, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 9s 89ms/step - loss: 0.1628 - val_loss: 0.1370\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 9s 88ms/step - loss: 0.1711 - val_loss: 0.1359\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.13636 to 0.13588, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 9s 89ms/step - loss: 0.1638 - val_loss: 0.1343\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.13588 to 0.13432, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 9s 88ms/step - loss: 0.1556 - val_loss: 0.1339\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.13432 to 0.13395, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 9s 88ms/step - loss: 0.1651 - val_loss: 0.1359\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 9s 86ms/step - loss: 0.1542 - val_loss: 0.1336\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.13395 to 0.13359, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 9s 88ms/step - loss: 0.1577 - val_loss: 0.1349\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.1560 - val_loss: 0.1354\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 9s 86ms/step - loss: 0.1585 - val_loss: 0.1304\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.13359 to 0.13040, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.1486 - val_loss: 0.1346\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.1547 - val_loss: 0.1292\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.13040 to 0.12918, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 9s 90ms/step - loss: 0.1472 - val_loss: 0.1305\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 9s 86ms/step - loss: 0.1551 - val_loss: 0.1271\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.12918 to 0.12713, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.1558 - val_loss: 0.1327\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 9s 86ms/step - loss: 0.1536 - val_loss: 0.1308\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 9s 86ms/step - loss: 0.1482 - val_loss: 0.1295\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.1488 - val_loss: 0.1305\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.1413 - val_loss: 0.1297\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 00048: early stopping\n",
      "810/810 [==============================] - 1s 2ms/step\n",
      "810/810 [==============================] - 1s 1ms/step\n",
      "18000/18000 [==============================] - 16s 876us/step\n",
      "0.5 0.7741975308641975\n",
      "running fold  1\n",
      "Epoch 1/100\n",
      "99/99 [==============================] - 14s 140ms/step - loss: 0.4355 - val_loss: 0.4259\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42592, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.3425 - val_loss: 0.8598\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: 0.3223 - val_loss: 0.5652\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.2843 - val_loss: 0.2844\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.42592 to 0.28442, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.2690 - val_loss: 0.3835\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2568 - val_loss: 0.2886\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 9s 86ms/step - loss: 0.2493 - val_loss: 0.3534\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2509 - val_loss: 0.3708\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2153 - val_loss: 0.1787\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.28442 to 0.17868, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2031 - val_loss: 0.1828\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.2024 - val_loss: 0.1762\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.17868 to 0.17622, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1966 - val_loss: 0.1731\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.17622 to 0.17315, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.2020 - val_loss: 0.1780\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1914 - val_loss: 0.1752\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1898 - val_loss: 0.1715\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.17315 to 0.17153, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1861 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.17153 to 0.17018, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 8s 86ms/step - loss: 0.1838 - val_loss: 0.1675\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.17018 to 0.16753, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1886 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1832 - val_loss: 0.1658\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.16753 to 0.16581, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1732 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1835 - val_loss: 0.1657\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.16581 to 0.16565, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1745 - val_loss: 0.1633\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.16565 to 0.16331, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1756 - val_loss: 0.1617\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.16331 to 0.16171, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1778 - val_loss: 0.1641\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1670 - val_loss: 0.1632\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1739 - val_loss: 0.1624\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1680 - val_loss: 0.1566\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.16171 to 0.15659, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1731 - val_loss: 0.1598\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1715 - val_loss: 0.1512\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.15659 to 0.15119, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1668 - val_loss: 0.1496\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.15119 to 0.14960, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1628 - val_loss: 0.1549\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1635 - val_loss: 0.1493\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.14960 to 0.14933, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1652 - val_loss: 0.1501\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1569 - val_loss: 0.1466\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.14933 to 0.14664, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 9s 86ms/step - loss: 0.1606 - val_loss: 0.1551\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1644 - val_loss: 0.1438\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.14664 to 0.14377, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1649 - val_loss: 0.1547\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1600 - val_loss: 0.1535\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1522 - val_loss: 0.1543\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1629 - val_loss: 0.1418\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.14377 to 0.14176, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1459 - val_loss: 0.1423\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1580 - val_loss: 0.1523\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1511 - val_loss: 0.1507\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1551 - val_loss: 0.1485\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1517 - val_loss: 0.1405\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.14176 to 0.14050, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1449 - val_loss: 0.1411\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1437 - val_loss: 0.1414\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1475 - val_loss: 0.1390\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.14050 to 0.13904, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1385 - val_loss: 0.1386\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.13904 to 0.13859, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 8s 86ms/step - loss: 0.1378 - val_loss: 0.1394\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n",
      "Epoch 51/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1461 - val_loss: 0.1373\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.13859 to 0.13729, saving model to model-tgs-salt-fold1.h5\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1448 - val_loss: 0.1380\n",
      "\n",
      "Epoch 00052: val_loss did not improve\n",
      "Epoch 53/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1343 - val_loss: 0.1385\n",
      "\n",
      "Epoch 00053: val_loss did not improve\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1424 - val_loss: 0.1393\n",
      "\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1502 - val_loss: 0.1384\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1369 - val_loss: 0.1379\n",
      "\n",
      "Epoch 00056: val_loss did not improve\n",
      "Epoch 00056: early stopping\n",
      "804/804 [==============================] - 1s 2ms/step\n",
      "804/804 [==============================] - 1s 2ms/step\n",
      "18000/18000 [==============================] - 15s 843us/step\n",
      "0.5555555555555556 0.7567164179104477\n",
      "running fold  2\n",
      "Epoch 1/100\n",
      "99/99 [==============================] - 14s 146ms/step - loss: 0.4212 - val_loss: 0.3832\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.38322, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.3339 - val_loss: 0.3226\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.38322 to 0.32256, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.3191 - val_loss: 0.3657\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.3037 - val_loss: 0.2980\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.32256 to 0.29801, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2909 - val_loss: 0.2803\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.29801 to 0.28033, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 9s 86ms/step - loss: 0.2744 - val_loss: 0.2583\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.28033 to 0.25832, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 9s 86ms/step - loss: 0.2667 - val_loss: 0.2566\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.25832 to 0.25664, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2483 - val_loss: 0.2646\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2446 - val_loss: 0.5987\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2601 - val_loss: 0.3038\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2261 - val_loss: 0.2377\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.25664 to 0.23770, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2187 - val_loss: 0.2203\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.23770 to 0.22033, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2214 - val_loss: 0.3245\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2170 - val_loss: 0.2099\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.22033 to 0.20993, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2191 - val_loss: 0.2107\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2151 - val_loss: 0.1883\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.20993 to 0.18833, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2181 - val_loss: 0.2420\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1954 - val_loss: 0.1857\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.18833 to 0.18566, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2026 - val_loss: 0.1579\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.18566 to 0.15787, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1879 - val_loss: 0.3036\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.2115 - val_loss: 0.2456\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.2009 - val_loss: 0.1829\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1931 - val_loss: 0.1941\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 8s 86ms/step - loss: 0.1770 - val_loss: 0.1513\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.15787 to 0.15133, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1632 - val_loss: 0.1483\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.15133 to 0.14827, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1630 - val_loss: 0.1415\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.14827 to 0.14149, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.1584 - val_loss: 0.1427\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1544 - val_loss: 0.1421\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.1549 - val_loss: 0.1422\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.1519 - val_loss: 0.1431\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: 0.1682 - val_loss: 0.1453\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 00031: early stopping\n",
      "811/811 [==============================] - 2s 2ms/step\n",
      "811/811 [==============================] - 2s 2ms/step\n",
      "18000/18000 [==============================] - 15s 846us/step\n",
      "0.5555555555555556 0.7831072749691739\n",
      "running fold  3\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 0.4502 - val_loss: 0.7780\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.77802, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.3515 - val_loss: 0.4083\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.77802 to 0.40830, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.3264 - val_loss: 0.3770\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.40830 to 0.37700, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.2964 - val_loss: 0.4432\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.3002 - val_loss: 0.2395\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.37700 to 0.23953, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.2803 - val_loss: 0.2849\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.2626 - val_loss: 0.2450\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.2651 - val_loss: 0.3130\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.2525 - val_loss: 0.3175\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.2346 - val_loss: 0.1743\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.23953 to 0.17429, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.2232 - val_loss: 0.1742\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.17429 to 0.17425, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.2120 - val_loss: 0.1690\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.17425 to 0.16900, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.2069 - val_loss: 0.1643\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.16900 to 0.16435, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.2070 - val_loss: 0.1589\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.16435 to 0.15887, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.1974 - val_loss: 0.1579\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.15887 to 0.15795, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.2076 - val_loss: 0.1588\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.2061 - val_loss: 0.1576\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.15795 to 0.15764, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.2077 - val_loss: 0.1512\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.15764 to 0.15119, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1981 - val_loss: 0.1511\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.15119 to 0.15113, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.2040 - val_loss: 0.1512\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1920 - val_loss: 0.1510\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.15113 to 0.15101, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.1943 - val_loss: 0.1483\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.15101 to 0.14827, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1864 - val_loss: 0.1474\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.14827 to 0.14736, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.1924 - val_loss: 0.1535\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.1847 - val_loss: 0.1397\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.14736 to 0.13969, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.1872 - val_loss: 0.1414\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.1896 - val_loss: 0.1431\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.1895 - val_loss: 0.1412\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.1755 - val_loss: 0.1407\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1752 - val_loss: 0.1361\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.13969 to 0.13612, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.1787 - val_loss: 0.1348\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.13612 to 0.13480, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.1750 - val_loss: 0.1357\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.1763 - val_loss: 0.1344\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.13480 to 0.13441, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1768 - val_loss: 0.1331\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.13441 to 0.13315, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1724 - val_loss: 0.1338\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.1728 - val_loss: 0.1339\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.1744 - val_loss: 0.1325\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.13315 to 0.13250, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1695 - val_loss: 0.1327\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.1819 - val_loss: 0.1323\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.13250 to 0.13234, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1729 - val_loss: 0.1315\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.13234 to 0.13151, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.1714 - val_loss: 0.1331\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.1742 - val_loss: 0.1333\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1717 - val_loss: 0.1342\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.1745 - val_loss: 0.1336\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.1817 - val_loss: 0.1336\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 00045: early stopping\n",
      "790/790 [==============================] - 2s 3ms/step\n",
      "790/790 [==============================] - 2s 3ms/step\n",
      "18000/18000 [==============================] - 15s 855us/step\n",
      "0.5 0.7260759493670887\n",
      "running fold  4\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.4487 - val_loss: 0.4204\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42036, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.3417 - val_loss: 1.0833\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.3180 - val_loss: 0.5724\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.2958 - val_loss: 0.3398\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.42036 to 0.33983, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.2883 - val_loss: 0.2723\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.33983 to 0.27231, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.2595 - val_loss: 0.3447\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.2613 - val_loss: 0.2641\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.27231 to 0.26411, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.2623 - val_loss: 0.2162\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.26411 to 0.21618, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.2471 - val_loss: 0.2586\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.2381 - val_loss: 0.2489\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.2283 - val_loss: 0.2456\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.2309 - val_loss: 0.2362\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.2096 - val_loss: 0.1776\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.21618 to 0.17763, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.2006 - val_loss: 0.1737\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.17763 to 0.17368, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.1985 - val_loss: 0.1674\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.17368 to 0.16742, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.1915 - val_loss: 0.1697\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.1942 - val_loss: 0.1631\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.16742 to 0.16306, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.1895 - val_loss: 0.1638\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1867 - val_loss: 0.1624\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.16306 to 0.16235, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.1748 - val_loss: 0.1613\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.16235 to 0.16134, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.1868 - val_loss: 0.1600\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.16134 to 0.16001, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1834 - val_loss: 0.1618\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.1713 - val_loss: 0.1604\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.1828 - val_loss: 0.1575\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.16001 to 0.15747, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.1799 - val_loss: 0.1650\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1760 - val_loss: 0.1589\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.1759 - val_loss: 0.1555\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.15747 to 0.15548, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.1650 - val_loss: 0.1611\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.1748 - val_loss: 0.1552\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.15548 to 0.15517, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1632 - val_loss: 0.1535\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.15517 to 0.15349, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1813 - val_loss: 0.1508\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.15349 to 0.15084, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 9s 89ms/step - loss: 0.1659 - val_loss: 0.1542\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1651 - val_loss: 0.1507\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.15084 to 0.15074, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.1607 - val_loss: 0.1500\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.15074 to 0.14997, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1661 - val_loss: 0.1468\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.14997 to 0.14681, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.1633 - val_loss: 0.1497\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.1614 - val_loss: 0.1508\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1618 - val_loss: 0.1586\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.1637 - val_loss: 0.1490\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1515 - val_loss: 0.1487\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 00040: early stopping\n",
      "785/785 [==============================] - 2s 3ms/step\n",
      "785/785 [==============================] - 2s 3ms/step\n",
      "18000/18000 [==============================] - 15s 843us/step\n",
      "0.6111111111111112 0.7337579617834394\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in range(5):\n",
    "    print('running fold ', fold)\n",
    "    X_fold, y_fold, X_val, y_val = load_fold(X_train, y_train, fold)\n",
    "    weights_file = f\"model-tgs-salt-fold{fold}.h5\"    \n",
    "    \n",
    "    run_fold(X_fold, y_fold, X_val, y_val, weights_file)\n",
    "    \n",
    "    model = build_unet2()\n",
    "    model.load_weights(weights_file)\n",
    "    model.evaluate(X_val, y_val, verbose=1)\n",
    "    \n",
    "    preds_val = model.predict(X_val, verbose=1)\n",
    "    preds_test = model.predict(X_test, verbose=1)\n",
    "    \n",
    "    thres = np.linspace(0.5, 1.0, 10)\n",
    "    thres_ioc = [iou_metric_batch(y_val, np.int32(preds_val > t)) for t in thres]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(thres, thres_ioc);\n",
    "    best_thres = thres[np.argmax(thres_ioc)]\n",
    "    print(best_thres, max(thres_ioc))\n",
    "    \n",
    "    preds = preds_test > best_thres # threshold\n",
    "    np.save(f\"preds_fold{fold}\", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros_like(X_test)\n",
    "for fold in range(5):\n",
    "    p = np.load('preds_fold%s.npy' % fold)\n",
    "    preds += p\n",
    "preds /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18000 [00:00<?, ?it/s]/opt/miniconda2/envs/avito/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "100%|| 18000/18000 [00:15<00:00, 1160.20it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_ = []\n",
    "for i in tqdm(range(len(preds_test))):\n",
    "    preds_.append(resize(np.squeeze(preds[i]), (101, 101), mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RLenc(img, order='F', format=True):\n",
    "    \"\"\"\n",
    "    img is binary mask image, shape (r,c)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
    "\n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []  ## list of run lengths\n",
    "    r = 0  ## the current run length\n",
    "    pos = 1  ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if (c == 0):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    # if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "\n",
    "    if format:\n",
    "        z = ''\n",
    "\n",
    "        for rr in runs:\n",
    "            z += '{} {} '.format(rr[0], rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = []\n",
    "for image_id, p in zip(test_ids, preds_):\n",
    "    rows.append([image_id, RLenc(np.round(p))])\n",
    "    \n",
    "sub = pd.DataFrame(rows, columns=['id', 'rle_mask'])\n",
    "sub.to_csv('submissions/subm_006.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
