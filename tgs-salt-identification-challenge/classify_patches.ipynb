{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import SpatialDropout2D, Activation\n",
    "from keras.layers import MaxPooling2D, UpSampling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "        \n",
    "PATH = 'input'\n",
    "\n",
    "sample_df = pd.read_csv('input/sample_submission.csv')\n",
    "test_ids = sample_df.id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "FOLDS_CSV = os.path.join(PATH, 'folds.csv')\n",
    "def generate_folds():\n",
    "    n_fold = 5\n",
    "    depths = pd.read_csv(os.path.join(PATH, 'depths.csv'))\n",
    "    depths.sort_values('z', inplace=True)\n",
    "    depths.drop('z', axis=1, inplace=True)\n",
    "    depths['fold'] = (list(range(n_fold))*depths.shape[0])[:depths.shape[0]]\n",
    "    print(depths.head())\n",
    "    depths.to_csv(FOLDS_CSV, index=False)\n",
    "\n",
    "if not os.path.exists(FOLDS_CSV):\n",
    "    generate_folds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = 128\n",
    "im_height = 128\n",
    "im_chan = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('input/X_train2.npy')\n",
    "y_train = np.load('input/y_train2.npy')\n",
    "X_test = np.load('input/X_test2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import six\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Flatten\n",
    ")\n",
    "from keras.layers.convolutional import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D\n",
    ")\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
    "                          kernel_size=(1, 1),\n",
    "                          strides=(stride_width, stride_height),\n",
    "                          padding=\"valid\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(input)\n",
    "\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            input = block_function(filters=filters, init_strides=init_strides,\n",
    "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=init_strides,\n",
    "                           padding=\"same\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "                                  strides=init_strides)(input)\n",
    "\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "\n",
    "    Returns:\n",
    "        A final conv layer of filters * 4\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
    "                              strides=init_strides,\n",
    "                              padding=\"same\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
    "                                     strides=init_strides)(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
    "                The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.\n",
    "                At each block unit, the number of filters are doubled and the input size is halved\n",
    "\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "        _handle_dim_ordering()\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "                                 strides=(1, 1))(block)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(units=1, kernel_initializer=\"he_normal\",\n",
    "                      activation=\"sigmoid\")(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fold(X_train, y_train, fold):\n",
    "    train_df = pd.read_csv(os.path.join(PATH, 'train.csv'))\n",
    "    train_ids = train_df.id.values\n",
    "    \n",
    "    folds = pd.read_csv(FOLDS_CSV)\n",
    "    fold_dict = folds.set_index('id').to_dict()['fold']\n",
    "    \n",
    "    fold_train = [fold_dict[x]!=fold for x in train_ids]\n",
    "    fold_val = [fold_dict[x]==fold for x in train_ids]\n",
    "    \n",
    "    X_fold, y_fold = X_train[fold_train], y_train[fold_train]    \n",
    "    X_val, y_val = X_train[fold_val], y_train[fold_val]    \n",
    "    return X_fold, y_fold, X_val, y_val\n",
    "\n",
    "def split_patches(X, y):\n",
    "    X_patches = []\n",
    "    y_patches = []\n",
    "    for idx in tqdm(range(X.shape[0])):\n",
    "        for j in range(0, 128-32+1, 16):\n",
    "            for i in range(0, 128-32+1, 16):\n",
    "                x = X[idx, j:j+32, i:i+32]\n",
    "                X_patches.append(x)\n",
    "                y_patches.append(np.sum(y[idx, j:j+32, i:i+32]) > 32*32*0.5)\n",
    "    return np.array(X_patches), np.array(y_patches)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "def run_fold(X_fold, y_fold, X_val, y_val, weights_file):\n",
    "    print(X_fold.shape, y_fold.shape, X_val.shape, y_val.shape)\n",
    "    model = ResnetBuilder().build_resnet_34((1, 32, 32), 1)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=5, verbose=1),\n",
    "        ReduceLROnPlateau(patience=3, verbose=1),\n",
    "        ModelCheckpoint(weights_file, verbose=1, save_best_only=True)\n",
    "    ]\n",
    "        \n",
    "    data_gen_args = dict(\n",
    "        #width_shift_range=0.25,\n",
    "        #height_shift_range=0.25,\n",
    "        fill_mode='reflect',\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        #zoom_range=0.1\n",
    "    )\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    \n",
    "    seed = 1\n",
    "    image_datagen.fit(X_fold, augment=True, seed=seed)\n",
    "\n",
    "    image_generator = image_datagen.flow(X_fold, y_fold, batch_size=128, seed=seed)    \n",
    "    \n",
    "    #results = model.fit(X_fold, y_fold,\n",
    "    #                    epochs=10,\n",
    "    #                    validation_split=0.1)\n",
    "\n",
    "    results = model.fit_generator(\n",
    "        image_generator, \n",
    "        epochs=50, \n",
    "        verbose=2,\n",
    "        steps_per_epoch=len(X_fold)//128,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=(X_val, y_val))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18000/18000 [00:15<00:00, 1130.05it/s]\n",
      "  0%|          | 0/3190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running fold  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3190/3190 [00:02<00:00, 1160.43it/s]\n",
      "100%|██████████| 810/810 [00:00<00:00, 1252.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156310, 32, 32, 1) (156310, 1) (39690, 32, 32, 1) (39690, 1)\n",
      "Epoch 1/50\n",
      " - 96s - loss: 0.5580 - acc: 0.8767 - val_loss: 0.3411 - val_acc: 0.8967\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.34112, saving model to model-patches-fold0.h5\n",
      "Epoch 2/50\n",
      " - 83s - loss: 0.3185 - acc: 0.8950 - val_loss: 0.2788 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.34112 to 0.27879, saving model to model-patches-fold0.h5\n",
      "Epoch 3/50\n",
      " - 83s - loss: 0.2861 - acc: 0.9022 - val_loss: 0.2529 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.27879 to 0.25292, saving model to model-patches-fold0.h5\n",
      "Epoch 4/50\n",
      " - 83s - loss: 0.2737 - acc: 0.9059 - val_loss: 0.2396 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.25292 to 0.23956, saving model to model-patches-fold0.h5\n",
      "Epoch 5/50\n",
      " - 83s - loss: 0.2682 - acc: 0.9077 - val_loss: 0.3276 - val_acc: 0.8816\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/50\n",
      " - 83s - loss: 0.2583 - acc: 0.9113 - val_loss: 0.2439 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/50\n",
      " - 83s - loss: 0.2503 - acc: 0.9141 - val_loss: 0.3302 - val_acc: 0.8942\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/50\n",
      " - 83s - loss: 0.2473 - acc: 0.9148 - val_loss: 0.2672 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/50\n",
      " - 82s - loss: 0.2130 - acc: 0.9269 - val_loss: 0.1997 - val_acc: 0.9334\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.23956 to 0.19967, saving model to model-patches-fold0.h5\n",
      "Epoch 10/50\n",
      " - 82s - loss: 0.2063 - acc: 0.9291 - val_loss: 0.1939 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.19967 to 0.19389, saving model to model-patches-fold0.h5\n",
      "Epoch 11/50\n",
      " - 82s - loss: 0.2009 - acc: 0.9308 - val_loss: 0.1992 - val_acc: 0.9317\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/50\n",
      " - 82s - loss: 0.1976 - acc: 0.9319 - val_loss: 0.1977 - val_acc: 0.9346\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/50\n",
      " - 82s - loss: 0.1952 - acc: 0.9327 - val_loss: 0.2140 - val_acc: 0.9245\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/50\n",
      " - 82s - loss: 0.1928 - acc: 0.9338 - val_loss: 0.1902 - val_acc: 0.9359\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.19389 to 0.19022, saving model to model-patches-fold0.h5\n",
      "Epoch 15/50\n",
      " - 82s - loss: 0.1892 - acc: 0.9351 - val_loss: 0.1927 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/50\n",
      " - 82s - loss: 0.1876 - acc: 0.9355 - val_loss: 0.1907 - val_acc: 0.9358\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/50\n",
      " - 82s - loss: 0.1858 - acc: 0.9359 - val_loss: 0.1894 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.19022 to 0.18941, saving model to model-patches-fold0.h5\n",
      "Epoch 18/50\n",
      " - 82s - loss: 0.1838 - acc: 0.9364 - val_loss: 0.1868 - val_acc: 0.9372\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.18941 to 0.18680, saving model to model-patches-fold0.h5\n",
      "Epoch 19/50\n",
      " - 82s - loss: 0.1823 - acc: 0.9369 - val_loss: 0.2013 - val_acc: 0.9323\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/50\n",
      " - 82s - loss: 0.1801 - acc: 0.9377 - val_loss: 0.2099 - val_acc: 0.9274\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/50\n",
      " - 82s - loss: 0.1786 - acc: 0.9382 - val_loss: 0.1861 - val_acc: 0.9363\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.18680 to 0.18611, saving model to model-patches-fold0.h5\n",
      "Epoch 22/50\n",
      " - 82s - loss: 0.1774 - acc: 0.9387 - val_loss: 0.1947 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/50\n",
      " - 82s - loss: 0.1756 - acc: 0.9391 - val_loss: 0.1861 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.18611 to 0.18606, saving model to model-patches-fold0.h5\n",
      "Epoch 24/50\n",
      " - 82s - loss: 0.1742 - acc: 0.9400 - val_loss: 0.1903 - val_acc: 0.9370\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/50\n",
      " - 83s - loss: 0.1716 - acc: 0.9407 - val_loss: 0.1889 - val_acc: 0.9359\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/50\n",
      " - 82s - loss: 0.1635 - acc: 0.9439 - val_loss: 0.1889 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/50\n",
      " - 82s - loss: 0.1607 - acc: 0.9448 - val_loss: 0.1904 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/50\n",
      " - 82s - loss: 0.1596 - acc: 0.9458 - val_loss: 0.1904 - val_acc: 0.9372\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 00028: early stopping\n",
      "39690/39690 [==============================] - 8s 211us/step\n",
      "882000/882000 [==============================] - 123s 139us/step\n",
      "running fold  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3196/3196 [00:02<00:00, 1183.98it/s]\n",
      "100%|██████████| 804/804 [00:00<00:00, 1166.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156604, 32, 32, 1) (156604, 1) (39396, 32, 32, 1) (39396, 1)\n",
      "Epoch 1/50\n",
      " - 98s - loss: 0.5568 - acc: 0.8814 - val_loss: 0.3551 - val_acc: 0.8897\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35506, saving model to model-patches-fold1.h5\n",
      "Epoch 2/50\n",
      " - 83s - loss: 0.3150 - acc: 0.8965 - val_loss: 0.3015 - val_acc: 0.9006\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.35506 to 0.30152, saving model to model-patches-fold1.h5\n",
      "Epoch 3/50\n",
      " - 83s - loss: 0.2816 - acc: 0.9048 - val_loss: 0.2754 - val_acc: 0.9054\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.30152 to 0.27541, saving model to model-patches-fold1.h5\n",
      "Epoch 4/50\n",
      " - 83s - loss: 0.2750 - acc: 0.9062 - val_loss: 0.2948 - val_acc: 0.8991\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/50\n",
      " - 84s - loss: 0.2644 - acc: 0.9103 - val_loss: 0.2634 - val_acc: 0.9138\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.27541 to 0.26340, saving model to model-patches-fold1.h5\n",
      "Epoch 6/50\n",
      " - 83s - loss: 0.2544 - acc: 0.9132 - val_loss: 0.2848 - val_acc: 0.8965\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/50\n",
      " - 83s - loss: 0.2490 - acc: 0.9155 - val_loss: 0.2517 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.26340 to 0.25174, saving model to model-patches-fold1.h5\n",
      "Epoch 8/50\n",
      " - 83s - loss: 0.2431 - acc: 0.9170 - val_loss: 0.2845 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/50\n",
      " - 84s - loss: 0.2379 - acc: 0.9179 - val_loss: 0.3929 - val_acc: 0.8748\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/50\n",
      " - 83s - loss: 0.2331 - acc: 0.9199 - val_loss: 0.2815 - val_acc: 0.9027\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/50\n",
      " - 83s - loss: 0.2314 - acc: 0.9204 - val_loss: 0.3202 - val_acc: 0.8950\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/50\n",
      " - 83s - loss: 0.2063 - acc: 0.9297 - val_loss: 0.2125 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.25174 to 0.21246, saving model to model-patches-fold1.h5\n",
      "Epoch 13/50\n",
      " - 83s - loss: 0.1967 - acc: 0.9327 - val_loss: 0.2052 - val_acc: 0.9323\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.21246 to 0.20521, saving model to model-patches-fold1.h5\n",
      "Epoch 14/50\n",
      " - 84s - loss: 0.1929 - acc: 0.9338 - val_loss: 0.2062 - val_acc: 0.9327\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/50\n",
      " - 83s - loss: 0.1904 - acc: 0.9342 - val_loss: 0.2069 - val_acc: 0.9323\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/50\n",
      " - 83s - loss: 0.1874 - acc: 0.9355 - val_loss: 0.2033 - val_acc: 0.9337\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.20521 to 0.20332, saving model to model-patches-fold1.h5\n",
      "Epoch 17/50\n",
      " - 83s - loss: 0.1848 - acc: 0.9364 - val_loss: 0.2129 - val_acc: 0.9317\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/50\n",
      " - 83s - loss: 0.1832 - acc: 0.9366 - val_loss: 0.2010 - val_acc: 0.9335\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.20332 to 0.20098, saving model to model-patches-fold1.h5\n",
      "Epoch 19/50\n",
      " - 83s - loss: 0.1817 - acc: 0.9367 - val_loss: 0.2020 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/50\n",
      " - 83s - loss: 0.1792 - acc: 0.9382 - val_loss: 0.2019 - val_acc: 0.9315\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/50\n",
      " - 83s - loss: 0.1783 - acc: 0.9376 - val_loss: 0.2049 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/50\n",
      " - 83s - loss: 0.1759 - acc: 0.9389 - val_loss: 0.2038 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/50\n",
      " - 83s - loss: 0.1711 - acc: 0.9409 - val_loss: 0.1981 - val_acc: 0.9359\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.20098 to 0.19807, saving model to model-patches-fold1.h5\n",
      "Epoch 24/50\n",
      " - 83s - loss: 0.1697 - acc: 0.9412 - val_loss: 0.1965 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.19807 to 0.19650, saving model to model-patches-fold1.h5\n",
      "Epoch 25/50\n",
      " - 83s - loss: 0.1681 - acc: 0.9420 - val_loss: 0.1982 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/50\n",
      " - 83s - loss: 0.1688 - acc: 0.9411 - val_loss: 0.1988 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/50\n",
      " - 83s - loss: 0.1676 - acc: 0.9419 - val_loss: 0.1987 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/50\n",
      " - 83s - loss: 0.1668 - acc: 0.9419 - val_loss: 0.1990 - val_acc: 0.9355\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/50\n",
      " - 83s - loss: 0.1663 - acc: 0.9423 - val_loss: 0.1979 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 00029: early stopping\n",
      "39396/39396 [==============================] - 9s 223us/step\n",
      "882000/882000 [==============================] - 125s 142us/step\n",
      "running fold  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [00:02<00:00, 1148.37it/s]\n",
      "100%|██████████| 811/811 [00:00<00:00, 1161.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156261, 32, 32, 1) (156261, 1) (39739, 32, 32, 1) (39739, 1)\n",
      "Epoch 1/50\n",
      " - 100s - loss: 0.5567 - acc: 0.8820 - val_loss: 0.3964 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39636, saving model to model-patches-fold2.h5\n",
      "Epoch 2/50\n",
      " - 85s - loss: 0.3148 - acc: 0.8981 - val_loss: 0.3166 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.39636 to 0.31663, saving model to model-patches-fold2.h5\n",
      "Epoch 3/50\n",
      " - 84s - loss: 0.2794 - acc: 0.9053 - val_loss: 0.3322 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/50\n",
      " - 85s - loss: 0.2713 - acc: 0.9080 - val_loss: 0.3068 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.31663 to 0.30676, saving model to model-patches-fold2.h5\n",
      "Epoch 5/50\n",
      " - 85s - loss: 0.2621 - acc: 0.9111 - val_loss: 0.2803 - val_acc: 0.9028\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.30676 to 0.28035, saving model to model-patches-fold2.h5\n",
      "Epoch 6/50\n",
      " - 84s - loss: 0.2531 - acc: 0.9149 - val_loss: 0.2977 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/50\n",
      " - 85s - loss: 0.2458 - acc: 0.9165 - val_loss: 0.3161 - val_acc: 0.8908\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/50\n",
      " - 84s - loss: 0.2414 - acc: 0.9174 - val_loss: 0.2539 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.28035 to 0.25386, saving model to model-patches-fold2.h5\n",
      "Epoch 9/50\n",
      " - 84s - loss: 0.2370 - acc: 0.9191 - val_loss: 0.3015 - val_acc: 0.8989\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/50\n",
      " - 84s - loss: 0.2329 - acc: 0.9206 - val_loss: 0.2876 - val_acc: 0.9023\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/50\n",
      " - 84s - loss: 0.2287 - acc: 0.9225 - val_loss: 0.3116 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/50\n",
      " - 84s - loss: 0.2262 - acc: 0.9227 - val_loss: 0.3499 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/50\n",
      " - 84s - loss: 0.1984 - acc: 0.9334 - val_loss: 0.2196 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.25386 to 0.21964, saving model to model-patches-fold2.h5\n",
      "Epoch 14/50\n",
      " - 84s - loss: 0.1912 - acc: 0.9352 - val_loss: 0.2094 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.21964 to 0.20942, saving model to model-patches-fold2.h5\n",
      "Epoch 15/50\n"
     ]
    }
   ],
   "source": [
    "def stitch_patches(X_patches):\n",
    "    images = X_patches.shape[0] // 49 # TODO\n",
    "    out = np.zeros((images, 128, 128), dtype=np.float32)\n",
    "    patch_idx = 0\n",
    "    for image_idx in range(out.shape[0]): \n",
    "        for j in range(0, 128-32+1, 16):\n",
    "            for i in range(0, 128-32+1, 16):\n",
    "                out[image_idx, j:j+32, i:i+32] += X_patches[patch_idx]\n",
    "                patch_idx += 1\n",
    "    return out/4.0\n",
    "\n",
    "def debug_predict(X,):\n",
    "    x_patches, y_patches = split_patches(X[:, :, :, 0].reshape(-1, 128, 128), y[:, :, :, 0].reshape(-1, 128, 128))\n",
    "    x_pred = model.predict(x_patches.reshape(-1, 32, 32, 1), verbose=1)\n",
    "    x_out = stitch_patches(x_pred)\n",
    "    return x_out\n",
    "\n",
    "X_test_patches, _ = split_patches(X_test, X_test)\n",
    "\n",
    "for fold in range(5):\n",
    "    print('running fold ', fold)    \n",
    "    X_fold, y_fold, X_val, y_val = load_fold(X_train, y_train, fold)\n",
    "    \n",
    "    X_fold_patches, y_fold_patches = split_patches(X_fold, y_fold)\n",
    "    X_val_patches, y_val_patches = split_patches(X_val, y_val)\n",
    "    \n",
    "    weights_file = f\"model-patches-fold{fold}.h5\"    \n",
    "    \n",
    "    model = run_fold(X_fold_patches, y_fold_patches.reshape(-1, 1), X_val_patches, y_val_patches.reshape(-1, 1), weights_file)\n",
    "    #model = ResnetBuilder().build_resnet_34((1, 32, 32), 1)\n",
    "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.load_weights(weights_file)\n",
    "    \n",
    "    val_preds = model.predict(X_val_patches, verbose=1, batch_size=128)\n",
    "    np.save(f\"val_preds_fold{fold}\", val_preds)\n",
    "    \n",
    "    test_preds = model.predict(X_test_patches, verbose=1, batch_size=128)\n",
    "    np.save(f\"test_preds_fold{fold}\", test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 810/810 [00:00<00:00, 1117.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39690/39690 [==============================] - 16s 410us/step\n",
      "[[0.79537904]\n",
      " [0.9590244 ]\n",
      " [0.97290325]\n",
      " ...\n",
      " [0.6141258 ]\n",
      " [0.43407243]\n",
      " [0.0606115 ]]\n"
     ]
    }
   ],
   "source": [
    "#X_fold, y_fold, X_val, y_val = load_fold(X_train, y_train, fold)\n",
    "#X_val_patches, y_val_patches = split_patches(X_val, y_val)\n",
    "\n",
    "def stitch_patches(X_patches):\n",
    "    images = X_patches.shape[0] // 49 # TODO\n",
    "    out = np.zeros((images, 128, 128), dtype=np.float32)\n",
    "    patch_idx = 0\n",
    "    for image_idx in range(out.shape[0]): \n",
    "        for j in range(0, 128-32+1, 16):\n",
    "            for i in range(0, 128-32+1, 16):\n",
    "                out[image_idx, j:j+32, i:i+32] += X_patches[patch_idx]\n",
    "                patch_idx += 1\n",
    "    return out/4.0\n",
    "\n",
    "def debug_predict(X,):\n",
    "    x_patches, y_patches = split_patches(X[:, :, :, 0].reshape(-1, 128, 128), y[:, :, :, 0].reshape(-1, 128, 128))\n",
    "    x_pred = model.predict(x_patches.reshape(-1, 32, 32, 1), verbose=1)\n",
    "    x_out = stitch_patches(x_pred)\n",
    "    return x_out\n",
    "\n",
    "#x_pred = debug_predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for idx in range(10):\n",
    "        plt.figure()\n",
    "        plt.imshow(y_val[idx, :, :, 0])\n",
    "        plt.figure()\n",
    "        x_pred[idx, 0, 0] = 1\n",
    "        plt.imshow(x_pred[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros_like(X_test)\n",
    "for fold in range(5):\n",
    "    p = np.load('preds_fold%s.npy' % fold)\n",
    "    preds += p\n",
    "preds /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18000 [00:00<?, ?it/s]/opt/miniconda2/envs/avito/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "100%|██████████| 18000/18000 [00:15<00:00, 1160.20it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_ = []\n",
    "for i in tqdm(range(len(preds_test))):\n",
    "    preds_.append(resize(np.squeeze(preds[i]), (101, 101), mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold_idx(fold):\n",
    "    train_df = pd.read_csv(os.path.join(PATH, 'train.csv'))\n",
    "    train_ids = train_df.id.values\n",
    "    \n",
    "    folds = pd.read_csv(FOLDS_CSV)\n",
    "    fold_dict = folds.set_index('id').to_dict()['fold']\n",
    "    \n",
    "    fold_train = [ idx for idx, x in enumerate(train_ids) if fold_dict[x]!=fold]\n",
    "    fold_val = [ idx for idx, x in enumerate(train_ids) if fold_dict[x]==fold]\n",
    "    return fold_train, fold_val\n",
    "\n",
    "\n",
    "train_preds = np.zeros((X_train.shape[0], 128, 128), dtype=np.float32)\n",
    "\n",
    "for fold in range(5):\n",
    "    train_idx, val_idx = get_fold_idx(fold)\n",
    "    oof_preds = stitch_patches(np.load(f\"val_preds_fold{fold}.npy\"))\n",
    "    for idx in range(oof_preds.shape[0]):\n",
    "        #x2 = np.zeros((128, 128), dtype=np.float32)\n",
    "        #x2[:97, :97] = \n",
    "        #oof_preds[idx] = x2\n",
    "        oof_preds[idx] = np.pad(oof_preds[idx, 16:-16, 16:-16], ((16, 16), (16, 16)), mode='symmetric')\n",
    "    train_preds[val_idx] = oof_preds\n",
    "\n",
    "train_preds = train_preds.reshape((X_train.shape[0], 128, 128, 1))\n",
    "np.save('data/subm007/X_train3_stage1oof.npy', train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.zeros((X_test.shape[0], 128, 128), dtype=np.float32)\n",
    "\n",
    "for fold in range(5):    \n",
    "    oof_preds = stitch_patches(np.load(f\"test_preds_fold{fold}.npy\"))\n",
    "    for idx in range(oof_preds.shape[0]):\n",
    "        oof_preds[idx] = np.pad(oof_preds[idx, 16:-16, 16:-16], ((16, 16), (16, 16)), mode='symmetric')\n",
    "    test_preds += oof_preds\n",
    "test_preds /= 5.    \n",
    "\n",
    "test_preds = test_preds.reshape((-1, 128, 128, 1))\n",
    "np.save('data/subm007/X_test3_stage1oof.npy', test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc3e0b4deb8>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_preds[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workaround matplotlib rescaling\n",
    "train_preds[:, 50, 50, 0] = 1\n",
    "\n",
    "for i in range(0):\n",
    "    plt.figure()\n",
    "    #plt.imshow(y_train[i, 13:-14, 13:-14, 0])\n",
    "    plt.imshow(y_train[i, ..., 0])\n",
    "    plt.figure()\n",
    "    #plt.imshow(train_preds[i, 13:-14, 13:-14, 0])\n",
    "    plt.imshow(train_preds[i, ..., 0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RLenc(img, order='F', format=True):\n",
    "    \"\"\"\n",
    "    img is binary mask image, shape (r,c)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
    "\n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []  ## list of run lengths\n",
    "    r = 0  ## the current run length\n",
    "    pos = 1  ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if (c == 0):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    # if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "\n",
    "    if format:\n",
    "        z = ''\n",
    "\n",
    "        for rr in runs:\n",
    "            z += '{} {} '.format(rr[0], rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = []\n",
    "for image_id, p in zip(test_ids, preds_):\n",
    "    rows.append([image_id, RLenc(np.round(p))])\n",
    "    \n",
    "sub = pd.DataFrame(rows, columns=['id', 'rle_mask'])\n",
    "sub.to_csv('submissions/subm_006.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
