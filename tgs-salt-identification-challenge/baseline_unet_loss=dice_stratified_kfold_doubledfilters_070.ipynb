{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#filters from 8 to 16\n",
    "\n",
    "#0.9444444444444444 0.7085820895522389, --> 0.8888888888888888 0.7364427860696516\n",
    "#0.9444444444444444 0.698150431565968\n",
    "#0.9444444444444444 0.6929113924050634\n",
    "#0.7222222222222222 0.6810191082802548\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import SpatialDropout2D, Activation\n",
    "from keras.layers import MaxPooling2D, UpSampling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "        \n",
    "PATH = 'input'\n",
    "\n",
    "sample_df = pd.read_csv('input/sample_submission.csv')\n",
    "test_ids = sample_df.id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "FOLDS_CSV = os.path.join(PATH, 'folds.csv')\n",
    "def generate_folds():\n",
    "    n_fold = 5\n",
    "    depths = pd.read_csv(os.path.join(PATH, 'depths.csv'))\n",
    "    depths.sort_values('z', inplace=True)\n",
    "    depths.drop('z', axis=1, inplace=True)\n",
    "    depths['fold'] = (list(range(n_fold))*depths.shape[0])[:depths.shape[0]]\n",
    "    print(depths.head())\n",
    "    depths.to_csv(FOLDS_CSV, index=False)\n",
    "\n",
    "if not os.path.exists(FOLDS_CSV):\n",
    "    generate_folds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = 128\n",
    "im_height = 128\n",
    "im_chan = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('input/X_train_128.npy')\n",
    "y_train = np.load('input/y_train_128.npy')\n",
    "X_test = np.load('input/X_test_128.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def double_conv_layer(x, size, dropout=0.0, batch_norm=True):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 3\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    if dropout > 0:\n",
    "        conv = SpatialDropout2D(dropout)(conv)\n",
    "    return conv\n",
    "\n",
    "def build_unet2(dropout_val=0.2, weights=None):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        inputs = Input((im_height, im_width, im_chan), name='inputs1')\n",
    "        axis = 1\n",
    "    else:\n",
    "        inputs = Input((im_height, im_width, im_chan), name='inputs1')\n",
    "        axis = 3\n",
    "\n",
    "    filters = 16\n",
    "    conv_224 = double_conv_layer(inputs, filters)\n",
    "    pool_112 = MaxPooling2D(pool_size=(2, 2))(conv_224)\n",
    "\n",
    "    conv_112 = double_conv_layer(pool_112, 2*filters)\n",
    "    pool_56 = MaxPooling2D(pool_size=(2, 2))(conv_112)\n",
    "\n",
    "    conv_56 = double_conv_layer(pool_56, 4*filters)\n",
    "    pool_28 = MaxPooling2D(pool_size=(2, 2))(conv_56)\n",
    "\n",
    "    conv_28 = double_conv_layer(pool_28, 8*filters)\n",
    "    pool_14 = MaxPooling2D(pool_size=(2, 2))(conv_28)\n",
    "\n",
    "    conv_14 = double_conv_layer(pool_14, 16*filters)\n",
    "    pool_7 = MaxPooling2D(pool_size=(2, 2))(conv_14)\n",
    "\n",
    "    conv_7 = double_conv_layer(pool_7, 32*filters)\n",
    "\n",
    "    up_14 = concatenate([UpSampling2D(size=(2, 2))(conv_7), conv_14], axis=axis)\n",
    "    up_conv_14 = double_conv_layer(up_14, 16*filters)\n",
    "\n",
    "    up_28 = concatenate([UpSampling2D(size=(2, 2))(up_conv_14), conv_28], axis=axis)\n",
    "    up_conv_28 = double_conv_layer(up_28, 8*filters)\n",
    "\n",
    "    up_56 = concatenate([UpSampling2D(size=(2, 2))(up_conv_28), conv_56], axis=axis)\n",
    "    up_conv_56 = double_conv_layer(up_56, 4*filters)\n",
    "\n",
    "    up_112 = concatenate([UpSampling2D(size=(2, 2))(up_conv_56), conv_112], axis=axis)\n",
    "    up_conv_112 = double_conv_layer(up_112, 2*filters)\n",
    "\n",
    "    up_224 = concatenate([UpSampling2D(size=(2, 2))(up_conv_112), conv_224], axis=axis)\n",
    "    up_conv_224 = double_conv_layer(up_224, filters, dropout_val)\n",
    "\n",
    "    output_mask_channels = 1\n",
    "    conv_final = Conv2D(output_mask_channels, (1, 1))(up_conv_224)\n",
    "    conv_final = Activation('sigmoid')(conv_final)    \n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv_final])\n",
    "    model.compile(optimizer='adam', loss=dice_coef_loss)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fold(X_train, y_train, fold):\n",
    "    train_df = pd.read_csv(os.path.join(PATH, 'train.csv'))\n",
    "    train_ids = train_df.id.values\n",
    "    \n",
    "    folds = pd.read_csv(FOLDS_CSV)\n",
    "    fold_dict = folds.set_index('id').to_dict()['fold']\n",
    "    \n",
    "    fold_train = [fold_dict[x]!=fold for x in train_ids]\n",
    "    fold_val = [fold_dict[x]==fold for x in train_ids]\n",
    "    \n",
    "    X_fold, y_fold = X_train[fold_train], y_train[fold_train]    \n",
    "    X_val, y_val = X_train[fold_val], y_train[fold_val]    \n",
    "    return X_fold, y_fold, X_val, y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fold(X_fold, y_fold, X_val, y_val, weights_file):\n",
    "    model = build_unet2()\n",
    "        \n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=5, verbose=1),\n",
    "        ReduceLROnPlateau(patience=3, verbose=1),\n",
    "        ModelCheckpoint(weights_file, verbose=1, save_best_only=True)\n",
    "    ]\n",
    "        \n",
    "    data_gen_args = dict(\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.2\n",
    "    )\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    \n",
    "    seed = 1\n",
    "    image_datagen.fit(X_fold, augment=True, seed=seed)\n",
    "    mask_datagen.fit(y_fold, augment=True, seed=seed)\n",
    "\n",
    "    image_generator = image_datagen.flow(X_fold, batch_size=32, seed=seed)\n",
    "    mask_generator = mask_datagen.flow(y_fold, batch_size=32, seed=seed)    \n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "    results = model.fit_generator(\n",
    "        train_generator, \n",
    "        epochs=100, \n",
    "        steps_per_epoch=len(X_fold)//32,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=(X_val, y_val))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running fold  0\n",
      "Epoch 1/100\n",
      "99/99 [==============================] - 13s 133ms/step - loss: -0.5753 - val_loss: -0.5408\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.54085, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.6522 - val_loss: -0.5708\n",
      "\n",
      "Epoch 00002: val_loss improved from -0.54085 to -0.57081, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 8s 81ms/step - loss: -0.7208 - val_loss: -0.7309\n",
      "\n",
      "Epoch 00003: val_loss improved from -0.57081 to -0.73089, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 8s 82ms/step - loss: -0.7415 - val_loss: -0.7500\n",
      "\n",
      "Epoch 00004: val_loss improved from -0.73089 to -0.75001, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 8s 82ms/step - loss: -0.7392 - val_loss: -0.7823\n",
      "\n",
      "Epoch 00005: val_loss improved from -0.75001 to -0.78226, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.7640 - val_loss: -0.7130\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.7425 - val_loss: -0.7800\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.7598 - val_loss: -0.7538\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: -0.7563 - val_loss: -0.6067\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.7786 - val_loss: -0.8098\n",
      "\n",
      "Epoch 00010: val_loss improved from -0.78226 to -0.80976, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.7856 - val_loss: -0.8203\n",
      "\n",
      "Epoch 00011: val_loss improved from -0.80976 to -0.82028, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.7857 - val_loss: -0.8138\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.7927 - val_loss: -0.8223\n",
      "\n",
      "Epoch 00013: val_loss improved from -0.82028 to -0.82232, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 9s 87ms/step - loss: -0.7961 - val_loss: -0.8237\n",
      "\n",
      "Epoch 00014: val_loss improved from -0.82232 to -0.82374, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8024 - val_loss: -0.8231\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.7982 - val_loss: -0.8247\n",
      "\n",
      "Epoch 00016: val_loss improved from -0.82374 to -0.82472, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8079 - val_loss: -0.8257\n",
      "\n",
      "Epoch 00017: val_loss improved from -0.82472 to -0.82570, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.7947 - val_loss: -0.8267\n",
      "\n",
      "Epoch 00018: val_loss improved from -0.82570 to -0.82674, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8019 - val_loss: -0.8279\n",
      "\n",
      "Epoch 00019: val_loss improved from -0.82674 to -0.82786, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: -0.8071 - val_loss: -0.8287\n",
      "\n",
      "Epoch 00020: val_loss improved from -0.82786 to -0.82870, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.8011 - val_loss: -0.8287\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8074 - val_loss: -0.8159\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8107 - val_loss: -0.8228\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.8085 - val_loss: -0.8317\n",
      "\n",
      "Epoch 00024: val_loss improved from -0.82870 to -0.83170, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.8119 - val_loss: -0.8327\n",
      "\n",
      "Epoch 00025: val_loss improved from -0.83170 to -0.83272, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: -0.8149 - val_loss: -0.8346\n",
      "\n",
      "Epoch 00026: val_loss improved from -0.83272 to -0.83460, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8089 - val_loss: -0.8347\n",
      "\n",
      "Epoch 00027: val_loss improved from -0.83460 to -0.83469, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.8115 - val_loss: -0.8366\n",
      "\n",
      "Epoch 00028: val_loss improved from -0.83469 to -0.83655, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.8126 - val_loss: -0.8387\n",
      "\n",
      "Epoch 00029: val_loss improved from -0.83655 to -0.83874, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8188 - val_loss: -0.8416\n",
      "\n",
      "Epoch 00030: val_loss improved from -0.83874 to -0.84161, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8124 - val_loss: -0.8396\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8128 - val_loss: -0.8422\n",
      "\n",
      "Epoch 00032: val_loss improved from -0.84161 to -0.84224, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.8155 - val_loss: -0.8472\n",
      "\n",
      "Epoch 00033: val_loss improved from -0.84224 to -0.84722, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.8205 - val_loss: -0.8427\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8230 - val_loss: -0.8466\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8239 - val_loss: -0.8501\n",
      "\n",
      "Epoch 00036: val_loss improved from -0.84722 to -0.85008, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.8196 - val_loss: -0.8350\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8267 - val_loss: -0.8537\n",
      "\n",
      "Epoch 00038: val_loss improved from -0.85008 to -0.85366, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8306 - val_loss: -0.8526\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8366 - val_loss: -0.8530\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.8339 - val_loss: -0.8571\n",
      "\n",
      "Epoch 00041: val_loss improved from -0.85366 to -0.85711, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8323 - val_loss: -0.8582\n",
      "\n",
      "Epoch 00042: val_loss improved from -0.85711 to -0.85817, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8410 - val_loss: -0.8443\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 8s 82ms/step - loss: -0.8320 - val_loss: -0.8440\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8371 - val_loss: -0.8576\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8403 - val_loss: -0.8597\n",
      "\n",
      "Epoch 00046: val_loss improved from -0.85817 to -0.85971, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.8385 - val_loss: -0.8555\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8494 - val_loss: -0.8529\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 8s 82ms/step - loss: -0.8437 - val_loss: -0.8639\n",
      "\n",
      "Epoch 00049: val_loss improved from -0.85971 to -0.86393, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8478 - val_loss: -0.8691\n",
      "\n",
      "Epoch 00050: val_loss improved from -0.86393 to -0.86915, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 51/100\n",
      "99/99 [==============================] - 8s 82ms/step - loss: -0.8358 - val_loss: -0.8692\n",
      "\n",
      "Epoch 00051: val_loss improved from -0.86915 to -0.86920, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: -0.8465 - val_loss: -0.8591\n",
      "\n",
      "Epoch 00052: val_loss did not improve\n",
      "Epoch 53/100\n",
      "99/99 [==============================] - 8s 82ms/step - loss: -0.8504 - val_loss: -0.8659\n",
      "\n",
      "Epoch 00053: val_loss did not improve\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8371 - val_loss: -0.8666\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 8s 82ms/step - loss: -0.8463 - val_loss: -0.8676\n",
      "\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.8569 - val_loss: -0.8705\n",
      "\n",
      "Epoch 00056: val_loss improved from -0.86920 to -0.87046, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 57/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8480 - val_loss: -0.8712\n",
      "\n",
      "Epoch 00057: val_loss improved from -0.87046 to -0.87123, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 58/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8545 - val_loss: -0.8716\n",
      "\n",
      "Epoch 00058: val_loss improved from -0.87123 to -0.87156, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 59/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8562 - val_loss: -0.8709\n",
      "\n",
      "Epoch 00059: val_loss did not improve\n",
      "Epoch 60/100\n",
      "99/99 [==============================] - 8s 82ms/step - loss: -0.8516 - val_loss: -0.8716\n",
      "\n",
      "Epoch 00060: val_loss improved from -0.87156 to -0.87157, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 61/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8651 - val_loss: -0.8721\n",
      "\n",
      "Epoch 00061: val_loss improved from -0.87157 to -0.87210, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 62/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.8585 - val_loss: -0.8730\n",
      "\n",
      "Epoch 00062: val_loss improved from -0.87210 to -0.87297, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 63/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8554 - val_loss: -0.8726\n",
      "\n",
      "Epoch 00063: val_loss did not improve\n",
      "Epoch 64/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8571 - val_loss: -0.8726\n",
      "\n",
      "Epoch 00064: val_loss did not improve\n",
      "Epoch 65/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8578 - val_loss: -0.8742\n",
      "\n",
      "Epoch 00065: val_loss improved from -0.87297 to -0.87416, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 66/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8594 - val_loss: -0.8740\n",
      "\n",
      "Epoch 00066: val_loss did not improve\n",
      "Epoch 67/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8536 - val_loss: -0.8739\n",
      "\n",
      "Epoch 00067: val_loss did not improve\n",
      "Epoch 68/100\n",
      "99/99 [==============================] - 8s 82ms/step - loss: -0.8671 - val_loss: -0.8745\n",
      "\n",
      "Epoch 00068: val_loss improved from -0.87416 to -0.87446, saving model to model-tgs-salt-fold0.h5\n",
      "Epoch 69/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8616 - val_loss: -0.8734\n",
      "\n",
      "Epoch 00069: val_loss did not improve\n",
      "Epoch 70/100\n",
      "99/99 [==============================] - 8s 82ms/step - loss: -0.8514 - val_loss: -0.8718\n",
      "\n",
      "Epoch 00070: val_loss did not improve\n",
      "Epoch 71/100\n",
      "99/99 [==============================] - 8s 82ms/step - loss: -0.8681 - val_loss: -0.8698\n",
      "\n",
      "Epoch 00071: val_loss did not improve\n",
      "Epoch 72/100\n",
      "99/99 [==============================] - 8s 82ms/step - loss: -0.8610 - val_loss: -0.8706\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00072: val_loss did not improve\n",
      "Epoch 73/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8593 - val_loss: -0.8706\n",
      "\n",
      "Epoch 00073: val_loss did not improve\n",
      "Epoch 00073: early stopping\n",
      "810/810 [==============================] - 1s 2ms/step\n",
      "810/810 [==============================] - 1s 2ms/step\n",
      "18000/18000 [==============================] - 15s 842us/step\n",
      "0.9444444444444444 0.7271604938271605\n",
      "running fold  2\n",
      "Epoch 1/100\n",
      "99/99 [==============================] - 14s 141ms/step - loss: -0.5717 - val_loss: -0.5852\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.58521, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: -0.6831 - val_loss: -0.3274\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.7086 - val_loss: -0.6785\n",
      "\n",
      "Epoch 00003: val_loss improved from -0.58521 to -0.67846, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 8s 82ms/step - loss: -0.7219 - val_loss: -0.7540\n",
      "\n",
      "Epoch 00004: val_loss improved from -0.67846 to -0.75400, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.7424 - val_loss: -0.5458\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.7493 - val_loss: -0.7833\n",
      "\n",
      "Epoch 00006: val_loss improved from -0.75400 to -0.78332, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.7657 - val_loss: -0.7647\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.7572 - val_loss: -0.7804\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: -0.7621 - val_loss: -0.7872\n",
      "\n",
      "Epoch 00009: val_loss improved from -0.78332 to -0.78721, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.7777 - val_loss: -0.7968\n",
      "\n",
      "Epoch 00010: val_loss improved from -0.78721 to -0.79681, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.7716 - val_loss: -0.7803\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.7810 - val_loss: -0.7897\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.7779 - val_loss: -0.8206\n",
      "\n",
      "Epoch 00013: val_loss improved from -0.79681 to -0.82060, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.7883 - val_loss: -0.7997\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.7439 - val_loss: -0.6019\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.7743 - val_loss: -0.7909\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.7907 - val_loss: -0.8180\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.8178 - val_loss: -0.8323\n",
      "\n",
      "Epoch 00018: val_loss improved from -0.82060 to -0.83226, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: -0.8135 - val_loss: -0.8421\n",
      "\n",
      "Epoch 00019: val_loss improved from -0.83226 to -0.84211, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8261 - val_loss: -0.8411\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8164 - val_loss: -0.8390\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 8s 82ms/step - loss: -0.8225 - val_loss: -0.8408\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8248 - val_loss: -0.8421\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.8318 - val_loss: -0.8426\n",
      "\n",
      "Epoch 00024: val_loss improved from -0.84211 to -0.84257, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8292 - val_loss: -0.8434\n",
      "\n",
      "Epoch 00025: val_loss improved from -0.84257 to -0.84339, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8248 - val_loss: -0.8454\n",
      "\n",
      "Epoch 00026: val_loss improved from -0.84339 to -0.84539, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 8s 84ms/step - loss: -0.8312 - val_loss: -0.8463\n",
      "\n",
      "Epoch 00027: val_loss improved from -0.84539 to -0.84626, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 8s 86ms/step - loss: -0.8426 - val_loss: -0.8461\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8329 - val_loss: -0.8463\n",
      "\n",
      "Epoch 00029: val_loss improved from -0.84626 to -0.84633, saving model to model-tgs-salt-fold2.h5\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 8s 85ms/step - loss: -0.8326 - val_loss: -0.8462\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 8s 82ms/step - loss: -0.8240 - val_loss: -0.8458\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8370 - val_loss: -0.8460\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8277 - val_loss: -0.8458\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 8s 83ms/step - loss: -0.8340 - val_loss: -0.8460\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 00034: early stopping\n",
      "811/811 [==============================] - 2s 2ms/step\n",
      "811/811 [==============================] - 2s 2ms/step\n",
      "18000/18000 [==============================] - 15s 853us/step\n",
      "0.9444444444444444 0.7277435265104809\n",
      "running fold  3\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 15s 147ms/step - loss: -0.5503 - val_loss: -0.5188\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.51883, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.6371 - val_loss: -0.6459\n",
      "\n",
      "Epoch 00002: val_loss improved from -0.51883 to -0.64592, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: -0.6902 - val_loss: -0.6885\n",
      "\n",
      "Epoch 00003: val_loss improved from -0.64592 to -0.68854, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: -0.7274 - val_loss: -0.5557\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 8s 83ms/step - loss: -0.7329 - val_loss: -0.7071\n",
      "\n",
      "Epoch 00005: val_loss improved from -0.68854 to -0.70706, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 8s 83ms/step - loss: -0.7493 - val_loss: -0.7838\n",
      "\n",
      "Epoch 00006: val_loss improved from -0.70706 to -0.78382, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.7549 - val_loss: -0.7904\n",
      "\n",
      "Epoch 00007: val_loss improved from -0.78382 to -0.79037, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: -0.7708 - val_loss: -0.7924\n",
      "\n",
      "Epoch 00008: val_loss improved from -0.79037 to -0.79236, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 8s 83ms/step - loss: -0.7571 - val_loss: -0.6678\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 8s 83ms/step - loss: -0.7601 - val_loss: -0.7200\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.7558 - val_loss: -0.7531\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.7837 - val_loss: -0.7352\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.7856 - val_loss: -0.8144\n",
      "\n",
      "Epoch 00013: val_loss improved from -0.79236 to -0.81437, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: -0.8067 - val_loss: -0.8126\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 8s 83ms/step - loss: -0.8113 - val_loss: -0.8165\n",
      "\n",
      "Epoch 00015: val_loss improved from -0.81437 to -0.81653, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 8s 83ms/step - loss: -0.8043 - val_loss: -0.8229\n",
      "\n",
      "Epoch 00016: val_loss improved from -0.81653 to -0.82291, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: -0.8128 - val_loss: -0.8264\n",
      "\n",
      "Epoch 00017: val_loss improved from -0.82291 to -0.82641, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 8s 83ms/step - loss: -0.7996 - val_loss: -0.8262\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 8s 82ms/step - loss: -0.8205 - val_loss: -0.8267\n",
      "\n",
      "Epoch 00019: val_loss improved from -0.82641 to -0.82671, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 8s 82ms/step - loss: -0.8082 - val_loss: -0.8293\n",
      "\n",
      "Epoch 00020: val_loss improved from -0.82671 to -0.82926, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: -0.8268 - val_loss: -0.8251\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 8s 83ms/step - loss: -0.8088 - val_loss: -0.8341\n",
      "\n",
      "Epoch 00022: val_loss improved from -0.82926 to -0.83411, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: -0.8291 - val_loss: -0.8309\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: -0.8152 - val_loss: -0.8269\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.8244 - val_loss: -0.8395\n",
      "\n",
      "Epoch 00025: val_loss improved from -0.83411 to -0.83949, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: -0.8205 - val_loss: -0.8400\n",
      "\n",
      "Epoch 00026: val_loss improved from -0.83949 to -0.84002, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 9s 88ms/step - loss: -0.8196 - val_loss: -0.8432\n",
      "\n",
      "Epoch 00027: val_loss improved from -0.84002 to -0.84325, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: -0.8207 - val_loss: -0.8445\n",
      "\n",
      "Epoch 00028: val_loss improved from -0.84325 to -0.84450, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: -0.8276 - val_loss: -0.8503\n",
      "\n",
      "Epoch 00029: val_loss improved from -0.84450 to -0.85031, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: -0.8270 - val_loss: -0.8450\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: -0.8257 - val_loss: -0.8507\n",
      "\n",
      "Epoch 00031: val_loss improved from -0.85031 to -0.85074, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.8353 - val_loss: -0.8436\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: -0.8285 - val_loss: -0.8504\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.8389 - val_loss: -0.8265\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: -0.8230 - val_loss: -0.8523\n",
      "\n",
      "Epoch 00035: val_loss improved from -0.85074 to -0.85231, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 8s 83ms/step - loss: -0.8488 - val_loss: -0.8538\n",
      "\n",
      "Epoch 00036: val_loss improved from -0.85231 to -0.85377, saving model to model-tgs-salt-fold3.h5\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: -0.8235 - val_loss: -0.8514\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 8s 83ms/step - loss: -0.8379 - val_loss: -0.8409\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.8331 - val_loss: -0.8464\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.8467 - val_loss: -0.8422\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: -0.8434 - val_loss: -0.8483\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 00041: early stopping\n",
      "790/790 [==============================] - 2s 3ms/step\n",
      "790/790 [==============================] - 2s 3ms/step\n",
      "18000/18000 [==============================] - 15s 858us/step\n",
      "0.9444444444444444 0.6962025316455697\n",
      "running fold  4\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 16s 160ms/step - loss: -0.5641 - val_loss: -0.5415\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.54146, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 9s 89ms/step - loss: -0.6663 - val_loss: -0.6502\n",
      "\n",
      "Epoch 00002: val_loss improved from -0.54146 to -0.65017, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 8s 83ms/step - loss: -0.7222 - val_loss: -0.6756\n",
      "\n",
      "Epoch 00003: val_loss improved from -0.65017 to -0.67560, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: -0.7125 - val_loss: -0.6781\n",
      "\n",
      "Epoch 00004: val_loss improved from -0.67560 to -0.67809, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: -0.7451 - val_loss: -0.7574\n",
      "\n",
      "Epoch 00005: val_loss improved from -0.67809 to -0.75743, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: -0.7642 - val_loss: -0.6822\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 8s 83ms/step - loss: -0.7570 - val_loss: -0.7304\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: -0.7651 - val_loss: -0.7608\n",
      "\n",
      "Epoch 00008: val_loss improved from -0.75743 to -0.76077, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: -0.7702 - val_loss: -0.7433\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: -0.7847 - val_loss: -0.7949\n",
      "\n",
      "Epoch 00010: val_loss improved from -0.76077 to -0.79490, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.7942 - val_loss: -0.7935\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: -0.7771 - val_loss: -0.7343\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: -0.7877 - val_loss: -0.7903\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: -0.7857 - val_loss: -0.7748\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.8105 - val_loss: -0.8264\n",
      "\n",
      "Epoch 00015: val_loss improved from -0.79490 to -0.82639, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: -0.8160 - val_loss: -0.8310\n",
      "\n",
      "Epoch 00016: val_loss improved from -0.82639 to -0.83097, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: -0.8184 - val_loss: -0.8331\n",
      "\n",
      "Epoch 00017: val_loss improved from -0.83097 to -0.83312, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: -0.8140 - val_loss: -0.8341\n",
      "\n",
      "Epoch 00018: val_loss improved from -0.83312 to -0.83415, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.8258 - val_loss: -0.8235\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 8s 83ms/step - loss: -0.8286 - val_loss: -0.8300\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: -0.8244 - val_loss: -0.8311\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: -0.8261 - val_loss: -0.8308\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: -0.8360 - val_loss: -0.8343\n",
      "\n",
      "Epoch 00023: val_loss improved from -0.83415 to -0.83433, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: -0.8324 - val_loss: -0.8350\n",
      "\n",
      "Epoch 00024: val_loss improved from -0.83433 to -0.83497, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.8335 - val_loss: -0.8352\n",
      "\n",
      "Epoch 00025: val_loss improved from -0.83497 to -0.83523, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: -0.8317 - val_loss: -0.8354\n",
      "\n",
      "Epoch 00026: val_loss improved from -0.83523 to -0.83544, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: -0.8312 - val_loss: -0.8357\n",
      "\n",
      "Epoch 00027: val_loss improved from -0.83544 to -0.83571, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.8400 - val_loss: -0.8360\n",
      "\n",
      "Epoch 00028: val_loss improved from -0.83571 to -0.83597, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: -0.8235 - val_loss: -0.8368\n",
      "\n",
      "Epoch 00029: val_loss improved from -0.83597 to -0.83677, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.8470 - val_loss: -0.8364\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.8253 - val_loss: -0.8367\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.8328 - val_loss: -0.8377\n",
      "\n",
      "Epoch 00032: val_loss improved from -0.83677 to -0.83770, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.8460 - val_loss: -0.8395\n",
      "\n",
      "Epoch 00033: val_loss improved from -0.83770 to -0.83952, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.8373 - val_loss: -0.8401\n",
      "\n",
      "Epoch 00034: val_loss improved from -0.83952 to -0.84010, saving model to model-tgs-salt-fold4.h5\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: -0.8319 - val_loss: -0.8394\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 8s 83ms/step - loss: -0.8373 - val_loss: -0.8386\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: -0.8321 - val_loss: -0.8386\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.8372 - val_loss: -0.8400\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 8s 84ms/step - loss: -0.8352 - val_loss: -0.8400\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 00039: early stopping\n",
      "785/785 [==============================] - 2s 3ms/step\n",
      "785/785 [==============================] - 2s 3ms/step\n",
      "18000/18000 [==============================] - 15s 852us/step\n",
      "0.9444444444444444 0.6868789808917198\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3W1sHdd95/Hvj5dPInlliRJ16ciyZdm8TNwmcGpFDZoijb1IqmQB290Erl0sYhVNjBbrDbrZNWJhC6dwG2z7pt4tVujCcZ3nxEkMJFa2yqpJ6z4gjQPJqBNHMvRgyqkZxRL1ZEuUxId7//tihtSIoswr8vI+UL8PcMGZM2dmzgHJ+c+cc+4ZRQRmZmYt9S6AmZk1BgcEMzMDHBDMzCzlgGBmZoADgpmZpRwQzMwMcEAwM7OUA4KZmQEOCGZmlmqtdwGuxOrVq2P9+vX1LoaZWVN5/vnnj0VE31z5miogrF+/nt27d9e7GGZmTUXSzyrJ5yYjMzMDHBDMzCzlgGBmZoADgpmZpRwQzMwMcEAwM7OUA4KZmQFN9j0EM7PFNjo2yaFjo7w8coajb4xx76Z15Dvb6l2smnBAMLOrTrkcHH79HEMjyYV/aGSUoWNnePnoKK+9cf6ivPnOVu7ddH2dSlpbDghmtmSNjk1mLvZnePnYKEMjoxw6dobzE+XpfPnOVjb09fBrN6/ipr4eNqzu5sa+bn5r27+w78jpOtagthwQzKyplcvBz0+dY+jYKEMjZy7c8Y9cfLffIljX28WG1d382k3phb+vm5v6eljd046kS45dLPSw3wHBzKyxnBmbZGj6Yn+Gl9PmnleOj15yt39T5m7/pr5uNvT1cMOqLjpac1d0zmIhz7P7RqpdlYblgGBmVRERlMrBZDn9WQomy+WL08pBqVxmonTx+mRmfbJcZnwyOHzq3HS7/tCxMxx5Y2z6XFN3+zf19fDrN69mQ+bCf7m7/fkoFvJ88/lhToyO09vdXpVjNjIHBLMmFRFMlILzkyXOT5QYmyhzbiJZPn/R8oW08xOlNL186bbJEufGS0yULr6Iz1y/cMEvpxfwZL1UjqrXcXnatv/rN/elzTtJE8/187jbn49ifx6A/UdO8+4Nqxb9fPXmgGD2JrJ3vROl5E52Ir3DnSylP9M73PF0+2SpzER5avuFPMk+kaalF9NSmfHShbyXXqyzF/EZ2ybL874It+da6GhrYVlbjs62HJ1tLcnP1hzdHa3kWkRri9KfLdPrrTmRa2nJbBO5XLptKj03te+FfG2z7ZcerzWbnsnXf00nq7qrd7c/H4MFBwRbokrl4PVzE5w6Ow6Q/KPndNE/aWvu4n/aev4zZk2UypdeEDN3tVMXyPPjpek75nPj5enlN7u4jk2WL1zsL7pYJxf/qP6N7yVaW0RbroVl7Tk6W9OLc+ZCfc2yNjrbcpdexFtzLGvP0dGW7Jfsn2xf1t5Cx/TyxcfNtTTG77XRFZZ3sLyzlX2vXR0dyw4ITWrq4n5idJxTZ8c5MTrOybPjnDw7wcnRqfWJJC3ddurcxBVf3FrEhTvEWe78kjs60ZbJM/PusjU3+92mJMZLZc6Nlxibuohf5g55coF3wp1tufRCeuGiuHxZG2vyHXS05WjLJXVozSUX5rZcEhzb0iA5nTa9ntSlrfVCntbZjtFy4VitLaK9teXSY+QaJ/DaxSQx2J+/akYaVRQQJG0G/heQA56IiD+bJc89wB8DAfw4In5H0u3AY5lsbwXujYhvS/o88BvA6+m2LRHxwnwr0swqu7hn1s+O8/qbXNzbW1vo7WpnRVcbvd3tvO0ty1nZ1UZvVzsru5P0FumijrxZO/oybcZT7cXT20uZ/WasZ/OdHZ+cvf25XKZUiuTONnO3uybfdtFFO7kDbpm+6+3M3Ole0tyRLl9I952wLdxAIc///fFhImLJB+45A4KkHLANeD8wDOyStD0i9mbyDABbgfdExElJawAi4lng1jRPL3AQ+NvM4R+KiKerVZnFMFkqMzZZZnyyzHipzNhEmfFSaTptetvU9snS9PrY5KX7nj4/Ma+L+8rudlZ2tfG2tyxP1rvaWNndTm93Oyu62tM8bazsaqerPbfk/3DNamWwkOer5yc5enqMwvLOehdnUVXyhLAJOBgRQwCSngLuAvZm8nwc2BYRJwEi4ugsx/kI8N2IOLuwIl+5z/3gEHsOv5G5UJcYL5UvunBP/yyVGZu4sL1aAyfacqI910K+s+1NL+4ru9JPd3J3v6zNF3ezeiqmHcv7XjvtgACsBV7NrA8DvzojTxFA0g9ImpX+OCL+34w89wJ/MSPtM5IeAf4OeDgixlgELw6/zo8OnaC9tYX2XAvtrS10tCY/uztaM2m5i7Z1ZPJnt08dpyOT95I8uYuP0eKmC7OmVCz0AMlIo/cW++pcmsVVSUCY7Uo28765FRgA3gdcB/yzpF+OiFMAkq4F3g7szOyzFXgNaAceBz4FPHrJyaUHgAcArr9+fhNM/cVv3zqv/czMVvV0sLqn46oYaVTJ+xCGgXWZ9euAw7PkeSYiJiLiELCPJEBMuQf4VkRMTCVExC8iMQZ8jqRp6hIR8XhEbIyIjX19Szs6m1ljulrmNKokIOwCBiTdKKmdpOln+4w83wZuB5C0mqQJaSiz/T7ga9kd0qcGlDSQ3w38dD4VMDNbbMVCngNHz1BehG9jN5I5A0JETAIPkjT3vAR8IyL2SHpU0p1ptp3AcUl7gWdJRg8dB5C0nuQJ4x9nHPorkl4EXgRWA3+68OqYmVXfYH+es+Mlfn7qXL2Lsqgq+h5CROwAdsxIeySzHMAn08/MfV8h6ZiemX7HFZbVzKwusiON1vV21bk0i8fvVDYzm8PUSKOl/rIcBwQzsznkO9t4yzWdS75j2QHBzKwCxf48+4+cqXcxFpUDgplZBQYLeV4+eobJUnnuzE3KAcHMrALFQp7xUplXjtd89p2acUAwM6vAYObtaUuVA4KZWQVu6utBYklPYeGAYGZWgWXtOW7o7eLAUQcEM7OrXrGQ9xOCmZkl/QivHD/L+YlSvYuyKBwQzMwqVCzkKZWDoZHRehdlUTggmJlVaGpOo6U60sgBwcysQjeu7qa1RQ4IZmZXu/bWFjb0dTsgmJlZOtLIAcHMzAYLeV49cY7Rscl6F6XqHBDMzK7AQNqxfODo0pv51AHBzOwKLOU5jSoKCJI2S9on6aCkhy+T5x5JeyXtkfTVTHpJ0gvpZ3sm/UZJP5J0QNLXJbUvvDpmZovr+t4uOlpb2L8Ev7E8Z0CQlAO2AR8EbgHuk3TLjDwDwFbgPRHxS8AfZjafi4hb08+dmfQ/Bx6LiAHgJPB7C6uKmdniy7WIgULPkuxYruQJYRNwMCKGImIceAq4a0aejwPbIuIkQEQcfbMDShJwB/B0mvQF4O4rKbiZWb0UC/mrtsloLfBqZn04TcsqAkVJP5D0nKTNmW2dknan6VMX/VXAqYiY6qaf7ZhmZg2pWMhz5I0xXj87Ue+iVFVrBXk0S1rMcpwB4H3AdcA/S/rliDgFXB8RhyVtAP5e0ovAGxUcMzm59ADwAMD1119fQXHNzBbX4NQUFkdP8671vXUuTfVU8oQwDKzLrF8HHJ4lzzMRMRERh4B9JAGCiDic/hwC/gF4J3AMWCGp9U2OSbrf4xGxMSI29vX1VVQpM7PFVExHGi21qbArCQi7gIF0VFA7cC+wfUaebwO3A0haTdKENCRppaSOTPp7gL0REcCzwEfS/e8HnlloZczMauEt13TS09G65PoR5gwIaTv/g8BO4CXgGxGxR9KjkqZGDe0EjkvaS3KhfygijgNvA3ZL+nGa/mcRsTfd51PAJyUdJOlT+OtqVszMbLFIoljoWXJPCJX0IRARO4AdM9IeySwH8Mn0k83zL8DbL3PMIZIRTGZmTadYyLNzz2tEBMnAyebnbyqbmc1DsZDn5NkJjp0Zr3dRqsYBwcxsHpbiFBYOCGZm8zD19rSl1I/ggGBmNg+re9pZ2dXmJwQzs6tdMtJoaU1h4YBgZjZPg/159h85QzLQsvk5IJiZzVOxkOfM2CSHXz9f76JUhQOCmdk8TY80WiIdyw4IZmbzVFyTjjRaIv0IDghmZvN0TVcbheUdS6Zj2QHBzGwBltJIIwcEM7MFGCzkOXDkDKVy8480ckAwM1uAYn+escky/3bibL2LsmAOCGZmC7CUprBwQDAzW4CBNT0AHFgC/QgOCGZmC9Dd0cq63mVLYuipA4KZ2QINLpGRRg4IZmYLVCzkGRoZZXyyXO+iLEhFAUHSZkn7JB2U9PBl8twjaa+kPZK+mqbdKumHadpPJP12Jv/nJR2S9EL6ubU6VTIzq61iIc9kOTh0bLTeRVmQOd+pLCkHbAPeDwwDuyRtj4i9mTwDwFbgPRFxUtKadNNZ4KMRcUDSW4DnJe2MiFPp9oci4ulqVsjMrNamRhrtP3J6en6jZlTJE8Im4GBEDEXEOPAUcNeMPB8HtkXESYCIOJr+3B8RB9Llw8BRoK9ahTczawQb+rrJtajp+xEqCQhrgVcz68NpWlYRKEr6gaTnJG2eeRBJm4B24OVM8mfSpqTHJHVcYdnNzBpCZ1uO9au6mv67CJUEBM2SNvM72q3AAPA+4D7gCUkrpg8gXQt8CfjdiJjqddkKvBV4F9ALfGrWk0sPSNotaffIyEgFxTUzq73kZTlLPyAMA+sy69cBh2fJ80xETETEIWAfSYBA0nLgb4A/iojnpnaIiF9EYgz4HEnT1CUi4vGI2BgRG/v63NpkZo1pYE2en504y7nxUr2LMm+VBIRdwICkGyW1A/cC22fk+TZwO4Ck1SRNSENp/m8BX4yIb2Z3SJ8akCTgbuCnC6mImVk9DfbniYCXR87UuyjzNmdAiIhJ4EFgJ/AS8I2I2CPpUUl3ptl2Ascl7QWeJRk9dBy4B3gvsGWW4aVfkfQi8CKwGvjTqtbMzKyGlsKcRnMOOwWIiB3Ajhlpj2SWA/hk+snm+TLw5csc844rLayZWaNav6qL9lxLU/cj+JvKZmZV0Jpr4aY1PU09p5EDgplZlRQLPexv4iYjBwQzsyopFvIcfv08p89P1Lso8+KAYGZWJYPTU1g050gjBwQzsyqZmseoWTuWHRDMzKpk7YpldLXnmnboqQOCmVmVtLSIgTU9fkIwM7OkY9l9CGZmxmB/nmNnxjh+ZqzeRbliDghmZlVUbOKRRg4IZmZV1MwjjRwQzMyqaE2+g+WdrU05hYUDgplZFUlisD/PAQcEMzMrFvLse+00yUTQzcMBwcysygb787xxfpIjbzTXSCMHBDOzKpt+WU6TNRs5IJiZVdn00NMmm8LCAcHMrMp6u9tZ3dPRdENPKwoIkjZL2ifpoKSHL5PnHkl7Je2R9NVM+v2SDqSf+zPpt0l6MT3mX0rSwqtjZtYYBvubb06jOQOCpBywDfggcAtwn6RbZuQZALYC74mIXwL+ME3vBT4N/CqwCfi0pJXpbn8FPAAMpJ/N1aiQmVkjmJrTqFxunpFGlTwhbAIORsRQRIwDTwF3zcjzcWBbRJwEiIijafpvAt+LiBPptu8BmyVdCyyPiB9GMi7ri8DdVaiPmVlDGCzkOTdRYvjkuXoXpWKVBIS1wKuZ9eE0LasIFCX9QNJzkjbPse/adPnNjmlm1rQGmnCkUSUBYba2/ZnPQK0kzT7vA+4DnpC04k32reSYycmlByTtlrR7ZGSkguKamdVfsdADNNecRpUEhGFgXWb9OuDwLHmeiYiJiDgE7CMJEJfbdzhdfrNjAhARj0fExojY2NfXV0FxzczqL9/ZxtoVy5ZcQNgFDEi6UVI7cC+wfUaebwO3A0haTdKENATsBD4gaWXamfwBYGdE/AI4Lend6eiijwLPVKVGZmYNoljoaarXac4ZECJiEniQ5OL+EvCNiNgj6VFJd6bZdgLHJe0FngUeiojjEXEC+BOSoLILeDRNA/gD4AngIPAy8N0q1svMrO6K/XmGRkaZKJXrXZSKtFaSKSJ2ADtmpD2SWQ7gk+ln5r5PAk/Okr4b+OUrLK+ZWdMorskzXirzs+Oj3LwmX+/izMnfVDYzWyQXXpbTHG9Pc0AwM1skN6/pQaJp+hEcEMzMFklnW471q7qbZqSRA4KZ2SIqFnqa5stpDghmZouoWMjzyrFRzk+U6l2UOTkgmJktomIhTzlgaGS03kWZkwOCmdkiujDSqPGbjRwQzMwW0fpV3bTl1BT9CA4IZmaLqL21hQ2re5ridZoOCGZmi2ygSUYaOSCYmS2ywUKe4ZPnGB2brHdR3pQDgpnZIiumHcsHjjb2FBYOCGZmi2wwfXtao/cjOCCYmS2ydb1ddLa1NHw/ggOCmdkiy7WIm9f0NPx3ERwQzMxqoFjIOyCYmVnSj3DkjTFOnR2vd1EuywHBzKwGik3wspyKAoKkzZL2SToo6eFZtm+RNCLphfTzsTT99kzaC5LOS7o73fZ5SYcy226tbtXMzBrH1EijRu5YnvOdypJywDbg/cAwsEvS9ojYOyPr1yPiwWxCRDwL3Joepxc4CPxtJstDEfH0AspvZtYUrr2mk3xHa0MPPa3kCWETcDAihiJiHHgKuGse5/oI8N2IODuPfc3MmpokBgqNPdKokoCwFng1sz6cps30YUk/kfS0pHWzbL8X+NqMtM+k+zwmqWO2k0t6QNJuSbtHRkYqKK6ZWWMa7E9GGkVEvYsyq0oCgmZJm1mb7wDrI+IdwPeBL1x0AOla4O3AzkzyVuCtwLuAXuBTs508Ih6PiI0RsbGvr6+C4pqZNaZiIc/JsxOMnBmrd1FmVUlAGAayd/zXAYezGSLieERM1fCzwG0zjnEP8K2ImMjs84tIjAGfI2maMjNbsorTU1g05kijSgLCLmBA0o2S2kmafrZnM6RPAFPuBF6acYz7mNFcNLWPJAF3Az+9sqKbmTWXYoOPNJpzlFFETEp6kKS5Jwc8GRF7JD0K7I6I7cAnJN0JTAIngC1T+0taT/KE8Y8zDv0VSX0kTVIvAL+/4NqYmTWw1T3t9Ha3c6BZAwJAROwAdsxIeySzvJWkT2C2fV9hlk7oiLjjSgpqZtbsJFFs4Jfl+JvKZmY1NFjIs/+1xhxp5IBgZlZDA4U8o+Mlfn7qXL2LcgkHBDOzGhqcntOo8ZqNHBDMzGqouKZxJ7lzQDAzq6FrutroX97ZkHMaOSCYmdVYsT/fkCONHBDMzGqsuKaHA0fPUCo31kgjBwQzsxor9ucZnyzzs+Oj9S7KRRwQzMxqbOplOY3WseyAYGZWYwOFHqDxhp46IJiZ1VhXeyvX93Y1XMeyA4KZWR0UCz0NN/TUAcHMrA6KhTyHjo0yPlmud1GmOSCYmdXBYH+eyXJw6FjjjDRyQDAzq4NGfFmOA4KZWR1s6Osm16KG6kdwQDAzq4OO1hzrVzXWSCMHBDOzOhnszzfUdxEqCgiSNkvaJ+mgpIdn2b5F0oikF9LPxzLbSpn07Zn0GyX9SNIBSV+X1F6dKpmZNYdiIc+/nTjLufFSvYsCVBAQJOWAbcAHgVuA+yTdMkvWr0fErenniUz6uUz6nZn0Pwcei4gB4CTwe/OvhplZ8xks5ImAg0cbYwqLSp4QNgEHI2IoIsaBp4C7FnJSSQLuAJ5Ok74A3L2QY5qZNZtif2ONNKokIKwFXs2sD6dpM31Y0k8kPS1pXSa9U9JuSc9JmrrorwJORcTkHMdE0gPp/rtHRkYqKK6ZWXO4obeL9lxLw/QjVBIQNEvazEm8vwOsj4h3AN8nueOfcn1EbAR+B/ifkm6q8JhJYsTjEbExIjb29fVVUFwzs+bQmmvhpjU9TRUQhoHsHf91wOFshog4HhFj6epngdsy2w6nP4eAfwDeCRwDVkhqvdwxzcyuBoMNNKdRJQFhFzCQjgpqB+4FtmczSLo2s3on8FKavlJSR7q8GngPsDciAngW+Ei6z/3AMwupiJlZMyr25zn8+nneOD9R76LMHRDSdv4HgZ0kF/pvRMQeSY9Kmho19AlJeyT9GPgEsCVNfxuwO01/FviziNibbvsU8ElJB0n6FP66WpUyM2sWUy/LOdAAzUatc2eBiNgB7JiR9khmeSuwdZb9/gV4+2WOOUQygsnM7Ko1PafRa2e47YbeupbF31Q2M6ujtSuW0dWea4iOZQcEM7M6amkRA4XGmMLCAcHMrM4GC40x9NQBwcyszoqFPMfOjHPszNjcmReRA4KZWZ1NdSzX+ynBAcHMrM4G+6eGntZ3kjsHBDOzOluT7+CaZW11n+TOAcHMrM4kMVjI130KCwcEM7MGUOzvYd+R0yQz+9SHA4KZWQMoFvKcPj/Ja2+cr1sZHBDMzBrAhZFG9etYdkAwM2sA0wGhjv0IDghmZg2gt7udvnxHXUcaOSCYmTWIwTrPaeSAYGbWIAYKPRw4coZyuT4jjRwQzMwaxGAhz7mJEsMnz9Xl/A4IZmYNophOYVGvfoSKAoKkzZL2SToo6eFZtm+RNCLphfTzsTT9Vkk/TF+v+RNJv53Z5/OSDmX2ubV61TIzaz4Da3qA+k1yN+crNCXlgG3A+4FhYJek7Zl3I0/5ekQ8OCPtLPDRiDgg6S3A85J2RsSpdPtDEfH0AutgZrYk5DvbWLtiGfvqNPS0kieETcDBiBiKiHHgKeCuSg4eEfsj4kC6fBg4CvTNt7BmZktdsY4vy6kkIKwFXs2sD6dpM304bRZ6WtK6mRslbQLagZczyZ9J93lMUseVFNzMbCkq9ucZGhllolSu+bkrCQiaJW3mmKjvAOsj4h3A94EvXHQA6VrgS8DvRsRULbcCbwXeBfQCn5r15NIDknZL2j0yMlJBcc3MmtdgIc94qczPjo/W/NyVBIRhIHvHfx1wOJshIo5HxNS73z4L3Da1TdJy4G+AP4qI5zL7/CISY8DnSJqmLhERj0fExojY2Nfn1iYzW9qmprDY91rt5zSqJCDsAgYk3SipHbgX2J7NkD4BTLkTeClNbwe+BXwxIr452z6SBNwN/HS+lTAzWypuXtNDi+oz9HTOUUYRMSnpQWAnkAOejIg9kh4FdkfEduATku4EJoETwJZ093uA9wKrJE2lbYmIF4CvSOojaZJ6Afj96lXLzKw5dbbluGFVd10muZszIABExA5gx4y0RzLLW0n6BGbu92Xgy5c55h1XVFIzs6tEsdDD/qO1Dwj+prKZWYMZLOR55dgo5ydKNT2vA4KZWYMp9ucpB7w8UtuOZQcEM7MGMzj99rTaNhs5IJiZNZj1q7tpy6nmQ08dEMzMGkxbroUNq3s44CcEMzMr9udr/l0EBwQzswY0WOhh+OQ5zoxN1uycDghmZg1oagqLWjYbOSCYmTWgYh1GGjkgmJk1oHW9XXS2tbD/SO1GGjkgmJk1oFyLGFiT9xOCmZklzUa1fJ2mA4KZWYMqFno4enqMk6PjNTmfA4KZWYMq9te2Y9kBwcysQU3PaXS0Nh3LDghmZg3q2ms6yXe01uxlOQ4IZmYNSlJNp7BwQDAza2DFQg/7j5wmIhb9XBUFBEmbJe2TdFDSw7Ns3yJpRNIL6edjmW33SzqQfu7PpN8m6cX0mH8pSdWpkpnZ0lEs5Dl1doKR02OLfq45A4KkHLAN+CBwC3CfpFtmyfr1iLg1/TyR7tsLfBr4VWAT8GlJK9P8fwU8AAykn80LrYyZ2VJz67oV/Pt3XMvYZHnRz1XJE8Im4GBEDEXEOPAUcFeFx/9N4HsRcSIiTgLfAzZLuhZYHhE/jOQ56IvA3fMov5nZkvbO61ey7Xd+hXW9XYt+rkoCwlrg1cz6cJo204cl/UTS05LWzbHv2nR5rmOamVmNVBIQZmvbn9m78R1gfUS8A/g+8IU59q3kmMkBpAck7Za0e2RkpILimpnZfFQSEIaBdZn164DD2QwRcTwipno8PgvcNse+w+nyZY+ZOfbjEbExIjb29fVVUFwzM5uPSgLCLmBA0o2S2oF7ge3ZDGmfwJQ7gZfS5Z3AByStTDuTPwDsjIhfAKclvTsdXfRR4JkF1sXMzBagda4METEp6UGSi3sOeDIi9kh6FNgdEduBT0i6E5gETgBb0n1PSPoTkqAC8GhEnEiX/wD4PLAM+G76MTOzOlEtvuxQLRs3bozdu3fXuxhmZk1F0vMRsXGufP6mspmZAQ4IZmaWaqomI0kjwM/muftq4FgVi9MMXOerg+u89C20vjdExJzDNJsqICyEpN2VtKEtJa7z1cF1XvpqVV83GZmZGeCAYGZmqaspIDxe7wLUget8dXCdl76a1Peq6UMwM7M3dzU9IZiZ2ZtYcgFhIW93a1Zz1TnNc4+kvZL2SPpqrctYTRX8jh/L/H73SzpVj3JWUwV1vl7Ss5L+NZ2G/kP1KGc1VVDnGyT9XVrff5B03WzHaSaSnpR0VNJPL7Nd6RsmD6b1/pWqFiAilsyHZK6ll4ENQDvwY+CWGXm2AP+73mWtcZ0HgH8FVqbra+pd7sWs74z8/5lk/q26l32Rf8ePA3+QLt8CvFLvctegzt8E7k+X7wC+VO9yV6He7wV+BfjpZbZ/iGTeNwHvBn5UzfMvtSeEhbzdrVlVUuePA9sieWsdEXG0xmWspiv9Hd8HfK0mJVs8ldQ5gOXp8jVcZjr5JlJJnW8B/i5dfnaW7U0nIv6JZILQy7kL+GIkngNWzJhtekGWWkBYyNvdmlUldS4CRUk/kPScpGZ+f3Wlv2Mk3QDcCPx9Dcq1mCqp8x8D/1HSMLCD5MmomVVS5x8DH06XfwvIS1pVg7LVU8V///Ox1ALCQt7u1qwqqXMrSbPR+0jumJ+QtGKRy7VYKn7bHsm7O56OiNIilqcWKqnzfcDnI+I6kmaFL0lq5v/vSur834DfkPSvwG8APyeZgn8pu5K//yvWzH8ws1nI292a1Zx1TvM8ExETEXEI2EcSIJpRJfWdci/N31wEldX594BvAETED4FOkvlvmlUl/8uHI+I/RMQ7gf+epr1euyLWxZX8/V+xpRYQFvJ2t2Y1Z52BbwO3A0haTdKENFTTUlZPJfVF0iCwEvhhjcu3GCqp878B/w5A0ttIAkIzv4S8kv/l1ZmnoK3AkzUuYz1sBz6ajjZ6N/BxP7UAAAAAqElEQVR6JG+grIo535jWTGIBb3drVhXWeepVpnuBEvBQRByvX6nnr8L6QtKE8lSkQzOaWYV1/q/AZyX9F5ImhC3NXPcK6/w+4H9ICuCfgP9UtwJXiaSvkdRrddof9GmgDSAi/g9J/9CHgIPAWeB3q3r+Jv6bMTOzKlpqTUZmZjZPDghmZgY4IJiZWcoBwczMAAcEMzNLOSCYmRnggGBmZikHBDMzA+D/A5JkTY60coxUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in range(5):\n",
    "    if fold == 1:\n",
    "        continue\n",
    "    print('running fold ', fold)\n",
    "    X_fold, y_fold, X_val, y_val = load_fold(X_train, y_train, fold)\n",
    "    weights_file = f\"model-tgs-salt-fold{fold}.h5\"    \n",
    "    \n",
    "    run_fold(X_fold, y_fold, X_val, y_val, weights_file)\n",
    "    \n",
    "    model = build_unet2()\n",
    "    model.load_weights(weights_file)\n",
    "    model.evaluate(X_val, y_val, verbose=1)\n",
    "    \n",
    "    preds_val = model.predict(X_val, verbose=1)\n",
    "    preds_test = model.predict(X_test, verbose=1)\n",
    "    \n",
    "    thres = np.linspace(0.5, 1.0, 10)\n",
    "    thres_ioc = [iou_metric_batch(y_val, np.int32(preds_val > t)) for t in thres]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(thres, thres_ioc);\n",
    "    best_thres = thres[np.argmax(thres_ioc)]\n",
    "    print(best_thres, max(thres_ioc))\n",
    "    \n",
    "    preds = preds_test > best_thres # threshold\n",
    "    np.save(f\"preds_fold{fold}\", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros_like(X_test)\n",
    "for fold in range(5):\n",
    "    p = np.load('preds_fold%s.npy' % fold)\n",
    "    preds += p\n",
    "preds /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18000 [00:00<?, ?it/s]/opt/miniconda2/envs/avito/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "100%|██████████| 18000/18000 [00:15<00:00, 1153.92it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_ = []\n",
    "for i in tqdm(range(len(preds_test))):\n",
    "    preds_.append(resize(np.squeeze(preds[i]), (101, 101), mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RLenc(img, order='F', format=True):\n",
    "    \"\"\"\n",
    "    img is binary mask image, shape (r,c)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
    "\n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []  ## list of run lengths\n",
    "    r = 0  ## the current run length\n",
    "    pos = 1  ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if (c == 0):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    # if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "\n",
    "    if format:\n",
    "        z = ''\n",
    "\n",
    "        for rr in runs:\n",
    "            z += '{} {} '.format(rr[0], rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = []\n",
    "for image_id, p in zip(test_ids, preds_):\n",
    "    rows.append([image_id, RLenc(np.round(p))])\n",
    "    \n",
    "sub = pd.DataFrame(rows, columns=['id', 'rle_mask'])\n",
    "sub.to_csv('submissions/subm_005.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
