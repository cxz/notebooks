{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform train & test.csv into numpy arrays.\n",
    "\n",
    "Before starting train.csv is split into parts so we can read in parallel.\n",
    "\n",
    "- `split -l 10000000 train.csv train_part`\n",
    "- `for i in $(ls -1 train_part*); do sed -i '1s;^;ip,app,device,os,channel,click_time,attributed_time,is_attributed\\n;' $i`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "import hashlib\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import traceback \n",
    "import multiprocessing as mp\n",
    "import glob\n",
    "\n",
    "D = 2 ** 12\n",
    "\n",
    "def hashed(value, size=D):\n",
    "    # return int(hashlib.md5((value).encode('utf8')).hexdigest(), 16)%(D-1)+1\n",
    "    return  hash(value) % D\n",
    "    \n",
    "def get_x(csv_row):        \n",
    "    try:\n",
    "        x = []\n",
    "        for k in ['ip', 'app', 'device', 'os', 'channel']:\n",
    "            x.append(hashed(csv_row[k]))\n",
    "        for k1, k2 in [('app', 'channel'), ('app', 'device'), ('ip', 'device')]:\n",
    "            x.append(hashed(csv_row[k1] + csv_row[k2]))\n",
    "        x.append(int(csv_row['click_time'][-8:-6])) # hour\n",
    "        x.append(int(csv_row['click_time'][-5:-3])) # minute\n",
    "        return x\n",
    "    except Exception as e:\n",
    "        #print(csv_row)\n",
    "        traceback.print_exc()\n",
    "\n",
    "def load_part(fname, max_size=10000000):\n",
    "    train_x = np.zeros((max_size, 10), dtype=np.uint16) \n",
    "    train_y = np.zeros((max_size), dtype=np.uint8)\n",
    "    assert(D < 2**16)\n",
    "\n",
    "    with open(fname) as f:\n",
    "        rows = 0\n",
    "        for idx, row in tqdm(enumerate(DictReader(f)), total=max_size):\n",
    "            train_x[idx, :] = get_x(row)\n",
    "            train_y[idx] = 1. if row['is_attributed'] == '1' else 0\n",
    "            rows += 1\n",
    "        return train_x[:rows], train_y[:rows]\n",
    "\n",
    "def prepare_train():\n",
    "    fnames = list(glob.glob('input/train_part*'))\n",
    "\n",
    "    p = mp.Pool(8)\n",
    "    parts = p.map(load_part, fnames)\n",
    "    X = np.concatenate([p[0] for p in parts])\n",
    "    y = np.concatenate([p[1] for p in parts])\n",
    "\n",
    "    print(X.shape, y.shape)\n",
    "    p.close()\n",
    "    \n",
    "    np.savez_compressed('tmp/train.npz', x=X, y=y)\n",
    "\n",
    "def prepare_test():\n",
    "    size = 18790470\n",
    "    X = np.zeros((size, 10), dtype=np.uint16)\n",
    "    with open('input/test.csv') as f:\n",
    "        for idx, row in tqdm(enumerate(DictReader(f)), total=size):\n",
    "            X[idx, :] = get_x(row)\n",
    "    np.savez_compressed('tmp/test.npz', x=X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 18790469/18790470 [06:20<00:00, 49422.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finishsed test.\n"
     ]
    }
   ],
   "source": [
    "#prepare_train()\n",
    "#print('finished train.')\n",
    "\n",
    "prepare_test()\n",
    "print('finishsed test.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.npz  unused.ipynb  weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "!ls tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184903890, 10) (184903890,)\n"
     ]
    }
   ],
   "source": [
    "train = np.load('tmp/train.npz')\n",
    "X_train, y_train = train['x'], train['y']\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18790470, 10)\n"
     ]
    }
   ],
   "source": [
    "test = np.load('tmp/test.npz')\n",
    "X_test = test['x']\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
