{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Draft.\n",
    "\n",
    "Train/test split by time:\n",
    "train [2017-11-06, 2017-11-09]\n",
    "test  [2017-11-10]\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "SEED=42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'ip':'uint32',\n",
    "    'app': 'uint16',\n",
    "    'device': 'uint16',\n",
    "    'os': 'uint16',\n",
    "    'channel': 'uint16',\n",
    "    'is_attributed': 'uint8'\n",
    "}   \n",
    "\n",
    "def add_mean(df_train, df_val, df_test=None):\n",
    "    df1 = df_train[['is_attributed', 'app']].groupby(['app']).median().rename(columns={'is_attributed': 'mean1'}).reset_index()\n",
    "    df_train = pd.merge(df_train, df1, on=['app'], how='left')\n",
    "    df_val = pd.merge(df_val, df1, on=['app'], how='left')\n",
    "    #df_test = pd.merge(df_test, df1, on=['app'], how='left')\n",
    "    \n",
    "    df2 = df_train[['is_attributed', 'app', 'channel']].groupby(['app', 'channel']).median().rename(columns={'is_attributed': 'mean2'}).reset_index()    \n",
    "    df_train = pd.merge(df_train, df2, on=['app', 'channel'], how='left')\n",
    "    df_val = pd.merge(df_val, df2, on=['app', 'channel'], how='left')\n",
    "    #df_test = pd.merge(df_test, df2, on=['app', 'channel'], how='left')\n",
    "                   \n",
    "    df3 = df_train[['is_attributed', 'app', 'device']].groupby(['app', 'device']).median().rename(columns={'is_attributed': 'mean3'}).reset_index()    \n",
    "    df_train = pd.merge(df_train, df3, on=['app', 'device'], how='left')\n",
    "    df_val = pd.merge(df_val, df3, on=['app', 'device'], how='left')\n",
    "    #df_test = pd.merge(df_test, df3, on=['app', 'device'], how='left')    \n",
    "    return df_train, df_val #, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ip' 'app' 'device' 'os' 'channel' 'click_time' 'attributed_time'\n",
      " 'is_attributed' 'click_hour']\n",
      "(100000, 9)\n"
     ]
    }
   ],
   "source": [
    "sample = pd.read_csv('input/train_sample.csv', dtype=dtypes, parse_dates=['click_time', 'attributed_time'])\n",
    "sample['click_hour'] = sample.click_time.dt.hour\n",
    "\n",
    "print(sample.columns.values)\n",
    "print(sample.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.topology import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "EMBEDS = [\n",
    "    {'name': 'ip', 'dim': [1024, 100]},\n",
    "    {'name': 'app', 'dim': [1024, 100]},\n",
    "    {'name': 'device', 'dim': [1024, 50]},\n",
    "    {'name': 'os', 'dim': [1024, 50]},\n",
    "    {'name': 'channel', 'dim': [1024, 50]},\n",
    "    {'name': 'click_hour', 'dim': [24, 5]}\n",
    "]\n",
    "\n",
    "def embed(input_dim, output_dim, x):\n",
    "    e = Embedding(input_dim, output_dim, input_length=1, embeddings_regularizer=l2(1e-8))\n",
    "    r = e(x)\n",
    "    r = Reshape((output_dim,))(r)\n",
    "    return r\n",
    "\n",
    "def build_model(features):\n",
    "    misc = Input(shape=(features,), name='misc')\n",
    "    \n",
    "    for e in EMBEDS:\n",
    "        e['input'] = Input(shape=(1,), name=e['name'])\n",
    "        e['layer'] = embed(e['dim'][0], e['dim'][1], e['input'])\n",
    "        \n",
    "    h = concatenate([misc] + [e['layer'] for e in EMBEDS])\n",
    "    h = BatchNormalization()(h)\n",
    "    \n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    h = Dropout(0.5)(h)\n",
    "    \n",
    "    h = Dense(16, activation='relu')(h)\n",
    "    \n",
    "    h = Dense(1, activation='sigmoid')(h)\n",
    "    \n",
    "    model = Model(\n",
    "            inputs=[misc] + [e['input'] for e in EMBEDS],\n",
    "            outputs=h)\n",
    "    \n",
    "    #model.compile(optimizer='sgd', loss='binary_crossentropy')\n",
    "    model.compile(optimizer='sgd', loss=roc_auc_score_fn)\n",
    "    return model    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def roc_auc_score_fn(y_true, y_pred):\n",
    "    \"\"\" ROC AUC Score.\n",
    "    \n",
    "    Source:\n",
    "    https://github.com/tflearn/tflearn/blob/1b0e4d3539e1c4c6b31735499328c27da3a874b0/tflearn/objectives.py\n",
    "    \n",
    "    Approximates the Area Under Curve score, using approximation based on\n",
    "    the Wilcoxon-Mann-Whitney U statistic.\n",
    "    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n",
    "    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n",
    "    Measures overall performance for a full range of threshold levels.\n",
    "    `y_pred` and `y_true` must have the same type and shape.\n",
    "    \"\"\"\n",
    "    pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n",
    "    neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n",
    "\n",
    "    pos = tf.expand_dims(pos, 0)\n",
    "    neg = tf.expand_dims(neg, 1)\n",
    "\n",
    "    # original paper suggests performance is robust to exact parameter choice\n",
    "    gamma = 0.2\n",
    "    p     = 3\n",
    "\n",
    "    difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n",
    "\n",
    "    masked = tf.boolean_mask(difference, difference < 0.0)\n",
    "\n",
    "    return tf.reduce_sum(tf.pow(-masked, p))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashed(s, size=10):\n",
    "    return s.apply(lambda x: hash(x) % 2 ** size)\n",
    "\n",
    "def build_input(df):\n",
    "    embed_names = [e['name'] for e in EMBEDS]\n",
    "    h = {'misc': df[[x for x in df.columns if x not in embed_names]] }\n",
    "    h.update(dict([(name, hashed(df.loc[:, name]).values) for name in embed_names]))\n",
    "    return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMetric(keras.callbacks.Callback):    \n",
    "    def __init__(self, val_x, val_y):\n",
    "        self.val_x = val_x\n",
    "        self.val_y = val_y\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is not None:\n",
    "            logs['val-auc'] = roc_auc_score(self.val_y, self.model.predict(self.val_x).ravel())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  0\n",
      "WARNING:tensorflow:From /opt/miniconda2/envs/talkingdata/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /opt/miniconda2/envs/talkingdata/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 89999 samples, validate on 10001 samples\n",
      "Epoch 1/5\n",
      "89952/89999 [============================>.] - ETA: 0s - loss: 0.0173Epoch 00001: val-auc improved from -inf to 0.92763, saving model to tmp/weights.hdf5\n",
      "89999/89999 [==============================] - 14s 160us/step - loss: 0.0173 - val_loss: 0.0047\n",
      "Epoch 2/5\n",
      "89760/89999 [============================>.] - ETA: 0s - loss: 0.0081Epoch 00002: val-auc improved from 0.92763 to 0.96923, saving model to tmp/weights.hdf5\n",
      "89999/89999 [==============================] - 14s 153us/step - loss: 0.0081 - val_loss: 0.0027\n",
      "Epoch 3/5\n",
      "89728/89999 [============================>.] - ETA: 0s - loss: 0.0053Epoch 00003: val-auc improved from 0.96923 to 0.97158, saving model to tmp/weights.hdf5\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 4/5\n",
      "89984/89999 [============================>.] - ETA: 0s - loss: 0.0029Epoch 00004: val-auc improved from 0.97158 to 0.97757, saving model to tmp/weights.hdf5\n",
      "89999/89999 [==============================] - 14s 153us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 5/5\n",
      "89632/89999 [============================>.] - ETA: 0s - loss: 0.0016Epoch 00005: val-auc improved from 0.97757 to 0.97980, saving model to tmp/weights.hdf5\n",
      "89999/89999 [==============================] - 14s 152us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "fold 0, best train-auc: 0.9885535298812436 val-auc: 0.9798033935527727\n",
      "fold  1\n",
      "Train on 89999 samples, validate on 10001 samples\n",
      "Epoch 1/5\n",
      "89792/89999 [============================>.] - ETA: 0s - loss: 0.0161Epoch 00001: val-auc improved from -inf to 0.90992, saving model to tmp/weights.hdf5\n",
      "89999/89999 [==============================] - 14s 160us/step - loss: 0.0160 - val_loss: 0.0078\n",
      "Epoch 2/5\n",
      "89664/89999 [============================>.] - ETA: 0s - loss: 0.0097Epoch 00002: val-auc improved from 0.90992 to 0.93606, saving model to tmp/weights.hdf5\n",
      "89999/89999 [==============================] - 14s 153us/step - loss: 0.0097 - val_loss: 0.0066\n",
      "Epoch 3/5\n",
      "89856/89999 [============================>.] - ETA: 0s - loss: 0.0064Epoch 00003: val-auc improved from 0.93606 to 0.95489, saving model to tmp/weights.hdf5\n",
      "89999/89999 [==============================] - 14s 153us/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 4/5\n",
      "89888/89999 [============================>.] - ETA: 0s - loss: 0.0043Epoch 00004: val-auc did not improve\n",
      "89999/89999 [==============================] - 14s 152us/step - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 5/5\n",
      "89952/89999 [============================>.] - ETA: 0s - loss: 0.0040Epoch 00005: val-auc improved from 0.95489 to 0.95510, saving model to tmp/weights.hdf5\n",
      "89999/89999 [==============================] - 14s 152us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "fold 1, best train-auc: 0.9843138346713483 val-auc: 0.9551012226899179\n",
      "fold  2\n",
      "Train on 89999 samples, validate on 10001 samples\n",
      "Epoch 1/5\n",
      "89696/89999 [============================>.] - ETA: 0s - loss: 0.0141Epoch 00001: val-auc improved from -inf to 0.84223, saving model to tmp/weights.hdf5\n",
      "89999/89999 [==============================] - 15s 163us/step - loss: 0.0140 - val_loss: 0.0091\n",
      "Epoch 2/5\n",
      "89984/89999 [============================>.] - ETA: 0s - loss: 0.0062Epoch 00002: val-auc improved from 0.84223 to 0.90510, saving model to tmp/weights.hdf5\n",
      "89999/89999 [==============================] - 14s 153us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 3/5\n",
      "89664/89999 [============================>.] - ETA: 0s - loss: 0.0041Epoch 00003: val-auc improved from 0.90510 to 0.90724, saving model to tmp/weights.hdf5\n",
      "89999/89999 [==============================] - 14s 153us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 4/5\n",
      "89824/89999 [============================>.] - ETA: 0s - loss: 0.0033Epoch 00004: val-auc did not improve\n",
      "89999/89999 [==============================] - 14s 152us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 5/5\n",
      "89888/89999 [============================>.] - ETA: 0s - loss: 0.0023Epoch 00005: val-auc improved from 0.90724 to 0.91784, saving model to tmp/weights.hdf5\n",
      "89999/89999 [==============================] - 14s 152us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "fold 2, best train-auc: 0.9929896692793717 val-auc: 0.9178409893069099\n",
      "fold  3\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0205Epoch 00001: val-auc improved from -inf to 0.93529, saving model to tmp/weights.hdf5\n",
      "90000/90000 [==============================] - 15s 165us/step - loss: 0.0205 - val_loss: 0.0035\n",
      "Epoch 2/5\n",
      "89952/90000 [============================>.] - ETA: 0s - loss: 0.0095Epoch 00002: val-auc did not improve\n",
      "90000/90000 [==============================] - 14s 152us/step - loss: 0.0095 - val_loss: 0.0063\n",
      "Epoch 3/5\n",
      "89632/90000 [============================>.] - ETA: 0s - loss: 0.0022Epoch 00003: val-auc improved from 0.93529 to 0.93926, saving model to tmp/weights.hdf5\n",
      "90000/90000 [==============================] - 14s 152us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 4/5\n",
      "89888/90000 [============================>.] - ETA: 0s - loss: 0.0027Epoch 00004: val-auc improved from 0.93926 to 0.94061, saving model to tmp/weights.hdf5\n",
      "90000/90000 [==============================] - 14s 152us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 5/5\n",
      "89664/90000 [============================>.] - ETA: 0s - loss: 0.0026Epoch 00005: val-auc improved from 0.94061 to 0.94518, saving model to tmp/weights.hdf5\n",
      "90000/90000 [==============================] - 14s 152us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "fold 3, best train-auc: 0.9924053344443483 val-auc: 0.9451826156682107\n",
      "fold  4\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "89920/90000 [============================>.] - ETA: 0s - loss: 0.0178Epoch 00001: val-auc improved from -inf to 0.93241, saving model to tmp/weights.hdf5\n",
      "90000/90000 [==============================] - 15s 167us/step - loss: 0.0177 - val_loss: 0.0052\n",
      "Epoch 2/5\n",
      "89792/90000 [============================>.] - ETA: 0s - loss: 0.0091Epoch 00002: val-auc did not improve\n",
      "90000/90000 [==============================] - 14s 152us/step - loss: 0.0091 - val_loss: 0.0076\n",
      "Epoch 3/5\n",
      "89760/90000 [============================>.] - ETA: 0s - loss: 0.0064Epoch 00003: val-auc did not improve\n",
      "90000/90000 [==============================] - 14s 153us/step - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 4/5\n",
      "89984/90000 [============================>.] - ETA: 0s - loss: 0.0043Epoch 00004: val-auc did not improve\n",
      "90000/90000 [==============================] - 14s 151us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 5/5\n",
      "89760/90000 [============================>.] - ETA: 0s - loss: 0.0022Epoch 00005: val-auc did not improve\n",
      "90000/90000 [==============================] - 15s 162us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "fold 4, best train-auc: 0.9601504423097583 val-auc: 0.9324075809143639\n",
      "fold  5\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "89888/90000 [============================>.] - ETA: 0s - loss: 0.0233Epoch 00001: val-auc improved from -inf to 0.82401, saving model to tmp/weights.hdf5\n",
      "90000/90000 [==============================] - 15s 168us/step - loss: 0.0232 - val_loss: 0.0084\n",
      "Epoch 2/5\n",
      "89824/90000 [============================>.] - ETA: 0s - loss: 0.0108Epoch 00002: val-auc improved from 0.82401 to 0.90947, saving model to tmp/weights.hdf5\n",
      "90000/90000 [==============================] - 14s 152us/step - loss: 0.0108 - val_loss: 0.0062\n",
      "Epoch 3/5\n",
      "89664/90000 [============================>.] - ETA: 0s - loss: 0.0093Epoch 00003: val-auc improved from 0.90947 to 0.93740, saving model to tmp/weights.hdf5\n",
      "90000/90000 [==============================] - 14s 152us/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 4/5\n",
      "89984/90000 [============================>.] - ETA: 0s - loss: 0.0045Epoch 00004: val-auc improved from 0.93740 to 0.94960, saving model to tmp/weights.hdf5\n",
      "90000/90000 [==============================] - 14s 152us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 5/5\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0030Epoch 00005: val-auc did not improve\n",
      "90000/90000 [==============================] - 14s 151us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "fold 5, best train-auc: 0.9886099669053777 val-auc: 0.949597116847009\n",
      "fold  6\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "89888/90000 [============================>.] - ETA: 0s - loss: 0.0184Epoch 00001: val-auc improved from -inf to 0.94750, saving model to tmp/weights.hdf5\n",
      "90000/90000 [==============================] - 15s 171us/step - loss: 0.0184 - val_loss: 0.0036\n",
      "Epoch 2/5\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0096Epoch 00002: val-auc did not improve\n",
      "90000/90000 [==============================] - 14s 152us/step - loss: 0.0096 - val_loss: 0.0053\n",
      "Epoch 3/5\n",
      "89664/90000 [============================>.] - ETA: 0s - loss: 0.0062Epoch 00003: val-auc improved from 0.94750 to 0.96081, saving model to tmp/weights.hdf5\n",
      "90000/90000 [==============================] - 14s 152us/step - loss: 0.0062 - val_loss: 0.0026\n",
      "Epoch 4/5\n",
      "89824/90000 [============================>.] - ETA: 0s - loss: 0.0047Epoch 00004: val-auc improved from 0.96081 to 0.97216, saving model to tmp/weights.hdf5\n",
      "90000/90000 [==============================] - 14s 152us/step - loss: 0.0047 - val_loss: 0.0015\n",
      "Epoch 5/5\n",
      "89760/90000 [============================>.] - ETA: 0s - loss: 0.0032Epoch 00005: val-auc improved from 0.97216 to 0.97951, saving model to tmp/weights.hdf5\n",
      "90000/90000 [==============================] - 14s 152us/step - loss: 0.0032 - val_loss: 0.0012\n",
      "fold 6, best train-auc: 0.988788339626465 val-auc: 0.9795050354946812\n",
      "fold  7\n",
      "Train on 90001 samples, validate on 9999 samples\n",
      "Epoch 1/5\n",
      "89984/90001 [============================>.] - ETA: 0s - loss: 0.0236Epoch 00001: val-auc improved from -inf to 0.84880, saving model to tmp/weights.hdf5\n",
      "90001/90001 [==============================] - 16s 172us/step - loss: 0.0236 - val_loss: 0.0310\n",
      "Epoch 2/5\n",
      "89952/90001 [============================>.] - ETA: 0s - loss: 0.0119Epoch 00002: val-auc did not improve\n",
      "90001/90001 [==============================] - 14s 153us/step - loss: 0.0119 - val_loss: 0.0107\n",
      "Epoch 3/5\n",
      "89696/90001 [============================>.] - ETA: 0s - loss: 0.0125Epoch 00003: val-auc improved from 0.84880 to 0.85150, saving model to tmp/weights.hdf5\n",
      "90001/90001 [==============================] - 14s 153us/step - loss: 0.0125 - val_loss: 0.0115\n",
      "Epoch 4/5\n",
      "89664/90001 [============================>.] - ETA: 0s - loss: 0.0073Epoch 00004: val-auc did not improve\n",
      "90001/90001 [==============================] - 14s 152us/step - loss: 0.0073 - val_loss: 0.0250\n",
      "Epoch 5/5\n",
      "89952/90001 [============================>.] - ETA: 0s - loss: 0.0049Epoch 00005: val-auc improved from 0.85150 to 0.85711, saving model to tmp/weights.hdf5\n",
      "90001/90001 [==============================] - 14s 153us/step - loss: 0.0049 - val_loss: 0.0329\n",
      "fold 7, best train-auc: 0.9813743944268254 val-auc: 0.8571122673057122\n",
      "fold  8\n",
      "Train on 90001 samples, validate on 9999 samples\n",
      "Epoch 1/5\n",
      "89792/90001 [============================>.] - ETA: 0s - loss: 0.0152Epoch 00001: val-auc improved from -inf to 0.98933, saving model to tmp/weights.hdf5\n",
      "90001/90001 [==============================] - 16s 175us/step - loss: 0.0152 - val_loss: 0.0014\n",
      "Epoch 2/5\n",
      "89792/90001 [============================>.] - ETA: 0s - loss: 0.0049Epoch 00002: val-auc improved from 0.98933 to 0.99477, saving model to tmp/weights.hdf5\n",
      "90001/90001 [==============================] - 14s 153us/step - loss: 0.0049 - val_loss: 8.4745e-04\n",
      "Epoch 3/5\n",
      "89856/90001 [============================>.] - ETA: 0s - loss: 0.0029Epoch 00003: val-auc improved from 0.99477 to 0.99488, saving model to tmp/weights.hdf5\n",
      "90001/90001 [==============================] - 14s 153us/step - loss: 0.0029 - val_loss: 7.7584e-04\n",
      "Epoch 4/5\n",
      "89888/90001 [============================>.] - ETA: 0s - loss: 0.0024Epoch 00004: val-auc improved from 0.99488 to 0.99538, saving model to tmp/weights.hdf5\n",
      "90001/90001 [==============================] - 14s 153us/step - loss: 0.0024 - val_loss: 6.2788e-04\n",
      "Epoch 5/5\n",
      "89792/90001 [============================>.] - ETA: 0s - loss: 0.0015Epoch 00005: val-auc did not improve\n",
      "90001/90001 [==============================] - 14s 153us/step - loss: 0.0015 - val_loss: 6.7796e-04\n",
      "fold 8, best train-auc: 0.9928651555993042 val-auc: 0.995384839676711\n",
      "fold  9\n",
      "Train on 90001 samples, validate on 9999 samples\n",
      "Epoch 1/5\n",
      "89984/90001 [============================>.] - ETA: 0s - loss: 0.0290Epoch 00001: val-auc improved from -inf to 0.97193, saving model to tmp/weights.hdf5\n",
      "90001/90001 [==============================] - 16s 177us/step - loss: 0.0290 - val_loss: 0.0036\n",
      "Epoch 2/5\n",
      "89664/90001 [============================>.] - ETA: 0s - loss: 0.0130Epoch 00002: val-auc did not improve\n",
      "90001/90001 [==============================] - 14s 152us/step - loss: 0.0139 - val_loss: 0.0054\n",
      "Epoch 3/5\n",
      "89664/90001 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00003: val-auc did not improve\n",
      "90001/90001 [==============================] - 14s 153us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 4/5\n",
      "89792/90001 [============================>.] - ETA: 0s - loss: 0.0024Epoch 00004: val-auc improved from 0.97193 to 0.97593, saving model to tmp/weights.hdf5\n",
      "90001/90001 [==============================] - 14s 153us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 5/5\n",
      "89632/90001 [============================>.] - ETA: 0s - loss: 0.0031Epoch 00005: val-auc did not improve\n",
      "90001/90001 [==============================] - 14s 153us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "fold 9, best train-auc: 0.9897515941282624 val-auc: 0.9759310049477435\n",
      "final val auc 0.5065177247506024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = sample\n",
    "y_train = sample.is_attributed.values\n",
    "\n",
    "oof_pred = np.zeros_like(y_train)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for fold_no, (train_index, dev_index) in enumerate(skf.split(X_train, y_train)):\n",
    "    X_train1, X_dev1 = X_train.iloc[train_index], X_train.iloc[dev_index]\n",
    "    y_train1, y_dev1 = y_train[train_index], y_train[dev_index]\n",
    "    \n",
    "    #build features inside fold.\n",
    "    #X_train1, X_dev1 = add_meanx2(X_train1, X_dev1)    \n",
    "    \n",
    "    X_train1 = X_train1.drop(['attributed_time', 'click_time', 'is_attributed'], axis=1)\n",
    "    X_dev1 = X_dev1.drop(['attributed_time', 'click_time', 'is_attributed'], axis=1)\n",
    "    \n",
    "    \n",
    "    train1_input = build_input(X_train1)\n",
    "    dev_input = build_input(X_dev1)\n",
    "    \n",
    "    print('fold ', fold_no)\n",
    "    model = build_model(train1_input['misc'].shape[1])\n",
    "    \n",
    "    # callbacks\n",
    "    ckpt = keras.callbacks.ModelCheckpoint(filepath='tmp/weights.hdf5', \n",
    "                                           # val-auc is calculated by the custom eval_callback\n",
    "                                           monitor='val-auc', mode='max',\n",
    "                                           verbose=1, save_best_only=True)    \n",
    "    eval_callback = CustomMetric(dev_input, y_dev1)\n",
    "    \n",
    "    model.fit(train1_input, y_train1, \n",
    "              validation_data=(dev_input, y_dev1),\n",
    "              callbacks=[eval_callback, ckpt],\n",
    "              epochs=5)\n",
    "    \n",
    "    model.load_weights('tmp/weights.hdf5')\n",
    "    \n",
    "    print('fold {}, best train-auc: {} val-auc: {}'.format(\n",
    "        fold_no, \n",
    "        roc_auc_score(y_train1, model.predict(train1_input).ravel()),\n",
    "        roc_auc_score(y_dev1, model.predict(dev_input).ravel())))\n",
    "    \n",
    "    oof_pred[dev_index] = model.predict(dev_input).ravel()\n",
    "\n",
    "print('final val auc', roc_auc_score(y_train, oof_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
