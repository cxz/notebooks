{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Draft.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "SEED=42\n",
    "\n",
    "D=12\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'ip':'uint32',\n",
    "    'app': 'uint16',\n",
    "    'device': 'uint16',\n",
    "    'os': 'uint16',\n",
    "    'channel': 'uint16',\n",
    "    'is_attributed': 'uint8'\n",
    "}   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample():\n",
    "    sample = pd.read_csv('input/train_sample.csv', dtype=dtypes, parse_dates=['click_time', 'attributed_time'])\n",
    "    sample['app_channel'] = sample[['app', 'channel']].apply(lambda row: ' '.join([str(row['app']), str(row['channel'])]), axis=1)\n",
    "    sample['app_device'] = sample[['app', 'device']].apply(lambda row: ' '.join([str(row['app']), str(row['device'])]), axis=1)\n",
    "    sample['ip_device'] = sample[['ip', 'device']].apply(lambda row: ' '.join([str(row['ip']), str(row['device'])]), axis=1)\n",
    "    sample['click_hour'] = sample.click_time.dt.hour\n",
    "    sample['click_minute'] = sample.click_time.dt.minute\n",
    "\n",
    "    print(sample.columns.values)\n",
    "    print(sample.shape)\n",
    "    return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.topology import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "# Important to keep same ordering as in train.npz & test.npz            \n",
    "EMBEDS = [\n",
    "    {'name': 'ip', 'dim': [2**D, 100]},\n",
    "    {'name': 'app', 'dim': [2**D, 100]},\n",
    "    {'name': 'device', 'dim': [2**D, 50]},\n",
    "    {'name': 'os', 'dim': [2**D, 50]},\n",
    "    {'name': 'channel', 'dim': [2**D, 50]},\n",
    "    {'name': 'app_channel', 'dim': [2**D, 100]},\n",
    "    {'name': 'app_device', 'dim': [2**D, 100]},\n",
    "    {'name': 'ip_device', 'dim': [2**D, 100]},\n",
    "    {'name': 'click_hour', 'dim': [24, 5]},\n",
    "    {'name': 'click_minute', 'dim': [60, 5]}\n",
    "]\n",
    "\n",
    "def embed(input_dim, output_dim, x):\n",
    "    e = Embedding(input_dim, output_dim, input_length=1, embeddings_regularizer=l2(1e-8))\n",
    "    r = e(x)\n",
    "    r = Reshape((output_dim,))(r)\n",
    "    return r\n",
    "\n",
    "def build_model(features):    \n",
    "    #misc = Input(shape=(features,), name='misc')\n",
    "    \n",
    "    for e in EMBEDS:\n",
    "        e['input'] = Input(shape=(1,), name=e['name'])\n",
    "        e['layer'] = embed(e['dim'][0], e['dim'][1], e['input'])\n",
    "        \n",
    "    # removed [misc]\n",
    "    h = concatenate([e['layer'] for e in EMBEDS])\n",
    "    h = BatchNormalization()(h)\n",
    "    \n",
    "    h = Dense(128, activation='relu')(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Dropout(0.5)(h)\n",
    "    \n",
    "    h = Dense(64, activation='relu')(h)\n",
    "    #h = BatchNormalization()(h)\n",
    "    h = Dropout(0.2)(h)\n",
    "    \n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    #h = BatchNormalization()(h)\n",
    "    \n",
    "    h = Dense(1, activation='sigmoid')(h)\n",
    "    \n",
    "    # removed [misc]\n",
    "    model = Model(inputs=[e['input'] for e in EMBEDS], \n",
    "                  outputs=h)\n",
    "    return model    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def roc_auc_score_fn(y_true, y_pred):\n",
    "    \"\"\" ROC AUC Score.\n",
    "    \n",
    "    Source:\n",
    "    https://github.com/tflearn/tflearn/blob/1b0e4d3539e1c4c6b31735499328c27da3a874b0/tflearn/objectives.py\n",
    "    \n",
    "    Approximates the Area Under Curve score, using approximation based on\n",
    "    the Wilcoxon-Mann-Whitney U statistic.\n",
    "    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n",
    "    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n",
    "    Measures overall performance for a full range of threshold levels.\n",
    "    `y_pred` and `y_true` must have the same type and shape.\n",
    "    \"\"\"\n",
    "    pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n",
    "    neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n",
    "\n",
    "    pos = tf.expand_dims(pos, 0)\n",
    "    neg = tf.expand_dims(neg, 1)\n",
    "\n",
    "    # original paper suggests performance is robust to exact parameter choice\n",
    "    gamma = 0.2\n",
    "    p     = 3\n",
    "\n",
    "    difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n",
    "\n",
    "    masked = tf.boolean_mask(difference, difference < 0.0)\n",
    "\n",
    "    return tf.reduce_sum(tf.pow(-masked, p))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashed(s, size=D):\n",
    "    return s.apply(lambda x: hash(x) % 2 ** size)\n",
    "\n",
    "def build_input(df):\n",
    "    embed_names = [e['name'] for e in EMBEDS]\n",
    "    h = {'misc': df[[x for x in df.columns if x not in embed_names]] }\n",
    "    h.update(dict([(name, hashed(df.loc[:, name]).values) for name in embed_names]))\n",
    "    return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMetric(keras.callbacks.Callback):    \n",
    "    def __init__(self, val_x, val_y):\n",
    "        self.val_x = val_x\n",
    "        self.val_y = val_y\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is not None:\n",
    "            logs['val-auc'] = roc_auc_score(self.val_y, self.model.predict(self.val_x).ravel())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoldDataset:\n",
    "    def __init__(self, X_train, y_train, X_dev, y_dev):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_dev = X_dev\n",
    "        self.y_dev = y_dev\n",
    "        \n",
    "    def build(self):\n",
    "        #build features inside fold.\n",
    "        #X_train1, X_dev1 = add_meanx2(X_train1, X_dev1)    \n",
    "\n",
    "        X_train1 = self.X_train.drop(['attributed_time', 'click_time', 'is_attributed'], axis=1)\n",
    "        X_dev1 = self.X_dev.drop(['attributed_time', 'click_time', 'is_attributed'], axis=1)\n",
    "\n",
    "        self.train_input = build_input(X_train1)\n",
    "        self.dev_input = build_input(X_dev1)        \n",
    "    \n",
    "    def parts(self):\n",
    "        return self.train_input, self.y_train, self.dev_input, self.y_dev\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, optimizer='sgd', loss='binary_crossentropy'):\n",
    "        # roc_auc_score_fn\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "            \n",
    "    def train(self, fold_no, ds, **fit_args):\n",
    "        \n",
    "        train1_input, y_train, dev_input, y_dev = ds.parts()\n",
    "\n",
    "        if len(train1_input['misc'].shape) == 1:\n",
    "            features = 1\n",
    "        else:\n",
    "            features = train1_input['misc'].shape[1]\n",
    "        model = build_model(features)\n",
    "        model.compile(optimizer=self.optimizer, loss=self.loss)\n",
    "\n",
    "        # callbacks\n",
    "        ckpt = keras.callbacks.ModelCheckpoint(filepath='tmp/weights.hdf5', \n",
    "                                               # val-auc is calculated by the custom eval_callback\n",
    "                                               monitor='val-auc', mode='max',\n",
    "                                               verbose=0, save_best_only=True)    \n",
    "        eval_callback = CustomMetric(dev_input, y_dev)\n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val-auc', mode='max', patience=2)\n",
    "        \n",
    "        fit_args['callbacks']: [eval_callback, ckpt, reduce_lr]        \n",
    "        \n",
    "        if dev_input is None:\n",
    "            fit_args['validation_data'] = None\n",
    "            fit_args['validation_split'] = 0.05\n",
    "        else:\n",
    "            fit_args['validation_data'] = (dev_input, y_dev)\n",
    "\n",
    "        model.fit(train1_input, y_train, **fit_args)\n",
    "\n",
    "        model.load_weights('tmp/weights.hdf5')\n",
    "\n",
    "        print('fold {}, best train-auc: {} val-auc: {}'.format(\n",
    "            fold_no, \n",
    "            roc_auc_score(y_train, model.predict(train1_input).ravel()),\n",
    "            roc_auc_score(y_dev, model.predict(dev_input).ravel())))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def predict(self, model, X_test):\n",
    "        print('.')        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold(splits):\n",
    "    X_train = sample.copy()\n",
    "    y_train = sample.is_attributed.values.copy()\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=SEED)\n",
    "    oof_pred = np.zeros(y_train.shape, dtype=np.float32)\n",
    "\n",
    "    for fold_no, (train_index, dev_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train1, X_dev1 = X_train.iloc[train_index], X_train.iloc[dev_index]\n",
    "        y_train1, y_dev1 = y_train[train_index], y_train[dev_index]\n",
    "\n",
    "        ds = FoldDataset(X_train1, y_train1, X_dev1, y_dev1)\n",
    "        ds.build()\n",
    "\n",
    "        c = Classifier(loss='binary_crossentropy')\n",
    "        model = c.train(fold_no, ds, epochs=10)\n",
    "\n",
    "        _, _, dev_input, _ = ds.parts()\n",
    "        oof_pred[dev_index] = model.predict(dev_input).ravel()\n",
    "\n",
    "    print('final val auc', roc_auc_score(y_train, oof_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10-fold final val auc 0.9624749061426707"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#without kfold, optimizing roc-auc directly.\n",
    "#final val auc varies between 0.958 and 0.970\n",
    "\n",
    "def run_single(test_size=0.1, epochs=4):\n",
    "    X_train = sample.copy()\n",
    "    y_train = sample.is_attributed.values.copy()\n",
    "\n",
    "    X_train1, X_dev1, y_train1, y_dev1 = train_test_split(X_train, y_train, test_size=test_size, random_state=1+SEED, stratify=y_train)\n",
    "\n",
    "    ds = FoldDataset(X_train1, y_train1, X_dev1, y_dev1)\n",
    "    ds.build()\n",
    "\n",
    "    c = Classifier(loss=roc_auc_score_fn)\n",
    "    model = c.train(0, ds, epochs=epochs)\n",
    "\n",
    "    _, _, dev_input, _ = ds.parts()\n",
    "    print('final val auc', roc_auc_score(y_dev1, model.predict(dev_input).ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_single()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! added app_channel, app_device, ip_device and val-auc increased from 0.97 to 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_kfold(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_single_split_by_time(test_size=0.1, epochs=6):\n",
    "    \n",
    "    train_sample = sample[sample.click_time < pd.datetime(2017,11,9)]\n",
    "    dev_sample = sample[sample.click_time >= pd.datetime(2017,11,9)]\n",
    "    \n",
    "    X_train = train_sample.copy()\n",
    "    y_train = train_sample.is_attributed.values.copy()\n",
    "    \n",
    "    X_dev = dev_sample.copy()\n",
    "    y_dev = dev_sample.is_attributed.values.copy()\n",
    "\n",
    "    ds = FoldDataset(X_train, y_train, X_dev, y_dev)\n",
    "    ds.build()\n",
    "\n",
    "    c = Classifier(loss=roc_auc_score_fn)\n",
    "    model = c.train(0, ds, epochs=epochs)\n",
    "\n",
    "    _, _, dev_input, _ = ds.parts()\n",
    "    print('final val auc', roc_auc_score(y_dev, model.predict(dev_input).ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda2/envs/talkingdata/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /opt/miniconda2/envs/talkingdata/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 71439 samples, validate on 28561 samples\n",
      "Epoch 1/6\n",
      "71439/71439 [==============================] - 18s 253us/step - loss: 0.0132 - val_loss: 0.0026\n",
      "Epoch 2/6\n",
      "71439/71439 [==============================] - 17s 241us/step - loss: 0.0051 - val_loss: 0.0019\n",
      "Epoch 3/6\n",
      "71439/71439 [==============================] - 17s 241us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 4/6\n",
      "71439/71439 [==============================] - 17s 241us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 5/6\n",
      "71439/71439 [==============================] - 17s 240us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 6/6\n",
      "71439/71439 [==============================] - 17s 240us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "fold 0, best train-auc: 0.99162356324719 val-auc: 0.9739991484391818\n",
      "final val auc 0.9739991484391818\n"
     ]
    }
   ],
   "source": [
    "#run_single_split_by_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CachedDataset:\n",
    "    def __init__(self, fname):\n",
    "        self.arr = np.load(fname)\n",
    "        self.is_train = False\n",
    "        \n",
    "    def build(self):\n",
    "        self.X = self.arr['x']\n",
    "        if 'y' in self.arr:\n",
    "            self.is_train = True\n",
    "            self.y = self.arr['y']         \n",
    "        self.X_prepared = self.build_input()\n",
    "            \n",
    "    def build_input(self):\n",
    "        embed_names = [e['name'] for e in EMBEDS]\n",
    "        #misc = np.concatenate([self.X[:, 0], self.X[:, idx], ...]) #TODO\n",
    "        misc = self.X[:, 0]\n",
    "        h = {'misc': misc} \n",
    "        h.update(dict([(name, self.X[:, idx]) for idx, name in enumerate(embed_names)]))\n",
    "        return h\n",
    "            \n",
    "    def parts(self):\n",
    "        if self.is_train:\n",
    "            return self.X_prepared, self.y, None, None\n",
    "        else:\n",
    "            return self.X_prepared\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = CachedDataset('tmp/train.npz')\n",
    "ds.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda2/envs/talkingdata/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /opt/miniconda2/envs/talkingdata/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 175658695 samples, validate on 9245195 samples\n",
      "Epoch 1/10\n",
      "  6874432/175658695 [>.............................] - ETA: 4:53:59 - loss: 0.0169"
     ]
    }
   ],
   "source": [
    "c = Classifier(optimizer='sgd', loss=roc_auc_score_fn)\n",
    "model = c.train(0, ds, epochs=10, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, _, _ = ds.parts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['misc', 'ip', 'app', 'device', 'os', 'channel', 'app_channel', 'app_device', 'ip_device', 'click_hour', 'click_minute'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
