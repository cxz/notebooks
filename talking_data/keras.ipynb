{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Draft.\n",
    "\n",
    "Train/test split by time:\n",
    "train [2017-11-06, 2017-11-09]\n",
    "test  [2017-11-10]\n",
    "\n",
    "Cannot use kfold if optimizing ROC for each fold separately. Comparing optimizing xentropy for each fold vs optimizing roc-auc without folds.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "SEED=42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'ip':'uint32',\n",
    "    'app': 'uint16',\n",
    "    'device': 'uint16',\n",
    "    'os': 'uint16',\n",
    "    'channel': 'uint16',\n",
    "    'is_attributed': 'uint8'\n",
    "}   \n",
    "\n",
    "def add_mean(df_train, df_val, df_test=None):\n",
    "    df1 = df_train[['is_attributed', 'app']].groupby(['app']).median().rename(columns={'is_attributed': 'mean1'}).reset_index()\n",
    "    df_train = pd.merge(df_train, df1, on=['app'], how='left')\n",
    "    df_val = pd.merge(df_val, df1, on=['app'], how='left')\n",
    "    #df_test = pd.merge(df_test, df1, on=['app'], how='left')\n",
    "    \n",
    "    df2 = df_train[['is_attributed', 'app', 'channel']].groupby(['app', 'channel']).median().rename(columns={'is_attributed': 'mean2'}).reset_index()    \n",
    "    df_train = pd.merge(df_train, df2, on=['app', 'channel'], how='left')\n",
    "    df_val = pd.merge(df_val, df2, on=['app', 'channel'], how='left')\n",
    "    #df_test = pd.merge(df_test, df2, on=['app', 'channel'], how='left')\n",
    "                   \n",
    "    df3 = df_train[['is_attributed', 'app', 'device']].groupby(['app', 'device']).median().rename(columns={'is_attributed': 'mean3'}).reset_index()    \n",
    "    df_train = pd.merge(df_train, df3, on=['app', 'device'], how='left')\n",
    "    df_val = pd.merge(df_val, df3, on=['app', 'device'], how='left')\n",
    "    #df_test = pd.merge(df_test, df3, on=['app', 'device'], how='left')    \n",
    "    return df_train, df_val #, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ip' 'app' 'device' 'os' 'channel' 'click_time' 'attributed_time'\n",
      " 'is_attributed' 'click_hour']\n",
      "(100000, 9)\n"
     ]
    }
   ],
   "source": [
    "sample = pd.read_csv('input/train_sample.csv', dtype=dtypes, parse_dates=['click_time', 'attributed_time'])\n",
    "sample['click_hour'] = sample.click_time.dt.hour\n",
    "\n",
    "print(sample.columns.values)\n",
    "print(sample.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.topology import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "EMBEDS = [\n",
    "    {'name': 'ip', 'dim': [1024, 100]},\n",
    "    {'name': 'app', 'dim': [1024, 100]},\n",
    "    {'name': 'device', 'dim': [1024, 50]},\n",
    "    {'name': 'os', 'dim': [1024, 50]},\n",
    "    {'name': 'channel', 'dim': [1024, 50]},\n",
    "    {'name': 'click_hour', 'dim': [24, 5]}\n",
    "]\n",
    "\n",
    "def embed(input_dim, output_dim, x):\n",
    "    e = Embedding(input_dim, output_dim, input_length=1, embeddings_regularizer=l2(1e-8))\n",
    "    r = e(x)\n",
    "    r = Reshape((output_dim,))(r)\n",
    "    return r\n",
    "\n",
    "def build_model(features):\n",
    "    misc = Input(shape=(features,), name='misc')\n",
    "    \n",
    "    for e in EMBEDS:\n",
    "        e['input'] = Input(shape=(1,), name=e['name'])\n",
    "        e['layer'] = embed(e['dim'][0], e['dim'][1], e['input'])\n",
    "        \n",
    "    h = concatenate([misc] + [e['layer'] for e in EMBEDS])\n",
    "    h = BatchNormalization()(h)\n",
    "    \n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    h = Dropout(0.5)(h)\n",
    "    \n",
    "    h = Dense(16, activation='relu')(h)    \n",
    "    h = Dense(1, activation='sigmoid')(h)\n",
    "    \n",
    "    model = Model(inputs=[misc] + [e['input'] for e in EMBEDS], \n",
    "                  outputs=h)\n",
    "    return model    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def roc_auc_score_fn(y_true, y_pred):\n",
    "    \"\"\" ROC AUC Score.\n",
    "    \n",
    "    Source:\n",
    "    https://github.com/tflearn/tflearn/blob/1b0e4d3539e1c4c6b31735499328c27da3a874b0/tflearn/objectives.py\n",
    "    \n",
    "    Approximates the Area Under Curve score, using approximation based on\n",
    "    the Wilcoxon-Mann-Whitney U statistic.\n",
    "    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n",
    "    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n",
    "    Measures overall performance for a full range of threshold levels.\n",
    "    `y_pred` and `y_true` must have the same type and shape.\n",
    "    \"\"\"\n",
    "    pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n",
    "    neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n",
    "\n",
    "    pos = tf.expand_dims(pos, 0)\n",
    "    neg = tf.expand_dims(neg, 1)\n",
    "\n",
    "    # original paper suggests performance is robust to exact parameter choice\n",
    "    gamma = 0.2\n",
    "    p     = 3\n",
    "\n",
    "    difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n",
    "\n",
    "    masked = tf.boolean_mask(difference, difference < 0.0)\n",
    "\n",
    "    return tf.reduce_sum(tf.pow(-masked, p))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashed(s, size=10):\n",
    "    return s.apply(lambda x: hash(x) % 2 ** size)\n",
    "\n",
    "def build_input(df):\n",
    "    embed_names = [e['name'] for e in EMBEDS]\n",
    "    h = {'misc': df[[x for x in df.columns if x not in embed_names]] }\n",
    "    h.update(dict([(name, hashed(df.loc[:, name]).values) for name in embed_names]))\n",
    "    return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMetric(keras.callbacks.Callback):    \n",
    "    def __init__(self, val_x, val_y):\n",
    "        self.val_x = val_x\n",
    "        self.val_y = val_y\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is not None:\n",
    "            logs['val-auc'] = roc_auc_score(self.val_y, self.model.predict(self.val_x).ravel())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoldDataset:\n",
    "    def __init__(self, X_train, y_train, X_dev, y_dev):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_dev = X_dev\n",
    "        self.y_dev = y_dev\n",
    "        \n",
    "    def build(self):\n",
    "        #build features inside fold.\n",
    "        #X_train1, X_dev1 = add_meanx2(X_train1, X_dev1)    \n",
    "\n",
    "        X_train1 = self.X_train.drop(['attributed_time', 'click_time', 'is_attributed'], axis=1)\n",
    "        X_dev1 = self.X_dev.drop(['attributed_time', 'click_time', 'is_attributed'], axis=1)\n",
    "\n",
    "        self.train_input = build_input(X_train1)\n",
    "        self.dev_input = build_input(X_dev1)        \n",
    "    \n",
    "    def parts(self):\n",
    "        return self.train_input, self.y_train, self.dev_input, self.y_dev\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, loss='binary_crossentropy'):\n",
    "        # roc_auc_score_fn\n",
    "        self.loss = loss\n",
    "        self.optimizer = 'sgd'\n",
    "            \n",
    "    def train(self, fold_no, ds, epochs=1):\n",
    "        \n",
    "        train1_input, y_train, dev_input, y_dev = ds.parts()\n",
    "\n",
    "        model = build_model(train1_input['misc'].shape[1])\n",
    "        model.compile(optimizer=self.optimizer, loss=self.loss)\n",
    "\n",
    "        # callbacks\n",
    "        ckpt = keras.callbacks.ModelCheckpoint(filepath='tmp/weights.hdf5', \n",
    "                                               # val-auc is calculated by the custom eval_callback\n",
    "                                               monitor='val-auc', mode='max',\n",
    "                                               verbose=0, save_best_only=True)    \n",
    "        eval_callback = CustomMetric(dev_input, y_dev1)\n",
    "\n",
    "        model.fit(train1_input, y_train1, \n",
    "                  validation_data=(dev_input, y_dev1),\n",
    "                  callbacks=[eval_callback, ckpt],\n",
    "                  epochs=epochs)\n",
    "\n",
    "        model.load_weights('tmp/weights.hdf5')\n",
    "\n",
    "        print('fold {}, best train-auc: {} val-auc: {}'.format(\n",
    "            fold_no, \n",
    "            roc_auc_score(y_train1, model.predict(train1_input).ravel()),\n",
    "            roc_auc_score(y_dev1, model.predict(dev_input).ravel())))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def predict(self, model, X_test):\n",
    "        print('.')        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 89999 samples, validate on 10001 samples\n",
      "Epoch 1/10\n",
      "89999/89999 [==============================] - 15s 168us/step - loss: 0.0334 - val_loss: 0.0086\n",
      "Epoch 2/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0117 - val_loss: 0.0075\n",
      "Epoch 3/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0102 - val_loss: 0.0075\n",
      "Epoch 4/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 5/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 6/10\n",
      "89999/89999 [==============================] - 14s 153us/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 7/10\n",
      "89999/89999 [==============================] - 14s 153us/step - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 8/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 9/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "89999/89999 [==============================] - 14s 153us/step - loss: 0.0068 - val_loss: 0.0079\n",
      "fold 0, best train-auc: 0.997122203188308 val-auc: 0.9744829930194254\n",
      "Train on 89999 samples, validate on 10001 samples\n",
      "Epoch 1/10\n",
      "89999/89999 [==============================] - 15s 169us/step - loss: 0.0315 - val_loss: 0.0095\n",
      "Epoch 2/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0119 - val_loss: 0.0089\n",
      "Epoch 3/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 4/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0095 - val_loss: 0.0086\n",
      "Epoch 5/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0085 - val_loss: 0.0086\n",
      "Epoch 6/10\n",
      "89999/89999 [==============================] - 14s 153us/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 7/10\n",
      "89999/89999 [==============================] - 14s 153us/step - loss: 0.0082 - val_loss: 0.0090\n",
      "Epoch 8/10\n",
      "89999/89999 [==============================] - 14s 153us/step - loss: 0.0078 - val_loss: 0.0089\n",
      "Epoch 9/10\n",
      "89999/89999 [==============================] - 14s 153us/step - loss: 0.0073 - val_loss: 0.0088\n",
      "Epoch 10/10\n",
      "89999/89999 [==============================] - 14s 153us/step - loss: 0.0073 - val_loss: 0.0091\n",
      "fold 1, best train-auc: 0.9899739220817788 val-auc: 0.9560816404786182\n",
      "Train on 89999 samples, validate on 10001 samples\n",
      "Epoch 1/10\n",
      "89999/89999 [==============================] - 15s 172us/step - loss: 0.0432 - val_loss: 0.0090\n",
      "Epoch 2/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0123 - val_loss: 0.0080\n",
      "Epoch 3/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0105 - val_loss: 0.0076\n",
      "Epoch 4/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0098 - val_loss: 0.0074\n",
      "Epoch 5/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0093 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0083 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0080 - val_loss: 0.0069\n",
      "Epoch 8/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0082 - val_loss: 0.0068\n",
      "Epoch 9/10\n",
      "89999/89999 [==============================] - 14s 154us/step - loss: 0.0077 - val_loss: 0.0067\n",
      "Epoch 10/10\n",
      "89999/89999 [==============================] - 14s 153us/step - loss: 0.0073 - val_loss: 0.0067\n",
      "fold 2, best train-auc: 0.9945358381673288 val-auc: 0.9675939240241576\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "90000/90000 [==============================] - 16s 177us/step - loss: 0.0309 - val_loss: 0.0106\n",
      "Epoch 2/10\n",
      "90000/90000 [==============================] - 14s 154us/step - loss: 0.0118 - val_loss: 0.0103\n",
      "Epoch 3/10\n",
      "90000/90000 [==============================] - 14s 154us/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 4/10\n",
      "90000/90000 [==============================] - 14s 154us/step - loss: 0.0091 - val_loss: 0.0099\n",
      "Epoch 5/10\n",
      "90000/90000 [==============================] - 14s 154us/step - loss: 0.0088 - val_loss: 0.0098\n",
      "Epoch 6/10\n",
      "90000/90000 [==============================] - 14s 154us/step - loss: 0.0083 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "90000/90000 [==============================] - 14s 154us/step - loss: 0.0079 - val_loss: 0.0097\n",
      "Epoch 8/10\n",
      "90000/90000 [==============================] - 14s 154us/step - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 9/10\n",
      "90000/90000 [==============================] - 14s 154us/step - loss: 0.0072 - val_loss: 0.0099\n",
      "Epoch 10/10\n",
      "90000/90000 [==============================] - 14s 154us/step - loss: 0.0070 - val_loss: 0.0100\n",
      "fold 3, best train-auc: 0.9626210205004982 val-auc: 0.9474094765787398\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "90000/90000 [==============================] - 16s 179us/step - loss: 0.0349 - val_loss: 0.0102\n",
      "Epoch 2/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0118 - val_loss: 0.0093\n",
      "Epoch 3/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0106 - val_loss: 0.0089\n",
      "Epoch 4/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 5/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0084 - val_loss: 0.0086\n",
      "Epoch 7/10\n",
      "90000/90000 [==============================] - 14s 154us/step - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 8/10\n",
      "90000/90000 [==============================] - 14s 154us/step - loss: 0.0075 - val_loss: 0.0087\n",
      "Epoch 9/10\n",
      "90000/90000 [==============================] - 14s 154us/step - loss: 0.0074 - val_loss: 0.0089\n",
      "Epoch 10/10\n",
      "90000/90000 [==============================] - 14s 154us/step - loss: 0.0071 - val_loss: 0.0089\n",
      "fold 4, best train-auc: 0.9861640360852791 val-auc: 0.958504560489125\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "90000/90000 [==============================] - 16s 181us/step - loss: 0.0353 - val_loss: 0.0090\n",
      "Epoch 2/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0120 - val_loss: 0.0083\n",
      "Epoch 3/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0103 - val_loss: 0.0081\n",
      "Epoch 4/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 5/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 6/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 7/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 8/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0076 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0075 - val_loss: 0.0083\n",
      "Epoch 10/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0072 - val_loss: 0.0083\n",
      "fold 5, best train-auc: 0.99029734282238 val-auc: 0.9774612042480314\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "90000/90000 [==============================] - 16s 181us/step - loss: 0.0382 - val_loss: 0.0091\n",
      "Epoch 2/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0123 - val_loss: 0.0082\n",
      "Epoch 3/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0106 - val_loss: 0.0079\n",
      "Epoch 4/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 5/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0088 - val_loss: 0.0074\n",
      "Epoch 6/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0085 - val_loss: 0.0074\n",
      "Epoch 7/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 8/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 9/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 10/10\n",
      "90000/90000 [==============================] - 14s 155us/step - loss: 0.0071 - val_loss: 0.0074\n",
      "fold 6, best train-auc: 0.9972164302265965 val-auc: 0.9698763678198988\n",
      "Train on 90001 samples, validate on 9999 samples\n",
      "Epoch 1/10\n",
      "90001/90001 [==============================] - 16s 183us/step - loss: 0.0299 - val_loss: 0.0101\n",
      "Epoch 2/10\n",
      "90001/90001 [==============================] - 14s 155us/step - loss: 0.0116 - val_loss: 0.0097\n",
      "Epoch 3/10\n",
      "90001/90001 [==============================] - 14s 155us/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 4/10\n",
      "90001/90001 [==============================] - 14s 155us/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 5/10\n",
      "90001/90001 [==============================] - 14s 155us/step - loss: 0.0085 - val_loss: 0.0096\n",
      "Epoch 6/10\n",
      "90001/90001 [==============================] - 14s 155us/step - loss: 0.0079 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "90001/90001 [==============================] - 14s 156us/step - loss: 0.0080 - val_loss: 0.0092\n",
      "Epoch 8/10\n",
      "90001/90001 [==============================] - 14s 155us/step - loss: 0.0075 - val_loss: 0.0093\n",
      "Epoch 9/10\n",
      "90001/90001 [==============================] - 14s 155us/step - loss: 0.0073 - val_loss: 0.0095\n",
      "Epoch 10/10\n",
      "90001/90001 [==============================] - 14s 155us/step - loss: 0.0071 - val_loss: 0.0096\n",
      "fold 7, best train-auc: 0.9940143186344332 val-auc: 0.9814391281766244\n",
      "Train on 90001 samples, validate on 9999 samples\n",
      "Epoch 1/10\n",
      "90001/90001 [==============================] - 17s 185us/step - loss: 0.0349 - val_loss: 0.0113\n",
      "Epoch 2/10\n",
      "90001/90001 [==============================] - 14s 156us/step - loss: 0.0120 - val_loss: 0.0108\n",
      "Epoch 3/10\n",
      "90001/90001 [==============================] - 14s 156us/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 4/10\n",
      "90001/90001 [==============================] - 14s 155us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 5/10\n",
      "90001/90001 [==============================] - 14s 156us/step - loss: 0.0090 - val_loss: 0.0102\n",
      "Epoch 6/10\n",
      "90001/90001 [==============================] - 14s 156us/step - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 7/10\n",
      "90001/90001 [==============================] - 14s 156us/step - loss: 0.0081 - val_loss: 0.0102\n",
      "Epoch 8/10\n",
      "90001/90001 [==============================] - 14s 155us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 9/10\n",
      "90001/90001 [==============================] - 14s 155us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 10/10\n",
      "90001/90001 [==============================] - 14s 155us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "fold 8, best train-auc: 0.9842504799496746 val-auc: 0.9172323617046481\n",
      "Train on 90001 samples, validate on 9999 samples\n",
      "Epoch 1/10\n",
      "90001/90001 [==============================] - 17s 189us/step - loss: 0.0438 - val_loss: 0.0093\n",
      "Epoch 2/10\n",
      "90001/90001 [==============================] - 14s 156us/step - loss: 0.0120 - val_loss: 0.0087\n",
      "Epoch 3/10\n",
      "90001/90001 [==============================] - 14s 156us/step - loss: 0.0106 - val_loss: 0.0081\n",
      "Epoch 4/10\n",
      "90001/90001 [==============================] - 14s 156us/step - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 5/10\n",
      "90001/90001 [==============================] - 14s 156us/step - loss: 0.0088 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "90001/90001 [==============================] - 14s 156us/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 7/10\n",
      "90001/90001 [==============================] - 14s 156us/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 8/10\n",
      "90001/90001 [==============================] - 14s 155us/step - loss: 0.0078 - val_loss: 0.0080\n",
      "Epoch 9/10\n",
      "90001/90001 [==============================] - 14s 155us/step - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "90001/90001 [==============================] - 14s 155us/step - loss: 0.0070 - val_loss: 0.0079\n",
      "fold 9, best train-auc: 0.9951781490619931 val-auc: 0.9758398862839076\n",
      "final val auc 0.9624749061426707\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = sample.copy()\n",
    "y_train = sample.is_attributed.values.copy()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "oof_pred = np.zeros(y_train.shape, dtype=np.float32)\n",
    "\n",
    "for fold_no, (train_index, dev_index) in enumerate(skf.split(X_train, y_train)):\n",
    "    X_train1, X_dev1 = X_train.iloc[train_index], X_train.iloc[dev_index]\n",
    "    y_train1, y_dev1 = y_train[train_index], y_train[dev_index]\n",
    "\n",
    "    ds = FoldDataset(X_train1, y_train1, X_dev1, y_dev1)\n",
    "    ds.build()\n",
    "    \n",
    "    c = Classifier(loss='binary_crossentropy')\n",
    "    model = c.train(fold_no, ds, epochs=10)\n",
    "    \n",
    "    _, _, dev_input, _ = ds.parts()\n",
    "    oof_pred[dev_index] = model.predict(dev_input).ravel()\n",
    "\n",
    "print('final val auc', roc_auc_score(y_train, oof_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10-fold final val auc 0.9624749061426707"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 17s 207us/step - loss: 0.0170 - val_loss: 0.0043\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 14s 170us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 14s 170us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 14s 171us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 14s 170us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 14s 170us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 14s 170us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 14s 170us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 14s 170us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 14s 170us/step - loss: 9.1383e-04 - val_loss: 0.0024\n",
      "fold 0, best train-auc: 0.9859320407223136 val-auc: 0.9705715637963195\n",
      "final val auc 0.9705715637963195\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#without kfold, optimizing roc-auc directly.\n",
    "#final val auc 0.9705715637963195\n",
    "\n",
    "X_train = sample.copy()\n",
    "y_train = sample.is_attributed.values.copy()\n",
    "\n",
    "X_train1, X_dev1, y_train1, y_dev1 = train_test_split(X_train, y_train, test_size=0.2, random_state=SEED, stratify=y_train)\n",
    "\n",
    "ds = FoldDataset(X_train1, y_train1, X_dev1, y_dev1)\n",
    "ds.build()\n",
    "\n",
    "c = Classifier(loss=roc_auc_score_fn)\n",
    "model = c.train(0, ds, epochs=10)\n",
    "\n",
    "_, _, dev_input, _ = ds.parts()\n",
    "print('final val auc', roc_auc_score(y_dev1, model.predict(dev_input).ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
