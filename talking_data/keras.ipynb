{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "SEED=42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'ip':'uint32',\n",
    "    'app': 'uint16',\n",
    "    'device': 'uint16',\n",
    "    'os': 'uint16',\n",
    "    'channel': 'uint16',\n",
    "    'is_attributed': 'uint8'\n",
    "}   \n",
    "\n",
    "\n",
    "def add_meanx(df):\n",
    "    df1 = sample[['is_attributed', 'app']].groupby(['app']).median().rename(columns={'is_attributed': 'mean1'}).reset_index()\n",
    "    df = pd.merge(df, df1, on=['app'], how='left')\n",
    "    \n",
    "    #df6 = sample[['is_attributed', 'app']].groupby(['app']).std().rename(columns={'is_attributed': 'mean6'}).reset_index()\n",
    "    #df = pd.merge(df, df6, on=['app'], how='left')\n",
    "\n",
    "    #df7 = sample[['is_attributed', 'app']].groupby(['app']).var().rename(columns={'is_attributed': 'mean7'}).reset_index()\n",
    "    #df = pd.merge(df, df7, on=['app'], how='left')\n",
    "\n",
    "    df2 = sample[['is_attributed', 'app', 'channel']].groupby(['app', 'channel']).median().rename(columns={'is_attributed': 'mean2'}).reset_index()    \n",
    "    df = pd.merge(df, df2, on=['app', 'channel'], how='left')\n",
    "                   \n",
    "    #df4 = sample[['is_attributed', 'app', 'channel']].groupby(['app', 'channel']).var().rename(columns={'is_attributed': 'mean4'}).reset_index()    \n",
    "    #df = pd.merge(df, df4, on=['app', 'channel'], how='left')\n",
    "    \n",
    "    #df5 = sample[['is_attributed', 'app', 'channel']].groupby(['app', 'channel']).std().rename(columns={'is_attributed': 'mean5'}).reset_index()    \n",
    "    #df = pd.merge(df, df5, on=['app', 'channel'], how='left')\n",
    "    \n",
    "    df3 = sample[['is_attributed', 'app', 'device']].groupby(['app', 'device']).median().rename(columns={'is_attributed': 'mean3'}).reset_index()    \n",
    "    df = pd.merge(df, df3, on=['app', 'device'], how='left')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('input/train_sample.csv', dtype=dtypes, parse_dates=['click_time', 'attributed_time'])\n",
    "sample['click_wd'] = sample.click_time.dt.weekday\n",
    "sample['click_hour'] = sample.click_time.dt.hour\n",
    "sample = add_meanx(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_y = sample.is_attributed.values\n",
    "sample = sample.drop(['attributed_time', 'click_time', 'is_attributed'], axis=1)\n",
    "\n",
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 10) (20000, 10) (80000,) (20000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(sample, sample_y, test_size=0.2, random_state=SEED)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.topology import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "EMBEDS = [\n",
    "    {'name': 'ip', 'dim': [1024, 100]},\n",
    "    {'name': 'app', 'dim': [1024, 100]},\n",
    "    {'name': 'device', 'dim': [1024, 50]},\n",
    "    {'name': 'os', 'dim': [1024, 50]},\n",
    "    {'name': 'channel', 'dim': [1024, 50]},\n",
    "    {'name': 'click_wd', 'dim': [3, 3]},\n",
    "    {'name': 'click_hour', 'dim': [24, 5]}\n",
    "]\n",
    "\n",
    "def embed(input_dim, output_dim, x):\n",
    "    e = Embedding(input_dim, output_dim, input_length=1, embeddings_regularizer=l2(1e-8))\n",
    "    r = e(x)\n",
    "    r = Reshape((output_dim,))(r)\n",
    "    return r\n",
    "\n",
    "def build_model(features):\n",
    "    misc = Input(shape=(features,), name='misc')\n",
    "    \n",
    "    for e in EMBEDS:\n",
    "        e['input'] = Input(shape=(1,), name=e['name'])\n",
    "        e['layer'] = embed(e['dim'][0], e['dim'][1], e['input'])\n",
    "        \n",
    "    h = concatenate([misc] + [e['layer'] for e in EMBEDS])\n",
    "    h = BatchNormalization()(h)\n",
    "    \n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    h = Dropout(0.5)(h)\n",
    "    \n",
    "    h = Dense(16, activation='relu')(h)\n",
    "    \n",
    "    h = Dense(1, activation='sigmoid')(h)\n",
    "    \n",
    "    model = Model(\n",
    "            inputs=[misc] + [e['input'] for e in EMBEDS],\n",
    "            outputs=h)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return model    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/3\n",
      "80000/80000 [==============================] - 18s 222us/step - loss: 0.0360 - val_loss: 0.0404\n",
      "Epoch 2/3\n",
      "80000/80000 [==============================] - 17s 212us/step - loss: 0.0355 - val_loss: 0.0411\n",
      "Epoch 3/3\n",
      "80000/80000 [==============================] - 17s 212us/step - loss: 0.0355 - val_loss: 0.0411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc46089b2b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hashed(s, size=10):\n",
    "    return s.apply(lambda x: hash(x) % 2 ** size)\n",
    "\n",
    "def build_input(df):\n",
    "    embed_names = [e['name'] for e in EMBEDS]\n",
    "    h = {'misc': df[[x for x in df.columns if x not in embed_names]] }\n",
    "    h.update(dict([(name, hashed(df.loc[:, name]).values) for name in embed_names]))\n",
    "    return h\n",
    "\n",
    "train_input = build_input(X_train)\n",
    "val_input = build_input(X_val)\n",
    "\n",
    "model = build_model(train_input['misc'].shape[1])\n",
    "model.fit(train_input, y_train, \n",
    "          validation_data=(val_input, y_val),\n",
    "          epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_input = build_input(X_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc: 0.5599002464512838\n",
      "val auc: 0.5319284764384474\n"
     ]
    }
   ],
   "source": [
    "print('train auc:', roc_auc_score(y_train, model.predict(train_input).ravel()))\n",
    "print('val auc:', roc_auc_score(y_val, model.predict(val_input).ravel()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
