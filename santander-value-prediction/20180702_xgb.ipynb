{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from https://www.kaggle.com/sggpls/pipeline-kernel-xgb-fe-lb1-40\n",
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "from sklearn.base import clone, is_classifier\n",
    "from sklearn.model_selection._split import check_cv\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "class UniqueTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, axis=1, accept_sparse=False):\n",
    "        if axis == 0:\n",
    "            raise NotImplementedError('axis is 0! Not implemented!')\n",
    "        if accept_sparse:\n",
    "            raise NotImplementedError('accept_sparse is True! Not implemented!')\n",
    "        self.axis = axis\n",
    "        self.accept_sparse = accept_sparse\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        _, self.unique_indices_ = np.unique(X, axis=self.axis, return_index=True)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.unique_indices_]\n",
    "\n",
    "\n",
    "class StatsTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, stat_funs=None):\n",
    "        self.stat_funs = stat_funs\n",
    "    \n",
    "    def _get_stats(self, row):\n",
    "        stats = []\n",
    "        for fun in self.stat_funs:\n",
    "            stats.append(fun(row))\n",
    "        return stats\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return np.apply_along_axis(self._get_stats, arr=X, axis=1)\n",
    "\n",
    "\n",
    "class ClassifierTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, estimator=None, n_classes=2, cv=3):\n",
    "        self.estimator = estimator\n",
    "        self.n_classes = n_classes\n",
    "        self.cv = cv\n",
    "    \n",
    "    def _get_labels(self, y):\n",
    "        y_labels = np.zeros(len(y))\n",
    "        y_us = np.sort(np.unique(y))\n",
    "        step = int(len(y_us) / self.n_classes)\n",
    "        \n",
    "        for i_class in range(self.n_classes):\n",
    "            if i_class + 1 == self.n_classes:\n",
    "                y_labels[y >= y_us[i_class * step]] = i_class\n",
    "            else:\n",
    "                y_labels[\n",
    "                    np.logical_and(\n",
    "                        y >= y_us[i_class * step],\n",
    "                        y < y_us[(i_class + 1) * step]\n",
    "                    )\n",
    "                ] = i_class\n",
    "        return y_labels\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        y_labels = self._get_labels(y)\n",
    "        cv = check_cv(self.cv, y_labels, classifier=is_classifier(self.estimator))\n",
    "        self.estimators_ = []\n",
    "        \n",
    "        for train, _ in cv.split(X, y_labels):\n",
    "            self.estimators_.append(\n",
    "                clone(self.estimator).fit(X[train], y_labels[train])\n",
    "            )\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        cv = check_cv(self.cv, y, classifier=is_classifier(self.estimator))\n",
    "        \n",
    "        X_prob = np.zeros((X.shape[0], self.n_classes))\n",
    "        X_pred = np.zeros(X.shape[0])\n",
    "        \n",
    "        for estimator, (_, test) in zip(self.estimators_, cv.split(X)):\n",
    "            X_prob[test] = estimator.predict_proba(X[test])\n",
    "            X_pred[test] = estimator.predict(X[test])\n",
    "        return np.hstack([X_prob, np.array([X_pred]).T])\n",
    "\n",
    "class XGBRegressorCV(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self, xgb_params=None, fit_params=None, cv=3):\n",
    "        self.xgb_params = xgb_params\n",
    "        self.fit_params = fit_params\n",
    "        self.cv = cv\n",
    "    \n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        feature_importances = []\n",
    "        for estimator in self.estimators_:\n",
    "            feature_importances.append(\n",
    "                estimator.feature_importances_\n",
    "            )\n",
    "        return np.mean(feature_importances, axis=0)\n",
    "    \n",
    "    @property\n",
    "    def evals_result_(self):\n",
    "        evals_result = []\n",
    "        for estimator in self.estimators_:\n",
    "            evals_result.append(\n",
    "                estimator.evals_result_\n",
    "            )\n",
    "        return np.array(evals_result)\n",
    "    \n",
    "    @property\n",
    "    def best_scores_(self):\n",
    "        best_scores = []\n",
    "        for estimator in self.estimators_:\n",
    "            best_scores.append(\n",
    "                estimator.best_score\n",
    "            )\n",
    "        return np.array(best_scores)\n",
    "    \n",
    "    @property\n",
    "    def cv_scores_(self):\n",
    "        return self.best_scores_ \n",
    "    \n",
    "    @property\n",
    "    def cv_score_(self):\n",
    "        return np.mean(self.best_scores_)\n",
    "    \n",
    "    @property\n",
    "    def best_iterations_(self):\n",
    "        best_iterations = []\n",
    "        for estimator in self.estimators_:\n",
    "            best_iterations.append(\n",
    "                estimator.best_iteration\n",
    "            )\n",
    "        return np.array(best_iterations)\n",
    "    \n",
    "    @property\n",
    "    def best_iteration_(self):\n",
    "        return np.round(np.mean(self.best_iterations_))\n",
    "    \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        cv = check_cv(self.cv, y, classifier=False)\n",
    "        self.estimators_ = []\n",
    "        \n",
    "        for train, valid in cv.split(X, y):\n",
    "            self.estimators_.append(\n",
    "                xgb.XGBRegressor(**self.xgb_params).fit(\n",
    "                    X[train], y[train],\n",
    "                    eval_set=[(X[valid], y[valid])],\n",
    "                    **self.fit_params\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        for estimator in self.estimators_:\n",
    "            y_pred.append(estimator.predict(X))\n",
    "        return np.mean(y_pred, axis=0)\n",
    "\n",
    "\n",
    "def get_stat_funs():\n",
    "    \n",
    "    def get_percentiles():\n",
    "        percentiles = []\n",
    "        for q in np.arange(0.1, 1.0, 0.1):\n",
    "            percentiles.append(lambda x: np.percentile(x, q=q))\n",
    "        return percentiles\n",
    "\n",
    "    stat_funs = []\n",
    "    stats = [len, np.min, np.max, np.mean, np.std, skew, kurtosis] + get_percentiles()\n",
    "    \n",
    "    for stat in stats:\n",
    "        stat_funs.append(\n",
    "            lambda x: -1 if x[x != 0.0].size == 0 else stat(x[x != 0.0])\n",
    "        )\n",
    "        stat_funs.append(\n",
    "            lambda x: -1 if np.unique(x[x != 0.0]).size == 0 else stat(np.unique(x[x != 0.0]))\n",
    "        )\n",
    "        stat_funs.append(\n",
    "            lambda x: -1 if np.diff(x[x != 0.0]).size == 0 else stat(np.diff(x[x != 0.0]))\n",
    "        )\n",
    "        stat_funs.append(\n",
    "            lambda x: -1 if np.diff(np.unique(x[x != 0.0])).size == 0 else stat(np.diff(np.unique(x[x != 0.0])))\n",
    "        )\n",
    "    \n",
    "    return stat_funs\n",
    "\n",
    "\n",
    "def get_rfc():\n",
    "    return RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_features=0.5,\n",
    "        max_depth=None,\n",
    "        max_leaf_nodes=270,\n",
    "        min_impurity_decrease=0.0001,\n",
    "        random_state=123,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "def get_data():\n",
    "    train = pd.read_csv('input/train.csv')\n",
    "    test = pd.read_csv('input/test.csv')\n",
    "    y_train_log = np.log1p(train['target'])\n",
    "    id_test = test['ID']\n",
    "    del test['ID']\n",
    "    del train['ID']\n",
    "    del train['target']\n",
    "    return train.values, y_train_log.values, test.values, id_test.values\n",
    "\n",
    "def main():\n",
    "    \n",
    "    xgb_params = {\n",
    "        'n_estimators': 1000,\n",
    "        'objective': 'reg:linear',\n",
    "        'booster': 'gbtree',\n",
    "        'learning_rate': 0.02,\n",
    "        'max_depth': 22,\n",
    "        'min_child_weight': 57,\n",
    "        'gamma' : 1.45,\n",
    "        'alpha': 0.0,\n",
    "        'lambda': 0.0,\n",
    "        'subsample': 0.67,\n",
    "        'colsample_bytree': 0.054,\n",
    "        'colsample_bylevel': 0.50,\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 456\n",
    "    }\n",
    "    \n",
    "    fit_params = {\n",
    "        'early_stopping_rounds': 15,\n",
    "        'eval_metric': 'rmse',\n",
    "        'verbose': False\n",
    "    }\n",
    "    \n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            ('vt', VarianceThreshold(threshold=0.0)),\n",
    "            ('ut', UniqueTransformer()),\n",
    "            ('fu', FeatureUnion(\n",
    "                    [\n",
    "                        ('pca', PCA(n_components=100)),\n",
    "                        ('ct-2', ClassifierTransformer(get_rfc(), n_classes=2, cv=5)),\n",
    "                        ('ct-3', ClassifierTransformer(get_rfc(), n_classes=3, cv=5)),\n",
    "                        ('ct-4', ClassifierTransformer(get_rfc(), n_classes=4, cv=5)),\n",
    "                        ('ct-5', ClassifierTransformer(get_rfc(), n_classes=5, cv=5)),\n",
    "                        ('st', StatsTransformer(stat_funs=get_stat_funs()))\n",
    "                    ]\n",
    "                )\n",
    "            ),\n",
    "            ('xgb-cv', XGBRegressorCV(\n",
    "                    xgb_params=xgb_params,\n",
    "                    fit_params=fit_params,\n",
    "                    cv=10\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    X_train, y_train_log, X_test, id_test = get_data()\n",
    "    \n",
    "    pipe.fit(X_train, y_train_log)\n",
    "    print(pipe.named_steps['xgb-cv'].cv_scores_)\n",
    "    print(pipe.named_steps['xgb-cv'].cv_score_)\n",
    "    \n",
    "    y_pred_log = pipe.predict(X_test)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    \n",
    "    with open('20180702_xgb_pipeline.pkl', 'wb') as f:\n",
    "        pickle.dump([X_train, y_train_log, X_test, id_test, y_pred], f)\n",
    "\n",
    "    submission = pd.DataFrame()\n",
    "    submission['ID'] = id_test\n",
    "    submission['target'] = y_pred\n",
    "    submission.to_csv('pipeline_kernel_xgb_fe_cv{}.csv'.format(\n",
    "        np.round(pipe.named_steps['xgb-cv'].cv_score_), 5), index=None\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.327251 1.303351 1.424554 1.359268 1.234024 1.285931 1.299278 1.347716\n",
      " 1.454937 1.320603]\n",
      "1.3356913\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
